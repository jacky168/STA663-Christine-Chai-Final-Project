{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimization -- JIT (Just-in-time Compiler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting jit_functions.py\n"
     ]
    }
   ],
   "source": [
    "%%file jit_functions.py\n",
    "from numba import jit\n",
    "import numpy as np\n",
    "\n",
    "@jit\n",
    "def calcM(Z,Kplus,sigmaX,sigmaA):\n",
    "    \"\"\"Save the matrix M so we won't need to calculate it again and again\"\"\"\n",
    "    return np.linalg.inv(np.dot(Z[:,0:Kplus].T,Z[:,0:Kplus])+((sigmaX/sigmaA)**2)*np.identity(Kplus))\n",
    "\n",
    "def calcInverse_orig(Z, M, i, k, val):\n",
    "    \"\"\"Effective inverse calculation from Griffiths and Ghahramani (2005; Equations 51 to 54)\n",
    "    M_(-i) = inv(inv(M) - zi.T * zi)\"\"\"\n",
    "    M_i = M - np.dot(np.dot(M,Z[i,:].T),np.dot(Z[i,:],M))/(np.dot(np.dot(Z[i,:],M),Z[i,:].T)-1)\n",
    "    Z[i,k] = val\n",
    "    M = M_i - np.dot(np.dot(M_i,Z[i,:].T),np.dot(Z[i,:],M_i))/(np.dot(np.dot(Z[i,:],M_i),Z[i,:].T)+1)\n",
    "    Inv = M\n",
    "    return Inv\n",
    "\n",
    "def calcInverse(Z, M, i, k, val):\n",
    "    \"\"\"New version to check: M_(-i) = inv(inv(M) - zi.T * zi)\"\"\"\n",
    "    Z[i,k] = val\n",
    "    return np.linalg.inv(np.linalg.inv(M) - np.dot(Z[i,:].T,Z[i,:]))\n",
    "\n",
    "def log_likelihood(X,Z,M,sigmaA,sigmaX,Kplus,N,D):  \n",
    "    \"\"\"Calculate the log-likelihood: P(X|Z,M,sigmaA,sigmaX,Kplus,N,D)\"\"\"  \n",
    "    determinant = np.linalg.det(np.dot(Z.T,Z)+((sigmaX/sigmaA)**2)*np.identity(Kplus))\n",
    "    constant = N*D*0.5*np.log(2*np.pi) + (N-Kplus)*D*np.log(sigmaX) + Kplus*D*np.log(sigmaA) + D*0.5*np.log(determinant)\n",
    "    \n",
    "    middle = np.identity(N) - np.dot(np.dot(Z, M),Z.T)\n",
    "    trace = np.trace(np.dot(np.dot(X.T,middle),X))\n",
    "    kernel = -0.5*np.reciprocal(sigmaX**2)*trace\n",
    "    \n",
    "    log_lik = -constant + kernel\n",
    "    return log_lik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting jit_IBPcode.py\n"
     ]
    }
   ],
   "source": [
    "%%file jit_IBPcode.py\n",
    "#from numba import jit\n",
    "from __future__ import division\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import jit_functions as func\n",
    "# You need to convert them into .py files \n",
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# %matplotlib inline\n",
    "# %precision 4\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "np.random.seed(1234)\n",
    "import scipy.stats as stats\n",
    "import timeit\n",
    "\n",
    "def IBP(N, alpha):\n",
    "    \"\"\"Indian Buffet Process (IBP) steps:\n",
    "    Input: N is the number of customers (objects, images); alpha is the only parameter;\n",
    "    Return: result is the binary matrix (prior); Kplus is the number of dishes (features)\"\"\"\n",
    "    result = np.zeros((N,1000))\n",
    "    \n",
    "    # Step 1: First customer takes a Poisson(alpha) of dishes\n",
    "    t = stats.poisson.rvs(alpha) # (set the random seed when calling the function)\n",
    "    if t > 0:\n",
    "        result[0,0:t] = 1\n",
    "    \n",
    "    # Kplus = the number of features for which m_k > 0 (m_k: the number of previous customers who sampled that dish)\n",
    "    Kplus = t\n",
    "    for i in range(1,N):\n",
    "        for k in range(Kplus):\n",
    "            # Step 2: The ith customer takes dish k with probability m_k/i\n",
    "            p = np.sum(result[0:(i+1),k])/(i+1) # this is a probability, so should be between 0 and 1\n",
    "            assert p <= 1 \n",
    "            assert p >= 0\n",
    "            if stats.uniform.rvs(0) < p:\n",
    "                result[i,k] = 1\n",
    "            else:\n",
    "                result[i,k] = 0\n",
    "                \n",
    "        # Step 3: The ith customer tries a Poisson(alpha/i) number of new dishes\n",
    "        t = stats.poisson.rvs(alpha/(i+1))\n",
    "        if t > 0:\n",
    "            result[i,Kplus:(Kplus+t)] = 1\n",
    "        Kplus += t\n",
    "    result = result[:,0:Kplus]\n",
    "    \n",
    "    return result, Kplus\n",
    "\n",
    "# -------------------------------------------------------------------------------------------------------\n",
    "\n",
    "# Basis images\n",
    "import Image\n",
    "basis1 = np.array([[0,0,0,0,0,0],[0,0,0,0,0,0],[0,0,0,0,0,0],[0,1,0,0,0,0],[1,1,1,0,0,0],[0,1,0,0,0,0]])\n",
    "basis2 = np.array([[1,1,1,0,0,0],[1,0,1,0,0,0],[1,1,1,0,0,0],[0,0,0,0,0,0],[0,0,0,0,0,0],[0,0,0,0,0,0]])\n",
    "basis3 = np.array([[0,0,0,0,0,0],[0,0,0,0,0,0],[0,0,0,0,0,0],[0,0,0,0,0,1],[0,0,0,0,1,1],[0,0,0,1,1,1]])\n",
    "basis4 = np.array([[0,0,0,1,0,0],[0,0,0,1,1,1],[0,0,0,1,0,0],[0,0,0,0,0,0],[0,0,0,0,0,0],[0,0,0,0,0,0]])\n",
    "\n",
    "D = 36\n",
    "b1 = basis1.reshape(D)\n",
    "b2 = basis2.reshape(D)\n",
    "b3 = basis3.reshape(D)\n",
    "b4 = basis4.reshape(D)\n",
    "A = np.array([b1,b2,b3,b4])\n",
    "\n",
    "# These are heatmaps!\n",
    "\n",
    "fig = plt.figure(figsize=(12,3)) # (num=None, tight_layout=True, figsize=(12,3), dpi=80, facecolor='w', edgecolor='k')\n",
    "fig1 = fig.add_subplot(141)\n",
    "fig1.pcolormesh(basis1,cmap=plt.cm.gray)     \n",
    "fig2 = fig.add_subplot(142)\n",
    "fig2.pcolormesh(basis2,cmap=plt.cm.gray)  \n",
    "fig3 = fig.add_subplot(143)\n",
    "fig3.pcolormesh(basis3,cmap=plt.cm.gray)  \n",
    "fig4 = fig.add_subplot(144)\n",
    "fig4.pcolormesh(basis4,cmap=plt.cm.gray) \n",
    "\n",
    "#fig.savefig('basis_images.png')\n",
    "plt.close()\n",
    "print \"Latent feature matrices (A):\"\n",
    "\n",
    "# Generate image data: 100 matrices of size 6*6\n",
    "N = 100\n",
    "D = 36\n",
    "K = 4\n",
    "sigmaX_orig = 0.5\n",
    "\n",
    "# All K basis images, each of length D\n",
    "# Generate N images (customers, objects)\n",
    "np.random.seed(1234)\n",
    "images = np.zeros((N,6,6)) # simulated image data\n",
    "structure = np.zeros((N,6,6))  # 0/1 structure for each image\n",
    "add = stats.bernoulli.rvs(0.5,size=(N,K)) # whether the K=4 latent bases are present in each image\n",
    "epsilon = stats.norm.rvs(loc=0,scale=0.5,size = (N,6,6)) # random noise\n",
    "\n",
    "for i in range(N):\n",
    "    structure[i,:,:] = add[i,0]*basis1 + add[i,1]*basis2 + add[i,2]*basis3 + add[i,3]*basis4\n",
    "    images[i,:,:] = structure[i,:,:] + epsilon[i,:,:]\n",
    "\n",
    "Z_orig = add   \n",
    "\n",
    "# print images.shape\n",
    "print \"Example image:\\n\",images[4]\n",
    "# plt.figure(tight_layout=True, figsize=(3,3),dpi=80)\n",
    "figEx = plt.figure(figsize=(3,3)) # (num=None, tight_layout=True, figsize=(3,3), dpi=80, facecolor='w', edgecolor='k')\n",
    "fig1 = figEx.add_subplot(111)\n",
    "fig1.pcolormesh(images[4],cmap=plt.cm.gray)\n",
    "#figEx.savefig('example_image.png')\n",
    "plt.close()\n",
    "\n",
    "# Generate the Harmonic numbers, but we only need the sum\n",
    "from fractions import Fraction\n",
    "sum_Harmonics = 0\n",
    "Harmonics = 0\n",
    "for i in range(N):\n",
    "    sum_Harmonics += (N-i)*Fraction(1,i+1)\n",
    "    Harmonics += Fraction(1,i+1)\n",
    "# print \"Sum of H_1 + ... + H_N:\", float(sum_Harmonics)\n",
    "# print \"Harmonic number H_N:\", float(Harmonics)\n",
    "\n",
    "# -------------------------------------------------------------------------------------------------------\n",
    "\n",
    "# Initialization\n",
    "N = 100\n",
    "D = 36\n",
    "K = 4\n",
    "sigmaA = 1\n",
    "sigmaX = 1\n",
    "\n",
    "np.random.seed(1005)\n",
    "# alpha = stats.gamma.rvs(a = 1, loc = 0, scale = 1, size = 1)[0]\n",
    "alpha = 1\n",
    "\n",
    "K_inf = 1000\n",
    "Z, Kplus = IBP(N, alpha)\n",
    "print \"Initial Kplus:\", Kplus\n",
    "print \"Z.shape:\",Z.shape # (100,4) = (N,Kplus) (latent)\n",
    "print \"A.shape:\",A.shape # (4,36) = (Kplus,D)  (weight)\n",
    "\n",
    "# Set MCMC steps\n",
    "mcmc = 1000 # plan to sample for 1000 times\n",
    "\n",
    "# Setup the array\n",
    "Z_arr = np.zeros((mcmc,N,K_inf))\n",
    "Kplus_arr = np.zeros(mcmc)\n",
    "sigmaX_arr = np.zeros(mcmc)\n",
    "sigmaA_arr = np.zeros(mcmc)\n",
    "alpha_arr = np.zeros(mcmc)\n",
    "rX_accept = 0\n",
    "rA_accept = 0\n",
    "\n",
    "# More initialization\n",
    "np.random.seed(16)\n",
    "basis1 = np.array([[0,0,0,0,0,0],[0,0,0,0,0,0],[0,0,0,0,0,0],[0,1,0,0,0,0],[1,1,1,0,0,0],[0,1,0,0,0,0]])\n",
    "basis2 = np.array([[1,1,1,0,0,0],[1,0,1,0,0,0],[1,1,1,0,0,0],[0,0,0,0,0,0],[0,0,0,0,0,0],[0,0,0,0,0,0]])\n",
    "basis3 = np.array([[0,0,0,0,0,0],[0,0,0,0,0,0],[0,0,0,0,0,0],[0,0,0,0,0,1],[0,0,0,0,1,1],[0,0,0,1,1,1]])\n",
    "basis4 = np.array([[0,0,0,1,0,0],[0,0,0,1,1,1],[0,0,0,1,0,0],[0,0,0,0,0,0],[0,0,0,0,0,0],[0,0,0,0,0,0]])\n",
    "\n",
    "D = 36\n",
    "b1 = basis1.reshape(D)\n",
    "b2 = basis2.reshape(D)\n",
    "b3 = basis3.reshape(D)\n",
    "b4 = basis4.reshape(D)\n",
    "A = np.array([b1,b2,b3,b4])\n",
    "\n",
    "Z_orig = np.zeros((N,4))\n",
    "sigmaX_orig = 0.5\n",
    "X = np.zeros((N,D))\n",
    "\n",
    "for i in range(N):\n",
    "    Z_orig[i,:] = stats.uniform.rvs(loc=0,scale=1,size=4) > 0.5\n",
    "    while np.sum(Z_orig[i,:]) == 0:\n",
    "        Z_orig[i,:] = stats.uniform.rvs(loc=0,scale=1,size=4) > 0.5\n",
    "    X[i,:] = np.random.normal(size=D)*sigmaX_orig + np.dot(Z_orig[i,:],A)\n",
    "    \n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "# Gibbs Sampler -- Steps\n",
    "np.random.seed(111)\n",
    "elapsed = 0\n",
    "elapsed1 = 0\n",
    "elapsed2 = 0\n",
    "elapsed1k_count = 0\n",
    "elapsed1N_count = 0\n",
    "elapsed1k_init = 0\n",
    "elapsed1k_calc = 0\n",
    "\n",
    "elapsed1_arr = np.zeros(mcmc)\n",
    "elapsed2_arr = np.zeros(mcmc)\n",
    "elapsed1k_count_arr = np.zeros(mcmc)\n",
    "elapsed1N_count_arr = np.zeros(mcmc)\n",
    "elapsed1k_init_arr = np.zeros(mcmc)\n",
    "elapsed1k_calc_arr = np.zeros(mcmc)\n",
    "\n",
    "start = timeit.default_timer()\n",
    "\n",
    "# for mc in range(mcmc):\n",
    "# for mc in range(1000):\n",
    "for mc in range(1000): # just test for 10 iterations\n",
    "\n",
    "    # Step 0: Save generated parameters to the MCMC array\n",
    "    Z_arr[mc,:,0:Kplus] = Z[:,0:Kplus]\n",
    "    # print \"Shape of Z:\",Z.shape\n",
    "    \n",
    "    alpha_arr[mc] = alpha\n",
    "    Kplus_arr[mc] = Kplus\n",
    "    sigmaX_arr[mc] = sigmaX\n",
    "    sigmaA_arr[mc] = sigmaA\n",
    "    \n",
    "    print \"At iteration\",mc,\": Kplus is\",Kplus,\", alpha is\",alpha\n",
    "    \n",
    "    elapsed1_arr[mc] = elapsed1\n",
    "    elapsed2_arr[mc] = elapsed2\n",
    "    elapsed1k_count_arr[mc] = elapsed1k_count/N\n",
    "    elapsed1N_count_arr[mc] = elapsed1N_count/N\n",
    "    elapsed1k_init_arr[mc] = elapsed1k_init\n",
    "    elapsed1k_calc_arr[mc] = elapsed1k_calc\n",
    "    \n",
    "    # print \"Generating Z|alpha takes\",elapsed1,\"sec, and sampling sigmaX, sigmaA takes\",elapsed2,\"sec\"\n",
    "    # print \"In generating Z|alpha, sampling from Kplus takes\",elapsed1k_count/N,\"sec, and sampling new dishes takes\",elapsed1N_count/N,\"sec\"\n",
    "    # print \"In generating Z|alpha -- sampling from Kplus, initializing takes\",elapsed1k_init,\"sec; calculation takes\",elapsed1k_calc,\"sec\"\n",
    "    # print \"----------------------------------------------------\"\n",
    "    \n",
    "    # Step 1: Generate Z|alpha (Gibbs)\n",
    "    start1 = timeit.default_timer()\n",
    "    elapsed1k_count = 0\n",
    "    elapsed1N_count = 0\n",
    "    \n",
    "    for i in range(N):\n",
    "        # Save the matrix M so we won't need to calculate it again and again\n",
    "        # naive.py\n",
    "        # M = func.calcM(Z,Kplus,sigmaX,sigmaA)\n",
    "        \n",
    "        start1k = timeit.default_timer()\n",
    "        \n",
    "        for k in range(Kplus):\n",
    "            \n",
    "            start1k_init = timeit.default_timer()\n",
    "            \n",
    "            # This is possible because Kplus may decrease in this loop (e.g. dropping redundant zeros)\n",
    "            if (k+1) > Kplus:\n",
    "                break\n",
    "            if Z[i,k] > 0:\n",
    "                # Take care of singular features\n",
    "                # Get rid of the features not sampled (remove the zeros)\n",
    "                if np.sum(Z[:,k]) - Z[i,k] <= 0: # whether the dish is sampled by other customers or not\n",
    "                # if np.sum(Z[:,k]) - Z[i,k] == 0: # same as the code above since Z is binary\n",
    "                    #Z[i,k] = 0\n",
    "                    # Avoid Kplus to become zero!\n",
    "#                     if Kplus == 1:\n",
    "#                         Z[:,0] = Z[:,1]\n",
    "#                     else: # Kplus > 1\n",
    "                    Z[:,k:(Kplus-1)] = Z[:,(k+1):Kplus]\n",
    "                    Kplus -= 1\n",
    "                        # Z = Z[:,0:Kplus] # remove the last column\n",
    "                    # naive.py\n",
    "                    # M = func.calcM(Z,Kplus,sigmaX,sigmaA)          \n",
    "                    continue            \n",
    "            \n",
    "            elapsed1k_init = timeit.default_timer() - start1k_init\n",
    "            \n",
    "            start1k_calc = timeit.default_timer()\n",
    "            \n",
    "            # Effective inverse calculation from Griffiths and Ghahramani (2005; Equations 51 to 54)\n",
    "            # M_(-i) = inv(inv(M) - zi.T * zi)\n",
    "#             M0 = calcInverse(Z[:,0:Kplus], M, i, k, 0)\n",
    "#             M1 = calcInverse(Z[:,0:Kplus], M, i, k, 1)\n",
    "            \n",
    "            # Then calculate the posterior distribution: prior * likelihood \n",
    "            # i.e. customers sample the dishes that have been previously sampled\n",
    "            # Likelihood: P(X|Z_(-i,k),sigmaX,sigmaA)\n",
    "            # Prior: P(z_ik = 1 | z_(-i,k)) = m_(-i,k) / N, where m_(-i,k) = number of objects possess feature k, excluding i\n",
    "            P = np.zeros(2)\n",
    "            Z[i,k] = 1\n",
    "            # M1 = calcM(Z,Kplus,sigmaX,sigmaA) \n",
    "            # P[1] = log_likelihood(X,Z[:,0:Kplus],M1,sigmaA,sigmaX,Kplus,N,D) + np.log(sum(Z[:,k])-Z[i,k]) - np.log(N)\n",
    "            M1 = func.calcM(Z,Kplus,sigmaX,sigmaA) \n",
    "            P[1] = func.log_likelihood(X,Z[:,0:Kplus],M1,sigmaA,sigmaX,Kplus,N,D) + np.log(sum(Z[:,k])-Z[i,k]) - np.log(N)\n",
    "            Z[i,k] = 0\n",
    "            # M0 = calcM(Z,Kplus,sigmaX,sigmaA) \n",
    "            # P[0] = log_likelihood(X,Z[:,0:Kplus],M0,sigmaA,sigmaX,Kplus,N,D) + np.log(N-sum(Z[:,k])) - np.log(N)\n",
    "            M0 = func.calcM(Z,Kplus,sigmaX,sigmaA) \n",
    "            P[0] = func.log_likelihood(X,Z[:,0:Kplus],M0,sigmaA,sigmaX,Kplus,N,D) + np.log(N-sum(Z[:,k])) - np.log(N)\n",
    "            P = np.exp(P - max(P))\n",
    "            # Sample from the posterior distribution\n",
    "            rand = stats.uniform.rvs(loc=0,scale=1,size=1)           \n",
    "            if rand < P[0]/(P[0]+P[1]):\n",
    "                Z[i,k] = 0\n",
    "                #M = M0\n",
    "            else:\n",
    "                Z[i,k] = 1\n",
    "                #M = M1\n",
    "\n",
    "            elapsed1k_calc = timeit.default_timer() - start1k_calc\n",
    "        elapsed1k = timeit.default_timer() - start1k\n",
    "        elapsed1k_count += elapsed1k\n",
    "        \n",
    "        # Sample the number of new dishes Pois(alpha/i) for the current customer/object\n",
    "        # Truncated prior: P(z_ik = 1 | z_(-i,k)) = (m_(-i,k) + alpha/Kplus) / (N + alpha/Kplus)\n",
    "        \n",
    "        start1N = timeit.default_timer()\n",
    "        \n",
    "        # trun = np.zeros(5)\n",
    "        trun = np.zeros(4)\n",
    "        # alphaN = alpha/N  # don't use alpha/i, or this can result in division by zero, but I don't know the details\n",
    "        # alphaN = alpha/(i+1)\n",
    "        alphaN = alpha/N\n",
    "        # Note: in MATLAB, any matrix can be expanded => in Python, we need np.vstack and/or np.hstack       \n",
    "        \n",
    "        # for ki in range(5):\n",
    "        for ki in range(4):\n",
    "            if ki > 0:\n",
    "                new_stack = np.zeros((N,ki))\n",
    "                new_stack[i,:] = 1\n",
    "                Z = np.hstack((Z[:,0:Kplus],new_stack))\n",
    "            M = np.linalg.inv(np.dot(Z[:,0:(Kplus+ki)].T,Z[:,0:(Kplus+ki)])+((sigmaX/sigmaA)**2)*np.identity(Kplus+ki))\n",
    "            # Prior: x ~ Pois(lambda): f(x) = ((lambda**x)/x!)*exp(-lambda), where x = ki, lambda = alphaN\n",
    "            \n",
    "            trun[ki] = (ki)*np.log(alphaN) - alphaN - np.log(np.math.factorial(ki)) \n",
    "            # posterior is proportional to prior x likelihood\n",
    "            # trun[ki] += log_likelihood(X,Z[:,0:(Kplus+ki)],M,sigmaA,sigmaX,Kplus+ki,N,D)\n",
    "            trun[ki] += func.log_likelihood(X,Z[:,0:(Kplus+ki)],M,sigmaA,sigmaX,Kplus+ki,N,D)\n",
    "            \n",
    "        # Z[i,Kplus:(Kplus+4)] = 0\n",
    "        Z[i,Kplus:(Kplus+3)] = 0\n",
    "        trun = np.exp(trun-max(trun))\n",
    "        trun = trun/np.sum(trun)\n",
    "        \n",
    "        p = stats.uniform.rvs(loc=0,scale=1,size=1)  \n",
    "        t = 0\n",
    "        # for ki in range(5):\n",
    "        for ki in range(4):\n",
    "            t += trun[ki]\n",
    "            if p < t:\n",
    "                new_dishes = ki\n",
    "                break\n",
    "        Z[i,Kplus:(Kplus+new_dishes)] = 1\n",
    "        Kplus += new_dishes\n",
    "        \n",
    "        elapsed1N = timeit.default_timer() - start1N\n",
    "        elapsed1N_count += elapsed1N\n",
    "        \n",
    "    elapsed1 = timeit.default_timer() - start1\n",
    "        \n",
    "    # Step 2: Sample sigmaX_star (Metropolis)\n",
    "    start2 = timeit.default_timer()\n",
    "    \n",
    "    # M = calcM(Z, Kplus+new_dishes, sigmaX, sigmaA)\n",
    "    M = func.calcM(Z, Kplus, sigmaX, sigmaA)\n",
    "    # logLik = log_likelihood(X, Z[:,0:(Kplus+new_dishes)], M, sigmaA, sigmaX, Kplus+new_dishes, N, D)\n",
    "    logLik = func.log_likelihood(X, Z[:,0:Kplus], M, sigmaA, sigmaX, Kplus, N, D)\n",
    "    epsilonX = stats.uniform.rvs(loc=0,scale=1,size=1) \n",
    "    if epsilonX < 0.5:\n",
    "        # sigmaX_star = sigmaX - epsilonX/40\n",
    "        # sigmaX_star = sigmaX - epsilonX/20\n",
    "        sigmaX_star = sigmaX - stats.uniform.rvs(loc=0,scale=1,size=1)/20\n",
    "    else:\n",
    "        # sigmaX_star = sigmaX + epsilonX/20   \n",
    "        sigmaX_star = sigmaX + stats.uniform.rvs(loc=0,scale=1,size=1)/20 \n",
    "    # M_Xstar = calcM(Z, Kplus+new_dishes, sigmaX_star, sigmaA)\n",
    "    M_Xstar = func.calcM(Z, Kplus, sigmaX_star, sigmaA)\n",
    "    # logLikX_star = log_likelihood(X, Z[:,0:(Kplus+new_dishes)], M_Xstar, sigmaA, sigmaX_star, Kplus+new_dishes, N, D)\n",
    "    logLikX_star = func.log_likelihood(X, Z[:,0:Kplus], M_Xstar, sigmaA, sigmaX_star, Kplus, N, D)\n",
    "    acc_X = np.exp(min(0, logLikX_star-logLik))\n",
    "    \n",
    "    # Step 3: Sample sigmaA_star (Metropolis)\n",
    "    epsilonA = stats.uniform.rvs(loc=0,scale=1,size=1)\n",
    "    if epsilonA < 0.5:\n",
    "        # sigmaA_star = sigmaA - epsilonA/20\n",
    "        sigmaA_star = sigmaA - stats.uniform.rvs(loc=0,scale=1,size=1)/20\n",
    "    else:\n",
    "        # sigmaA_star = sigmaA + epsilonA/40 \n",
    "        sigmaA_star = sigmaA + stats.uniform.rvs(loc=0,scale=1,size=1)/20\n",
    "        # sigmaA_star = sigmaA + epsilonA/20   \n",
    "    # M_Astar = calcM(Z, Kplus+new_dishes, sigmaX, sigmaA_star)\n",
    "    M_Astar = func.calcM(Z, Kplus, sigmaX, sigmaA_star)\n",
    "    # logLikA_star = log_likelihood(X, Z[:,0:(Kplus+new_dishes)], M_Astar, sigmaA_star, sigmaX, Kplus+new_dishes, N, D)\n",
    "    logLikA_star = func.log_likelihood(X, Z[:,0:Kplus], M_Astar, sigmaA_star, sigmaX, Kplus, N, D)\n",
    "    acc_A = np.exp(min(0, logLikA_star-logLik))\n",
    "    \n",
    "    randX = stats.uniform.rvs(loc=0,scale=1,size=1)\n",
    "    if randX < acc_X:\n",
    "        sigmaX = sigmaX_star\n",
    "        rX_accept += 1\n",
    "    randA = stats.uniform.rvs(loc=0,scale=1,size=1)\n",
    "    if randA < acc_A:\n",
    "        sigmaA = sigmaA_star\n",
    "        rA_accept += 1\n",
    "    \n",
    "    elapsed2 = timeit.default_timer() - start2\n",
    "    \n",
    "    # Step 4: Sample alpha|Z ~ Ga(a=1+Kplus,scale=1+Harmonics)\n",
    "    alpha = stats.gamma.rvs(a = 1+Kplus, loc = 0, scale = np.reciprocal(1+Harmonics),size=1)[0]\n",
    "    \n",
    "elapsed = timeit.default_timer() - start\n",
    "print \"It takes\",elapsed,\"sec to run 1000 iterations\"\n",
    "\n",
    "# ------------------------------------------------------------------------------------------\n",
    "\n",
    "### Plot the traceplots for the IBP results\n",
    "\n",
    "fig = plt.figure(figsize=(8,8))\n",
    "fig1 = fig.add_subplot(411)\n",
    "fig1.plot(Kplus_arr)\n",
    "fig1.set_ylabel('Kplus')\n",
    "fig2 = fig.add_subplot(412)\n",
    "fig2.plot(alpha_arr)\n",
    "fig2.set_ylabel('alpha')\n",
    "fig3 = fig.add_subplot(413)\n",
    "fig3.plot(sigmaX_arr)\n",
    "fig3.set_ylabel('sigmaX')\n",
    "fig4 = fig.add_subplot(414)\n",
    "fig4.plot(sigmaA_arr)\n",
    "fig4.set_ylabel('sigmaA')\n",
    "fig4.set_xlabel('Index')\n",
    "#fig.savefig('IBP_plot_results.png')\n",
    "plt.close()\n",
    "\n",
    "###### Setup the array\n",
    "Kplus_final = Kplus_arr[996] # in fact it is 5 =.=\n",
    "# Kplus_final = 4\n",
    "# Z_final = Z_arr[996,:,0:Kplus_final-1].reshape(N,Kplus_final-1)\n",
    "# Z_final = Z_arr[996,:,1:Kplus_final].reshape(N,Kplus_final-1)\n",
    "Z_final = Z_arr[996,:,0:Kplus_final].reshape(N,Kplus_final)\n",
    "sigmaX_final = sigmaX_arr[996]\n",
    "sigmaA_final = sigmaA_arr[996]\n",
    "A_inf = np.dot(np.linalg.inv(np.dot(Z_final.T,Z_final) +  ((sigmaX_final/sigmaA_final)**2)*np.identity(Kplus_final)),np.dot(Z_final.T,X))\n",
    "\n",
    "# A_inf[3,:].reshape(6,6)\n",
    "# subplot(1,4,1); imagesc(reshape(A_inf(1,:),6,6)); colormap(gray); axis off\n",
    "# subplot(1,4,2); imagesc(reshape(A_inf(2,:),6,6)); colormap(gray); axis off\n",
    "# subplot(1,4,3); imagesc(reshape(A_inf(3,:),6,6)); colormap(gray); axis off\n",
    "# subplot(1,4,4); imagesc(reshape(A_inf(4,:),6,6)); colormap(gray); axis off\n",
    "\n",
    "# print \"Example image:\\n\",A_inf[0,:].reshape(6,6)\n",
    "fig = plt.figure(figsize=(15,3))\n",
    "fig1 = fig.add_subplot(151)\n",
    "fig1.pcolormesh(A_inf[0,:].reshape(6,6),cmap=plt.cm.gray)\n",
    "fig2 = fig.add_subplot(152)\n",
    "fig2.pcolormesh(A_inf[1,:].reshape(6,6),cmap=plt.cm.gray)\n",
    "fig3 = fig.add_subplot(153)\n",
    "fig3.pcolormesh(A_inf[2,:].reshape(6,6),cmap=plt.cm.gray)\n",
    "fig4 = fig.add_subplot(154)\n",
    "fig4.pcolormesh(A_inf[3,:].reshape(6,6),cmap=plt.cm.gray)\n",
    "fig5 = fig.add_subplot(155)\n",
    "fig5.pcolormesh(A_inf[4,:].reshape(6,6),cmap=plt.cm.gray)\n",
    "fig.savefig(\"IBP_image_results_jit.png\")\n",
    "plt.close()\n",
    "\n",
    "##### Save the profiling results\n",
    "step1 = np.mean(elapsed1_arr)\n",
    "step2 = np.mean(elapsed2_arr)\n",
    "step3 = np.mean(elapsed1k_count_arr)\n",
    "step4 = np.mean(elapsed1N_count_arr)\n",
    "step5 = np.mean(elapsed1k_calc_arr)\n",
    "step6 = np.mean(elapsed1k_init_arr)\n",
    "first = np.array((step1,step2,step3,step4,step5,step6)).reshape(6,1)\n",
    "second = np.array((1,1,100,100,500,500)).reshape(6,1)\n",
    "third = first*second\n",
    "\n",
    "columns = ['Time (seconds)/action','Times performed','Total time (seconds)']\n",
    "index = ['Generating Z given alpha','Sampling sigmaX, sigmaA','Sampling from K+',\n",
    "         'Sampling new dishes','Calculation','Initialization']\n",
    "\n",
    "df = pd.DataFrame(np.hstack((first,second,third)),columns=columns,index=index)\n",
    "tab = df.to_latex()\n",
    "text_file = open(\"Table_jit.tex\", \"w\")\n",
    "text_file.write(tab)\n",
    "text_file.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
