{
 "metadata": {
  "name": "",
  "signature": "sha256:e9be93eb4664e044cfbf33f65e24e904dd37a91038cab3e0a06035ef0ea49dfc"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Initial Code -- Indian Buffet Process (IBP)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from __future__ import division\n",
      "import os\n",
      "import sys\n",
      "import glob\n",
      "import matplotlib.pyplot as plt\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "%matplotlib inline\n",
      "%precision 4\n",
      "plt.style.use('ggplot')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.random.seed(1234)\n",
      "import scipy.stats as stats"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Indian Buffet Process (IBP): Steps\n",
      "\n",
      "- Step 1: First customer takes a Poisson($\\alpha$) of dishes\n",
      "- Step 2: The $i$th customer takes dish $k$ with probability $\\frac{m_k}{i}$, where $m_k$ is the number of previous customers who sampled that dish\n",
      "- Step 3: The $i$th customer tries a Poisson($\\frac{\\alpha}{i}$) number of new dishes\n",
      "- Storage: Binary matrix $\\mathbf{Z}$ with $N$ rows and infinite columns, where $z_{ik}$ = 1 if customer $i$ sampled the dish $k$\n",
      "- Probability: $P(z_{ik}=1 | \\mathbf{z_{-i,k}}) = \\dfrac{m_{-i,k}+\\dfrac{\\alpha}{K}}{N+\\dfrac{\\alpha}{K}} \\rightarrow \\dfrac{m_{-i,k}}{N}$ as $K \\rightarrow \\infty$"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def IBP(N, K, alpha):\n",
      "    \"\"\"Indian Buffet Process (IBP) steps:\n",
      "    N is the number of customers (objects, images); K is the number of dishes (features); alpha is the only parameter\"\"\"\n",
      "    result = np.zeros((N,K))\n",
      "    # result = np.zeros((N,K))\n",
      "    \n",
      "    # Step 1: First customer takes a Poisson(alpha) of dishes\n",
      "    t = stats.poisson.rvs(alpha) # (set the random seed when calling the function)\n",
      "    if t > 0:\n",
      "        result[0,0:t] = 1\n",
      "    \n",
      "    # Kplus = the number of features for which m_k > 0 (m_k: the number of previous customers who sampled that dish)\n",
      "    Kplus = t\n",
      "    for i in range(1,N):\n",
      "        for k in range(Kplus):\n",
      "            # Step 2: The ith customer takes dish k with probability m_k/i\n",
      "            p = np.sum(result[0:i,k])/i # this is a probability, so should be between 0 and 1\n",
      "            # print p\n",
      "            assert p <= 1 \n",
      "            assert p >= 0\n",
      "            if stats.uniform.rvs(0) < p:\n",
      "                result[i,k] = 1\n",
      "            else:\n",
      "                result[i,k] = 0\n",
      "        # Step 3: The ith customer tries a Poisson(alpha/i) number of new dishes\n",
      "        t = stats.poisson.rvs(alpha/i)\n",
      "        if t > 0:\n",
      "            result[i,Kplus:(Kplus+t)] = 1\n",
      "        Kplus += t\n",
      "    \n",
      "    return result, Kplus"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 166
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Indian Buffet Process (IBP): Testing\n",
      "\n",
      "Probability must be between 0 and 1: $ 0 \\leq \\dfrac{m_{-i,k}+\\dfrac{\\alpha}{K}}{N+\\dfrac{\\alpha}{K}}, \\dfrac{m_{-i,k}}{N} \\leq 1$\n",
      "\n",
      "This is equivalent to testing $m_{-i,k} \\leq N$"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.random.seed(16)\n",
      "N1 = 100\n",
      "K1 = 20\n",
      "alpha1 = 1.5\n",
      "\n",
      "result1, Kplus1 = IBP(N1,K1,alpha1)\n",
      "print Kplus1\n",
      "\n",
      "# for i in range(N1):\n",
      "#     for k in range(K1):\n",
      "#         m_negik = np.sum(result1[:,k])-result1[i,k]\n",
      "#         assert m_negik <= N1\n",
      "# print \"done\"\n",
      "# print result1[0:10,:]\n",
      "# print Kplus1\n",
      "print result1.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "5\n",
        "(100, 20)\n"
       ]
      }
     ],
     "prompt_number": 171
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Algorithm Application -- Linear-Gaussian Binary Latent Feature Models\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Variables in Data (Images)\n",
      "\n",
      "$N = 100$ is the number of images (customers, objects)\n",
      "\n",
      "$D = 6 \\times 6 = 36$ is the length of vectors (dishes, features) for each image\n",
      "\n",
      "$K = 4$ is the number of basis images (latent or underlying variables)\n",
      "\n",
      "Each object $i$ has a $D$-dimensional vector of properties, named $x_i$\n",
      "\n",
      "- Generate images $X$ with the $K$ basis images, indicating which bases are used (each with probability 0.5)\n",
      "- Add white noises $\\text{Normal}(0,\\sigma_X^2 = 0.5)$ to these images"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Basis images\n",
      "import Image\n",
      "basis1 = np.array([[0,0,0,0,0,0],[0,0,0,0,0,0],[0,0,0,0,0,0],[0,1,0,0,0,0],[1,1,1,0,0,0],[0,1,0,0,0,0]])\n",
      "basis2 = np.array([[1,1,1,0,0,0],[1,0,1,0,0,0],[1,1,1,0,0,0],[0,0,0,0,0,0],[0,0,0,0,0,0],[0,0,0,0,0,0]])\n",
      "basis3 = np.array([[0,0,0,0,0,0],[0,0,0,0,0,0],[0,0,0,0,0,0],[0,0,0,0,0,1],[0,0,0,0,1,1],[0,0,0,1,1,1]])\n",
      "basis4 = np.array([[0,0,0,1,0,0],[0,0,0,1,1,1],[0,0,0,1,0,0],[0,0,0,0,0,0],[0,0,0,0,0,0],[0,0,0,0,0,0]])\n",
      "\n",
      "# These are heatmaps!\n",
      "plt.figure(num=None, figsize=(12,3), dpi=80, facecolor='w', edgecolor='k')\n",
      "plt.subplot(141)\n",
      "plt.pcolormesh(basis1,cmap=plt.cm.gray)     \n",
      "plt.subplot(142)\n",
      "plt.pcolormesh(basis2,cmap=plt.cm.gray)  \n",
      "plt.subplot(143)\n",
      "plt.pcolormesh(basis3,cmap=plt.cm.gray)  \n",
      "plt.subplot(144)\n",
      "plt.pcolormesh(basis4,cmap=plt.cm.gray)  "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 6,
       "text": [
        "<matplotlib.collections.QuadMesh at 0x7fb93268af10>"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAArsAAADMCAYAAABz22vSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAE11JREFUeJzt3WFoVff5B/DnRpnRSmZjaQuKNNQO5FKq0HaFdgWt+KJl\no68ykL6ovqtKWUdpRQYTnLSds2vpdO7V7JvBsrGVDQZ7sVeFvqpYLLfRYafFUWqopipqWq85/xf+\nF9zQe29yz7n3nF8+HziQtDfPOd7zPSff3PyS1LIsywIAABI00O8DAACAoii7AAAkS9kFACBZyi4A\nAMlSdgEASJayCwBAstqW3cuXL8f+/fvjpZdeipdeein++c9/tnx8o9HI7eD6tY+qz+/FPqowv2zZ\ndd7Tn5/XPuZbdqtyXsxvT3arNb8X+yjD/LZl97e//W2sW7cufvnLX8YvfvGLWLlyZdc77VYZnrgy\nz+/FPqowv2zZdd7Tn5/XPuZbdqtyXsxvT3arNb8X+yjD/JZl98qVK3H8+PHYsGFDREQsWLAglixZ\nks/RQYFkl6qSXapKdimrha3+58TERAwNDcXBgwfjs88+i5GRkdiyZUssWrSoV8cHcyK7VJXsUlWy\nS1nVWv254E8//TR+8pOfxJ49e2L16tVx+PDhWLx4cfzwhz+ceUyj0fivl5BHR0eLPWLmjbGxsZm3\n6/V61Ov1jj9Wdukn2aWKuslthOzSP+2y2/KV3eXLl8fw8HCsXr06IiIee+yxeO+99/7rMbcaWqvV\nujroVlp089wUefx0Jsuyrm6CZcwu84Pslk8vPm+koNviKbv0Qyf33JZrdpctWxZ33XVXfP755xER\ncezYsbaLzaEMZJeqkl2qSnYpq5bLGCIiTp8+Hb/5zW+i2WzGPffcE9u2bWu74Nwru3Qrj/Nctuwy\nP8hu+Xhlt3dkl17r5PpuW3bnQtmlW/365OTc0y3ZLR9lt9xkl250cn37C2oAACRL2QUAIFnKLgAA\nyVJ2AQBIlrILAECylF0AAJKl7AIAkCxlFwCAZCm7AAAkS9kFACBZyi4AAMlSdgEASJayCwBAspRd\nAACSpewCAJAsZRcAgGQpuwAAJEvZBQAgWcouAADJWtjJg7Zv3x6LFy+OgYGBWLBgQbz22mtFHxd0\nTW6pKtmlqmSXMuqo7EZE7N69O5YuXVrksUDu5Jaqkl2qSnYpm46XMWRZVuRxQCHklqqSXapKdimb\nWtZBKnfs2BFLliyJgYGB2LhxY2zcuLH10FottwP8X724iIo8fjqTx3mebW4jnHu6J7vlo3z1juzS\na51c3x2V3cnJybjzzjvj4sWLsWfPnti6dWusWbMmIiIajUY0Go2Zx46Ojiq7dC3LshgbG5t5v16v\nR71en9WMVrmN6H12mR9kt3yU3c50m9sI2aX3OrnndlR2b/aHP/whBgcH4/vf/34+RzkPubDby/uT\nU6e5dW7oluzOP8r0rckuvdDJ9dd2ze7XX38dV69ejYiIqampOHbsWKxatar7o4MCyS1VJbtUlexS\nVm1/G8OFCxdi3759ERExPT0dTzzxRDz00EOFHxh0Q26pKtmlqmSXspr1Mga651s27fUrls4N3ZLd\n+cen0e7ILt3IZRkDAABUlbILAECylF0AAJKl7AIAkCxlFwCAZCm7AAAkS9kFACBZyi4AAMlSdgEA\nSJayCwBAspRdAACSpewCAJAsZRcAgGQpuwAAJEvZBQAgWcouAADJUnYBAEiWsgsAQLKUXQAAktVR\n2Z2eno5XXnklXn/99aKPB3Ilu1SV7FJFcksZdVR2//a3v8XKlSujVqsVfTyQK9mlqmSXKpJbyqht\n2T137lwcPXo0NmzYEFmW9eKYIBeyS1XJLlUkt5RV27L77rvvxnPPPRcDA5b3Ui2yS1XJLlUkt5TV\nwlb/88iRIzE0NBQjIyPRaDRu+ZhGo/Ff/290dDTfI2TeGhsbm3m7Xq9HvV7v+GNll36SXaqo6NxG\nyC7FaJfdWtbiew2/+93v4v3334+BgYG4du1aXL16Nb773e/Gjh07Wu60yLU6vfjWiLVG/dfteS5j\ndpkfZJcilH1ZwFxzGyG7dKeTa6Nl2b3ZJ598En/5y19i586d7Ycqu3Qpz/NcluwyP8guRSh72b3Z\nbHIbIbt0p5NrY1YLawSSqpJdqkp2qSK5pUw6fmV3VkO9skuX+vUqhnNPt2SXIlTpld3Zkl26kfsr\nuwAAUCXKLgAAyVJ2AQBIlrILAECylF0AAJKl7AIAkCxlFwCAZCm7AAAkS9kFACBZyi4AAMlSdgEA\nSJayCwBAspRdAACSpewCAJAsZRcAgGQpuwAAJEvZBQAgWcouAADJUnYBAEjWwnYP+Oabb2L37t1x\n7dq1aDab8cgjj8TmzZt7cWwwZ3JLVckuVSW7lFbWgampqSzLsqzZbGa7du3KxsfHWz4+IgrbeqHI\n47f17jzPNrfOvS2PTXZtZc1VL8iurddbJzpaxrBo0aKIiGg2mzE9PR1Lly7t5MOgr+SWqpJdqkp2\nKaO2yxgiIqanp+PVV1+Ns2fPxqZNm2LlypVFHxd0TW6pKtmlqmSXMqr9/7cQOnLlypXYu3dvbN68\nOer1ekRENBqNaDQaM48ZHR2NWq2W/5H+v1kc7pwVefx0JsuyGBsbm3m/Xq/PZG62bpXbiN5nl/lB\ndilCLz735ZXbCNmldzq5586q7EZE/PGPf4xvfetb8YMf/OC2jxFcupX3jb2T3NKa67oz/cqu80M3\niijTstu9or/ISeG57+Q5artm9+LFi3H58uWIuPGTlh9//HGMjIx0f3RQILmlqmSXqpJdyqrtmt2v\nvvoqDhw4ENPT05FlWTz55JPx4IMP9uLYYM7klqqSXapKdimrWS9j6GhoAi+L01+9WJ/G7LiuO9Ov\n7Do/dKOf91zZvT3LGNrLZRkDAABUlbILAECylF0AAJKl7AIAkCxlFwCAZCm7AAAkS9kFACBZyi4A\nAMlSdgEASJayCwBAspRdAACSpewCAJAsZRcAgGQpuwAAJEvZBQAgWcouAADJUnYBAEiWsgsAQLKU\nXQAAkrWw3QO+/PLLOHDgQFy4cCFqtVo89dRT8fTTT/fi2KArsksVyS1VJbuUVtbG5ORkdurUqSzL\nsuzq1avZiy++mJ05c6blx0SEzdbVloe5ZJfb63cmqrJ1a6657fe/21btLQ+yW87zkvpz34m2yxiW\nLVsW9913X0REDA4OxooVK2JycrLdh0HfyS5VJLdUlexSVrNaszsxMRGnT5+OBx54oKjjgULILlUk\nt1SV7FImbdfs/sfU1FS8+eab8fzzz8fg4ODMf280GtFoNGbeHx0dzfcImbfGxsZm3q7X61Gv1+c0\npyzZrdVqhc6/8R0pyiCP7N4utxHuuxSj6HtuhOyWTSqfN9plt5Z18C9tNpvxxhtvxNq1a+OZZ55p\nu9OiP6mTvrwuwNlmt0hVL7uu687kcR7mklvnh270854ru7eXShntt7bLGLIsi0OHDsWKFSv6XhZg\nNmSXKpJbqkp2Kau2r+weP348fvrTn8aqVatmvvravHlzrF279vZDfZVGl/L4anYu2S2SV3bnh27P\nw1xz6/zQjX7ec2X39ryym4+OljHMeqjg0qUUL3Bld37oV3adH7rRz3uu7N5eip8L+8FfUAMAIFnK\nLgAAyVJ2AQBIlrILAECylF0AAJKl7AIAkCxlFwCAZCm7AAAkS9kFACBZyi4AAMlSdgEASJayCwBA\nspRdAACSpewCAJAsZRcAgGQpuwAAJEvZBQAgWcouAADJUnYBAEjWwnYPOHjwYBw9ejSGhoZi//79\nvTgmyIXsUlWySxXJLWXV9pXd9evXx65du3pxLJAr2aWqZJcqklvKqm3ZXbNmTdxxxx29OBbIlexS\nVbJLFcktZWXNLgAAyWq7ZredRqMRjUZj5v3R0dFuR0JERIyNjc28Xa/Xo16v5zq/19nNsqzQ+ZRH\natllfig6txGyWza1Wq3fh9C1LMvaZrfrslvUBQFF3wRll6LILlXUi+IpuxShXXYtYwAAIFm1rM33\nVt96660YHx+PS5cuxbe//e0YHR2N9evXtx6awMvi9Fce3/KfS3a5Pdd1Z/qVXeeHbvTzniu7t1f0\n8rcUnvtOnqO2ZXcuUnjy6C/rW8vHdd2ZfmXX+aEb/bznyu7tKbvtdfIcWcYAAECylF0AAJKl7AIA\nkCxlFwCAZCm7AAAkS9kFACBZyi4AAMlSdgEASJayCwBAspRdAACSpewCAJAsZRcAgGQpuwAAJEvZ\nBQAgWcouAADJUnYBAEiWsgsAQLKUXQAAkqXsAgCQrIXtHvDRRx/F4cOHY3p6OjZs2BDPPvtsL44L\nuia7VJXsUlWySyllLVy/fj3bsWNHdvbs2ezatWvZyy+/nJ05c6bVh2RZlmURYbN1tXVrrtnl9vqd\niaps3XLftfVjy4PslvO8pP7cd6LlMoaTJ0/GvffeG3fffXcsXLgwHn/88fjwww9bfQiUguxSVbJL\nVckuZdWy7J4/fz6WL18+8/7w8HCcP3++8IOCbskuVSW7VJXsUlZt1+y202g0otFozLw/OjoaN14Z\nh+6MjY3NvF2v16Ner+c6/1bZ5fZc153rR3adH7pVdG4jZLdsUnnu22a31RqHEydOZD/72c9m3v/T\nn/6U/fnPf265LuL3v/99R+snulH0Pqo+vxf7KPv8MmbXeU9/fh77mI/ZrcJ5Mb892a3e/F7sowzz\nWy5juP/+++OLL76IiYmJaDab8cEHH8TDDz9cSCuHPMkuVSW7VJXsUlYtlzEsWLAgtm7dGnv37p35\nNSIrV67s1bHBnMkuVSW7VJXsUlZt1+yuW7cu1q1b1/HAItb49HofVZ/fi31UYX7Zsuu8pz8/r33M\nt+xW5byY357sVmt+L/ZRhvm1LEtkdTIAAPwPfy4YAIBkKbsAACRL2QUAIFld/1GJm3300Udx+PDh\nmZ/CfPbZZ/McHwcPHoyjR4/G0NBQ7N+/P9fZERFffvllHDhwIC5cuBC1Wi2eeuqpePrpp3Ob/803\n38Tu3bvj2rVr0Ww245FHHonNmzfnNv8/pqenY+fOnTE8PBw7d+7Mdfb27dtj8eLFMTAwEAsWLIjX\nXnst1/kREZcvX45Dhw7Fv//974iIeOGFF+I73/lO7vu5WZHZrXpuI2S3E6nlNqL62U0htxGyOxey\n25kq33MjZpHdvH6p7/Xr17MdO3ZkZ8+eza5du5a9/PLL2ZkzZ/Ian2VZln3yySfZv/71r+zHP/5x\nrnP/Y3JyMjt16lSWZVl29erV7MUXX8z93zA1NZVlWZY1m81s165d2fj4eK7zsyzL/vrXv2Zvv/12\n9vrrr+c+e9u2bdmlS5dyn3uzd955J/vHP/6RZdmN5+ny5cuF7q/o7KaQ2yyT3XZSy22WpZHdquc2\ny2R3LmS3M1W+52ZZ59nNbRnDyZMn495774277747Fi5cGI8//nh8+OGHeY2PiIg1a9bEHXfckevM\nmy1btizuu+++iIgYHByMFStWxOTkZK77WLRoUURENJvNmJ6ejqVLl+Y6/9y5c3H06NHYsGFDYX8G\nsKi5ERFXrlyJ48ePx4YNGyLixu9tXLJkSWH7iyg+uynkNkJ2W0kxtxFpZDeF3EbI7mzJbntVvudG\nzC67uS1jOH/+fCxfvnzm/eHh4Th58mRe43tuYmIiTp8+HQ888ECuc6enp+PVV1+Ns2fPxqZNm3L/\nhdvvvvtuPPfcc3H16tVc5/5HrVaLPXv2xMDAQGzcuDE2btyY6/yJiYkYGhqKgwcPxmeffRYjIyOx\nZcuWmYu+CCllt6jcRshuK3LbPffc25PdcpPdWytTX/ADarcwNTUVb775Zjz//PMxODiY6+yBgYHY\nt29fHDp0KMbHx6PRaOQ2+8iRIzE0NBQjIyOFfTW1Z8+e+PnPfx67du2Kv//97zE+Pp7r/OvXr8ep\nU6di06ZN8cYbb8Tg4GC89957ue4jVUXmNkJ2W5Hb7rjntia75SW7t1emvpBb2R0eHo5z587NvH/u\n3LkYHh7Oa3zPNJvN2L9/f3zve9+LRx99tLD9LFmyJNatWxeffvppbjNPnDgRR44cie3bt8fbb78d\njUYjfvWrX+U2PyLizjvvjIiIoaGhePTRR3P/anz58uUxPDwcq1evjoiIxx57LE6dOpXrPv5XCtnt\nVW4jZPdW5Hbu3HPbk91ykt3WytQXciu7999/f3zxxRcxMTERzWYzPvjgg3j44YfzGt8TWZbFoUOH\nYsWKFfHMM8/kPv/ixYtx+fLliLjxk5Yff/xxjIyM5DZ/8+bN8etf/zoOHDgQP/rRj6Jer8eOHTty\nm//111/PfLtjamoqjh07FqtWrcptfsSNdVB33XVXfP755xERcezYscL/tnrVs1t0biNktx25nRv3\n3PZkt5xkt7Wy9YXc1uwuWLAgtm7dGnv37p35VSJ5XzBvvfVWjI+Px6VLl+KFF16I0dHRWL9+fW7z\nT5w4Ee+//36sWrUqXnnllYi4EYi1a9fmMv+rr76KAwcOxPT0dGRZFk8++WQ8+OCDucy+lVqtluu8\nCxcuxL59+yLixlqiJ554Ih566KFc9xERsWXLlnjnnXei2WzGPffcE9u2bct9HzcrOrtVz22E7HYi\ntdxGVD+7Vc9thOzOlezOThXvuRGdZ7eWFbnQCAAA+sgPqAEAkCxlFwCAZCm7AAAkS9kFACBZyi4A\nAMlSdgEASJayCwBAsv4PXDEO/+iVgFAAAAAASUVORK5CYII=\n",
       "text": [
        "<matplotlib.figure.Figure at 0x7fb932838a50>"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Generate image data: 100 matrices of size 6*6\n",
      "N = 100\n",
      "D = 36\n",
      "K = 4\n",
      "\n",
      "# All K basis images, each hof length D\n",
      "# Generate N images (customers, objects)\n",
      "np.random.seed(1234)\n",
      "images = np.zeros((N,6,6)) # simulated image data\n",
      "structure = np.zeros((N,6,6))  # 0/1 structure for each image\n",
      "add = stats.bernoulli.rvs(0.5,size=(N,K)) # whether the K=4 latent bases are present in each image\n",
      "epsilon = stats.norm.rvs(loc=0,scale=0.5,size = (N,6,6)) # random noise\n",
      "\n",
      "for i in range(N):\n",
      "    structure[i,:,:] = add[i,0]*basis1 + add[i,1]*basis2 + add[i,2]*basis3 + add[i,3]*basis4\n",
      "    images[i,:,:] = structure[i,:,:] + epsilon[i,:,:]\n",
      "    \n",
      "print images.shape\n",
      "print images[4]\n",
      "plt.pcolormesh(images[4],cmap=plt.cm.gray)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(100, 6, 6)\n",
        "[[ 0.2067  0.3588  0.1309  0.8786 -0.2506 -0.3491]\n",
        " [ 0.6923 -0.1432  0.25    1.9756  0.8608  1.0184]\n",
        " [ 0.2229 -0.7052  0.225   1.2577 -0.577  -0.6901]\n",
        " [-0.2479  0.7934 -0.8597 -0.0148 -0.383   1.0499]\n",
        " [ 0.6435 -0.1131  1.3629  0.4585  0.7181  0.2389]\n",
        " [-0.0071  0.8766 -0.0827  1.0596 -0.0375  0.4986]]\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 119,
       "text": [
        "<matplotlib.collections.QuadMesh at 0x7fb931161350>"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAWwAAAEECAYAAAAMOA6OAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nxH8BsFwqEFVt52UAAAAASUVORK5CYII=\n",
       "text": [
        "<matplotlib.figure.Figure at 0x7fb93125fa50>"
       ]
      }
     ],
     "prompt_number": 119
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Variables in Transformation\n",
      "\n",
      "$x_i \\sim \\text{Normal}(\\mathbf{z_i} \\mathbf{A}, \\Sigma_X = \\sigma_X^2\\mathbf{I})$\n",
      "\n",
      "$\\mathbf{z_i}$ is a $K$-dimensional binary vector (features)\n",
      "\n",
      "$\\mathbf{A}$ is a $K \\times D$ matrix of weights, with prior $A \\sim \\text{Normal}(0,\\sigma_A^2 \\mathbf{I})$\n",
      "\n",
      "$Z \\sim \\text{IBP}(\\alpha)$, where $m_k$ is the number of objects with feature $k$\n",
      "\n",
      "$p(Z | \\alpha) = \\dfrac{\\alpha^K}{\\prod^{2^N-1}_{h=1}K_h!} \\exp(-\\alpha H_N) \\prod^{K}_{k=1}\\dfrac{(N-m_k)!(m_k-1)!}{N!}$\n",
      "\n",
      "Note 1: $\\alpha$ is a variable influencing the number of features  $D$\n",
      "\n",
      "Note 2: $K_h$ is the number of features with history $h$ (whether the $N$ images possess this feature, $2^N-1$ possibilities in total)\n",
      "\n",
      "Note 3: $H_N$ is the $N^{\\text{th}}$ harmonic number, and $m_k$ is the number of objects with feature $k$"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Initialization\n",
      "N = 100\n",
      "D = 36\n",
      "K = 4\n",
      "sigmaA = 0.5\n",
      "sigmaX = 1.7\n",
      "np.random.seed(157)\n",
      "alpha = stats.gamma.rvs(a = 1, loc = 0, scale = 1, size = 1) \n",
      "print alpha"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[ 1.5965]\n"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Checking whether the gamma distribution is setup correctly\n",
      "# ff ~ Gamma(a,b): a = shape, b = 1/scale => E(ff) = a/b = a*scale, Var(ff) = a/b**2 = a*scale**2\n",
      "# Generate 1000 random samples from Ga(3,2)\n",
      "rv = stats.gamma.rvs(a = 3, loc = 0, scale = 2, size=1000)\n",
      "print np.mean(rv)  # should be close to 3*2 = 6\n",
      "print np.var(rv)   # should be close to 3*2*2 = 12"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "5.90360905136\n",
        "12.3931824739\n"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Gibbs Sampler\n",
      "\n",
      "Initialization: $\\sigma_A = 0.5, \\sigma_X = 1.7, \\alpha \\sim Ga(1,1)$\n",
      "\n",
      "1. Generate $\\alpha|Z \\sim Ga(1+K_+,1+\\sum^{N}_{i=1}H_i)$, where $K_+ = \\sum^{2^N-1}_{h=1}K_h$ and $K_+$ is the number of features for which $m_k > 0$\n",
      "2. Generate $Z|\\alpha \\sim IBP(\\alpha)$\n",
      "3. Sample $\\sigma_{X}^* = \\sigma_X + \\epsilon$, where $\\epsilon \\sim \\text{Unif}(-0.05,0.05)$, and accept $\\sigma_{X}^*$ by Metropolis (not just when the likelihood is larger, i.e. $P(\\sigma_{X}^*) > P(\\sigma_{X})$)\n",
      "4. Sample $\\sigma_{A}^* = \\sigma_A + \\epsilon$, where $\\epsilon \\sim \\text{Unif}(-0.05,0.05)$, and accept $\\sigma_{A}^*$ by Metropolis (not just when the likelihood is larger, i.e. $P(\\sigma_{A}^*) > P(\\sigma_{A})$)\n",
      "5. Sample $A \\sim \\text{Normal}(0,\\sigma_A^2 I)$\n",
      "6. Sample $X \\sim \\text{Normal}(ZA,\\sigma_X^2 I)$\n",
      "\n",
      "Metropolis for $\\sigma_A$ (for $\\sigma_X$ is similar):\n",
      "\n",
      "Current value: $\\sigma_{A}^{(n)}$\n",
      "\n",
      "Candidate value: $\\sigma_{A}^{*}$\n",
      "\n",
      "Generate $r \\sim \\text{Unif}(0,1)$\n",
      "\n",
      "Accept $\\sigma_{A}^{*}$ if $r < \\text{min}\\{ 1, \\dfrac{P(\\sigma_{A}^{*} | \\mathbf{Z,X},\\sigma_X)}{P(\\sigma_{A}^{(n)} | \\mathbf{Z,X},\\sigma_X)} \\}$"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def log_likelihood(X,Z,sigmaX,sigmaA,N,K,D):\n",
      "    \"\"\"Calculate the log-likelihood: P(X|Z,sigmaX,sigmaA,N,K,D)\"\"\"\n",
      "    determinant = np.linalg.det(np.dot(Z.T,Z)+((sigmaX/sigmaA)**2)*np.identity(K))\n",
      "    constant = N*D*0.5*np.log(2*np.pi) + (N-K)*D*np.log(sigmaX) + K*D*np.log(sigmaA) + D*0.5*np.log(determinant)\n",
      "    \n",
      "    middle = np.identity(N) - np.dot(np.dot(Z, np.linalg.inv(np.dot(Z.T,Z)+((sigmaX/sigmaA)**2)*np.identity(K))),Z.T)\n",
      "    trace = np.trace(np.dot(np.dot(X.T,middle),X))\n",
      "    kernel = -0.5*np.reciprocal(sigmaX**2)*trace\n",
      "    \n",
      "    log_lik = -constant + kernel\n",
      "    #print constant\n",
      "    #print kernel\n",
      "    return log_lik\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Initialization\n",
      "N = 100\n",
      "D = 36\n",
      "K = 4\n",
      "sigmaA = 0.5\n",
      "sigmaX = 0.7\n",
      "\n",
      "np.random.seed(157)\n",
      "alpha = stats.gamma.rvs(a = 1, loc = 0, scale = 1, size = 1) \n",
      "\n",
      "b1 = basis1.reshape(D)\n",
      "b2 = basis2.reshape(D)\n",
      "b3 = basis3.reshape(D)\n",
      "b4 = basis4.reshape(D)\n",
      "\n",
      "A = np.array([b1,b2,b3,b4])\n",
      "\n",
      "X = images.reshape(N,D)\n",
      "\n",
      "print alpha\n",
      "Ztemp, Kplus = IBP(N,K,alpha) # prior\n",
      "Z = Ztemp[:,0:K]\n",
      "\n",
      "# Generate the Harmonic numbers, but we only need the sum\n",
      "from fractions import Fraction\n",
      "\n",
      "sum_Harmonics = 0\n",
      "Harmonics = 0\n",
      "for i in range(N):\n",
      "    sum_Harmonics += (N-i)*Fraction(1,i+1)\n",
      "    Harmonics += Fraction(1,i+1)\n",
      "print \"Sum of H_1 + ... + H_N:\", float(sum_Harmonics)\n",
      "print \"Harmonic number H_N:\", float(Harmonics)\n",
      "\n",
      "print \"Z.shape:\",Z.shape # (100,4) = (N,K) (latent)\n",
      "print \"X.shape:\",X.shape # (100,36) = (N,D) (data)\n",
      "print \"A.shape:\",A.shape # (4,36) = (K,D)  (weight)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[ 1.5965]\n"
       ]
      },
      {
       "ename": "IndexError",
       "evalue": "index 4 is out of bounds for axis 1 with size 4",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-168-814faf252826>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m \u001b[0mZtemp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mKplus\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mIBP\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mN\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mK\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# prior\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[0mZ\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mZtemp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mK\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m<ipython-input-166-ea362d8b5d8c>\u001b[0m in \u001b[0;36mIBP\u001b[1;34m(N, K, alpha)\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mKplus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m             \u001b[1;31m# Step 2: The ith customer takes dish k with probability m_k/i\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m             \u001b[0mp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mi\u001b[0m \u001b[1;31m# this is a probability, so should be between 0 and 1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m             \u001b[1;31m# print p\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m             \u001b[1;32massert\u001b[0m \u001b[0mp\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mIndexError\u001b[0m: index 4 is out of bounds for axis 1 with size 4"
       ]
      }
     ],
     "prompt_number": 168
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Gibbs Sampler -- Steps\n",
      "np.random.seed(151)\n",
      "mcmc = 1000 # plan to sample for 1000 times\n",
      "alpha_arr = np.zeros(mcmc)\n",
      "Kplus_arr = np.zeros(mcmc)\n",
      "sigmaX_arr = np.zeros(mcmc)\n",
      "sigmaA_arr = np.zeros(mcmc)\n",
      "rX_accept = 0\n",
      "rA_accept = 0\n",
      "Z_arr = np.zeros((mcmc,N,K))\n",
      "X_arr = np.zeros((mcmc,N,D))\n",
      "A_arr = np.zeros((mcmc,K,D))\n",
      "\n",
      "alpha_arr[0] = alpha\n",
      "Kplus_arr[0] = Kplus\n",
      "sigmaX_arr[0] = sigmaX\n",
      "sigmaA_arr[0] = sigmaA\n",
      "Z_arr[0,:,:] = Z\n",
      "A_arr[0,:,:] = stats.norm.rvs(loc=0,scale=sigmaA,size=(K,D))\n",
      "X_arr[0,:,:] = stats.norm.rvs(loc=np.dot(Z_arr[0,:,:],A_arr[0,:,:]),scale=sigmaX,size=(N,D))\n",
      "\n",
      "for i in range(1,mcmc):\n",
      "# for i in range(1,10):\n",
      "\n",
      "    # Step 1: Generate alpha|Z (Gibbs)\n",
      "    alpha_arr[i] = stats.gamma.rvs(a = 1+Kplus_arr[i-1], loc = 0, scale = np.reciprocal(1+Harmonics),size=1)\n",
      "    \n",
      "    # Alpha becomes very small after the first step\n",
      "    \n",
      "    # alpha_arr[i] = stats.gamma.rvs(a = 1+Kplus_arr[i-1], loc = 0, scale = 1+sum_Harmonics,size=1)\n",
      "    \n",
      "    # print i\n",
      "    # print alpha_arr[i]\n",
      "    # alpha_arr[i] = stats.gamma.rvs(a = 1+Kplus_arr[i-1], loc = 0, scale = np.reciprocal(1+sum_Harmonics),size=1)\n",
      "    # Step 2: Generate Z|alpha (Gibbs)\n",
      "    Ztemp, Kplus_arr[i] = IBP(N,K,alpha_arr[i])\n",
      "    Z_arr[i,:,:] = Ztemp[:,0:K]\n",
      "\n",
      "    # Step 3: Sample sigmaX_star (Metropolis)\n",
      "    epsilonX = stats.uniform.rvs(loc=-0.05,scale=0.1,size=1) # uniform(loc,loc+scale) => acceptance rate 0.675\n",
      "    sigmaX_star = sigmaX_arr[i-1] + epsilonX\n",
      "\n",
      "    logLikX_star = log_likelihood(X_arr[i-1,:,:],Z_arr[i,:,:],sigmaX_star,sigmaA_arr[i-1],N,K,D)\n",
      "    logLikX = log_likelihood(X_arr[i-1,:,:],Z_arr[i,:,:],sigmaX_arr[i-1],sigmaA_arr[i-1],N,K,D)\n",
      "    \n",
      "    # print logLikX_star\n",
      "    # print logLikX\n",
      "    \n",
      "    metropolisX = np.min((1,np.exp(logLikX_star-logLikX)))\n",
      "    rX = stats.uniform.rvs(loc=0,scale=1,size=1)\n",
      "    if rX < metropolisX:\n",
      "        sigmaX_arr[i] = sigmaX_star\n",
      "        rX_accept += 1\n",
      "    else: \n",
      "        sigmaX_arr[i] = sigmaX_arr[i-1]\n",
      "\n",
      "    # Step 4: Sample sigmaA_star\n",
      "    epsilonA = stats.uniform.rvs(loc=-0.05,scale=0.1,size=1) # uniform(loc,loc+scale) => acceptance rate 0.82\n",
      "    sigmaA_star = sigmaA_arr[i-1] + epsilonA\n",
      "\n",
      "    logLikA_star = log_likelihood(X_arr[i-1,:,:],Z_arr[i,:,:],sigmaX_arr[i],sigmaA_star,N,K,D)\n",
      "    logLikA = log_likelihood(X_arr[i-1,:,:],Z_arr[i,:,:],sigmaX_arr[i],sigmaA_arr[i-1],N,K,D)\n",
      "    \n",
      "    # print logLikA_star\n",
      "    # print logLikA\n",
      "\n",
      "    metropolisA = np.min((1,np.exp(logLikA_star-logLikA)))\n",
      "    rA = stats.uniform.rvs(loc=0,scale=1,size=1)\n",
      "    if rA < metropolisA:\n",
      "        sigmaA_arr[i] = sigmaA_star\n",
      "        rA_accept += 1\n",
      "    else:\n",
      "        sigmaA_arr[i] = sigmaA_arr[i-1]\n",
      "\n",
      "    # Step 5: Sample weight matrix A ~ N(0,sigmaA**2 I)\n",
      "    A_arr[i,:,:] = stats.norm.rvs(loc=0,scale=sigmaA_arr[i],size=(K,D))\n",
      "    # Step 6: Sample the data X ~ N(ZA,sigmaX**2 I)\n",
      "    X_arr[i,:,:] = stats.norm.rvs(loc=np.dot(Z_arr[i,:,:],A_arr[i,:,:]),scale=sigmaX_arr[i],size=(N,D))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "IndexError",
       "evalue": "index 4 is out of bounds for axis 1 with size 4",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-165-cf297eef9ec5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     34\u001b[0m     \u001b[1;31m# alpha_arr[i] = stats.gamma.rvs(a = 1+Kplus_arr[i-1], loc = 0, scale = np.reciprocal(1+sum_Harmonics),size=1)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m     \u001b[1;31m# Step 2: Generate Z|alpha (Gibbs)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m     \u001b[0mZtemp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mKplus_arr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mIBP\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mN\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mK\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0malpha_arr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m     \u001b[0mZ_arr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mZtemp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mK\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m<ipython-input-157-2aa8a1754dc1>\u001b[0m in \u001b[0;36mIBP\u001b[1;34m(N, K, alpha)\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mKplus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m# make sure Kplus doesn't exceed K\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m             \u001b[1;31m# Step 2: The ith customer takes dish k with probability m_k/i\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m             \u001b[0mp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mi\u001b[0m \u001b[1;31m# this is a probability, so should be between 0 and 1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m             \u001b[1;31m# print p\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m             \u001b[1;32massert\u001b[0m \u001b[0mp\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mIndexError\u001b[0m: index 4 is out of bounds for axis 1 with size 4"
       ]
      }
     ],
     "prompt_number": 165
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Acceptance rate\n",
      "print \"rA accept:\",np.sum(rA_accept)/mcmc\n",
      "print \"rX accept:\",np.sum(rX_accept)/mcmc\n",
      "\n",
      "# Other parameters\n",
      "print alpha_arr\n",
      "# np.sum(np.dot(Z_arr[400,:,:],A_arr[400,:,:]))\n",
      "# print Z_arr[400,:,:]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "rA accept: 0.989\n",
        "rX accept: 0.346\n",
        "[  1.5965e+00   6.1943e-02   2.1149e-04   3.6612e-05   4.0635e-03\n",
        "   9.1306e-04   5.5217e-05   1.4420e-03   9.6860e-04   2.0396e-04\n",
        "   1.8482e-03   2.0727e-03   3.2543e-04   1.0555e-03   1.6733e-03\n",
        "   2.9629e-04   6.5792e-04   4.9446e-04   9.9701e-04   4.6340e-04\n",
        "   4.9942e-05   9.2354e-04   2.3735e-03   1.7120e-03   1.5677e-03\n",
        "   3.3876e-03   9.9489e-04   7.7254e-04   5.1930e-04   3.9374e-04\n",
        "   2.3656e-03   2.5106e-03   9.5674e-05   1.5953e-03   1.1864e-03\n",
        "   2.1562e-03   5.0957e-03   2.0579e-03   5.8111e-03   5.7135e-04\n",
        "   1.4249e-03   3.6923e-03   9.5398e-05   2.7682e-04   1.0499e-03\n",
        "   4.9563e-03   9.1018e-04   2.9588e-03   2.0203e-04   9.1938e-03\n",
        "   2.4642e-03   3.3257e-03   3.1009e-03   1.9400e-03   3.8763e-05\n",
        "   6.7089e-03   3.1114e-03   2.0773e-05   4.1231e-03   1.3396e-03\n",
        "   1.9208e-03   1.9854e-04   2.5687e-03   3.9101e-03   1.4229e-03\n",
        "   1.0762e-04   1.1930e-03   5.4895e-03   2.0466e-03   1.6363e-03\n",
        "   2.9605e-04   6.2128e-04   8.6876e-03   2.9442e-04   8.1657e-03\n",
        "   4.4769e-03   4.4024e-03   1.7726e-03   2.0389e-03   2.7389e-03\n",
        "   4.6267e-03   2.7895e-03   4.7025e-04   2.6391e-03   2.4441e-03\n",
        "   3.4211e-03   2.0907e-03   1.1288e-03   5.5301e-04   1.3782e-03\n",
        "   1.2131e-03   3.7990e-04   4.3842e-04   7.9918e-04   2.1090e-03\n",
        "   4.6940e-05   6.1253e-04   4.0436e-04   5.6040e-03   3.2778e-03\n",
        "   8.8836e-05   2.4274e-03   1.0295e-03   4.8812e-04   6.5904e-03\n",
        "   6.5152e-04   1.5526e-03   2.0816e-03   4.8804e-03   6.8625e-03\n",
        "   2.4842e-03   6.1268e-04   9.6907e-04   7.8196e-04   6.0014e-03\n",
        "   6.9868e-03   8.1738e-04   8.2886e-04   1.7992e-03   2.6851e-04\n",
        "   1.3553e-05   2.3532e-03   1.0038e-03   7.2220e-03   5.8941e-05\n",
        "   1.3096e-03   9.1371e-04   7.6227e-03   4.8032e-03   7.7504e-03\n",
        "   3.6606e-03   1.3456e-03   3.5152e-03   2.3253e-03   1.2242e-03\n",
        "   2.1387e-04   2.0991e-02   1.6054e-02   2.3427e-03   4.1321e-04\n",
        "   3.8766e-05   3.0397e-03   1.0387e-04   6.5607e-03   2.3238e-03\n",
        "   1.9262e-03   1.2166e-04   3.9327e-03   7.2422e-04   4.5394e-04\n",
        "   2.7004e-03   6.4110e-04   1.7989e-03   1.2667e-03   4.6893e-04\n",
        "   7.6825e-04   1.3058e-03   3.1518e-03   4.5381e-03   1.5202e-03\n",
        "   1.5645e-03   4.9665e-03   1.3333e-03   1.4542e-04   3.2799e-04\n",
        "   1.7815e-04   2.2388e-03   4.9547e-03   1.9572e-03   2.8640e-03\n",
        "   2.7829e-03   6.8569e-03   3.6141e-03   4.3015e-03   3.5766e-03\n",
        "   2.3906e-03   4.6808e-03   8.6603e-03   6.4765e-03   4.9660e-04\n",
        "   7.6282e-05   9.3445e-04   1.5870e-03   1.3434e-03   1.4595e-03\n",
        "   6.6770e-03   9.9597e-04   1.7056e-03   4.4227e-03   4.3185e-03\n",
        "   1.9144e-03   4.9884e-03   9.4778e-03   3.5346e-03   8.1174e-04\n",
        "   5.1201e-03   1.5784e-03   1.4204e-03   5.4929e-03   2.5337e-03\n",
        "   1.4182e-03   4.9777e-04   3.5328e-03   5.6144e-04   9.6481e-03\n",
        "   9.8026e-03   1.2589e-03   6.0537e-03   2.3692e-03   1.1605e-03\n",
        "   5.1294e-04   7.1856e-03   2.3539e-03   1.8688e-03   8.3245e-03\n",
        "   7.8145e-04   1.8142e-03   1.7024e-03   1.0647e-03   1.3544e-03\n",
        "   7.1603e-03   2.0592e-03   1.6980e-04   3.9837e-03   1.6878e-04\n",
        "   8.9570e-03   8.3782e-04   5.2856e-05   4.4180e-03   5.6250e-03\n",
        "   4.4397e-03   9.0518e-03   6.9026e-03   7.5958e-04   2.4354e-04\n",
        "   1.5412e-03   3.7299e-03   3.9169e-03   1.2671e-02   1.6786e-03\n",
        "   2.4676e-03   4.6193e-04   4.5635e-03   4.3766e-03   2.6496e-03\n",
        "   3.6934e-04   7.5780e-04   5.3636e-03   3.3357e-03   2.4974e-04\n",
        "   3.1502e-04   4.5183e-04   2.2622e-03   2.9026e-03   4.8222e-03\n",
        "   2.2157e-03   1.0924e-03   3.9215e-03   8.9097e-04   1.7926e-03\n",
        "   1.5153e-02   4.7479e-03   4.5912e-03   3.9368e-03   8.8938e-04\n",
        "   8.7563e-03   1.4832e-03   7.8174e-05   9.5865e-04   5.7058e-04\n",
        "   9.4306e-04   8.1173e-04   3.3557e-03   9.4545e-04   3.1512e-04\n",
        "   4.5647e-04   8.1411e-04   3.3055e-03   2.4154e-03   1.9855e-03\n",
        "   1.0485e-04   1.2946e-03   2.7499e-03   2.1344e-03   3.2894e-04\n",
        "   1.6867e-03   6.4241e-04   2.1658e-04   1.8184e-03   1.3056e-03\n",
        "   6.5561e-04   3.3140e-03   2.3626e-03   6.8981e-03   1.6976e-02\n",
        "   4.3754e-04   2.2595e-03   1.7400e-03   1.2593e-03   8.4427e-04\n",
        "   9.1842e-03   2.0793e-04   2.0089e-03   1.1302e-04   6.6528e-03\n",
        "   7.4634e-04   1.3511e-03   1.2155e-04   9.1549e-05   6.4647e-04\n",
        "   1.3814e-04   2.6873e-03   2.9942e-03   2.8046e-03   2.2033e-04\n",
        "   9.9714e-04   4.3630e-03   1.2068e-03   3.8076e-03   6.4804e-03\n",
        "   6.3588e-04   1.0763e-03   9.8708e-03   8.7784e-04   1.1831e-02\n",
        "   2.3081e-03   3.9712e-03   3.1985e-03   4.7720e-04   8.6432e-03\n",
        "   3.1348e-03   2.7848e-03   1.0306e-03   2.3791e-03   1.3308e-03\n",
        "   3.1773e-03   7.1652e-04   2.8279e-03   2.7204e-03   1.3215e-02\n",
        "   3.8443e-03   1.9586e-04   2.2403e-03   5.5865e-04   5.0200e-04\n",
        "   3.8021e-03   2.4349e-03   2.6911e-03   3.8732e-03   1.1594e-03\n",
        "   2.5273e-03   2.1662e-03   4.5474e-03   2.3650e-03   4.8984e-03\n",
        "   5.3482e-03   2.0111e-04   3.1717e-04   9.4894e-03   2.3857e-04\n",
        "   3.1432e-03   1.1412e-02   6.1311e-04   1.3001e-03   4.5021e-04\n",
        "   3.4329e-03   7.6822e-03   4.3751e-04   1.2456e-03   4.3145e-06\n",
        "   1.4303e-03   1.5961e-03   1.0277e-03   8.8017e-04   4.2059e-03\n",
        "   2.6165e-03   2.5004e-03   9.8572e-04   2.7697e-03   3.4249e-03\n",
        "   1.0831e-04   9.0002e-03   1.7304e-03   3.1202e-03   4.9545e-03\n",
        "   3.1090e-03   1.2781e-03   2.7964e-03   2.3409e-04   4.3622e-03\n",
        "   4.1313e-04   7.1069e-03   3.5400e-03   3.0666e-04   2.4647e-04\n",
        "   3.7470e-03   8.4152e-04   1.1211e-04   8.1820e-05   7.8363e-03\n",
        "   3.1056e-03   4.5065e-04   1.4248e-03   2.2598e-03   8.7605e-04\n",
        "   4.5327e-03   2.3208e-03   1.3828e-03   1.7587e-03   6.4356e-04\n",
        "   9.6914e-04   9.1878e-05   2.9423e-03   1.0593e-04   2.6286e-03\n",
        "   1.7561e-03   7.8985e-04   1.0190e-03   1.0838e-03   4.8136e-03\n",
        "   4.2995e-03   4.2044e-03   2.2490e-04   6.2516e-04   3.7160e-04\n",
        "   3.6374e-03   3.4387e-03   2.7480e-03   7.3041e-03   4.5920e-03\n",
        "   6.7041e-03   2.7853e-03   2.2883e-03   2.6917e-03   1.9150e-03\n",
        "   1.1344e-03   2.1163e-03   6.2538e-04   2.0357e-03   1.5904e-03\n",
        "   1.8465e-03   1.4126e-03   4.0579e-03   1.2855e-03   1.7383e-03\n",
        "   3.6309e-03   2.1948e-03   2.8456e-05   3.6712e-03   2.8312e-04\n",
        "   1.6761e-04   1.6166e-04   6.0756e-03   1.5503e-03   2.5233e-03\n",
        "   4.1070e-06   2.2737e-03   6.7577e-04   1.6312e-03   2.3383e-04\n",
        "   6.3602e-03   9.0254e-04   7.4838e-05   7.7054e-04   2.3630e-03\n",
        "   1.1896e-03   3.2668e-03   1.5100e-04   5.0406e-03   3.3711e-04\n",
        "   6.4006e-03   1.7035e-03   4.9777e-04   1.8715e-04   5.3106e-04\n",
        "   4.6220e-03   2.5991e-03   1.3172e-04   3.4239e-04   8.3672e-03\n",
        "   4.5772e-03   5.4730e-03   6.5198e-03   8.8629e-04   4.1086e-03\n",
        "   4.2657e-03   3.6887e-04   5.9251e-03   1.8849e-03   4.0312e-03\n",
        "   1.5769e-04   2.7113e-03   2.4098e-03   4.4156e-05   6.8615e-04\n",
        "   1.8414e-03   3.9984e-04   1.1020e-04   3.2835e-03   6.1896e-04\n",
        "   4.7160e-03   3.9814e-03   2.1239e-03   4.3871e-03   2.3636e-03\n",
        "   2.5056e-03   2.9074e-04   2.9225e-03   1.3480e-03   5.9248e-04\n",
        "   8.1537e-06   3.0055e-03   3.7247e-03   2.0318e-03   1.5107e-05\n",
        "   5.7401e-03   2.6367e-03   4.1325e-04   2.1770e-04   1.8412e-03\n",
        "   2.0005e-03   7.5206e-05   1.3980e-03   1.1322e-03   8.1102e-04\n",
        "   1.4724e-03   1.1701e-04   2.8309e-04   1.9767e-03   1.4639e-03\n",
        "   4.2124e-04   6.1227e-04   2.2321e-03   5.4854e-04   1.7034e-03\n",
        "   1.3319e-03   9.8170e-05   2.7160e-03   1.6321e-03   2.9554e-03\n",
        "   3.5067e-03   5.5867e-04   5.4962e-03   1.8849e-04   2.4504e-03\n",
        "   8.1581e-04   8.4712e-04   4.1865e-03   2.7193e-04   2.6833e-04\n",
        "   1.3327e-03   2.6196e-03   5.3939e-03   1.1399e-03   8.9773e-06\n",
        "   9.9874e-04   2.7985e-03   5.4096e-05   1.2113e-03   4.8208e-03\n",
        "   1.6895e-03   1.5194e-03   3.3389e-03   1.3830e-03   3.4141e-03\n",
        "   3.7697e-03   3.5631e-03   2.2049e-03   4.2898e-04   2.6584e-04\n",
        "   5.6437e-04   1.0384e-03   1.3919e-03   2.2399e-03   5.6062e-03\n",
        "   7.3986e-03   9.2202e-04   1.1901e-03   1.6862e-03   1.1459e-03\n",
        "   3.5451e-03   2.4089e-03   5.4932e-03   9.6792e-03   8.4959e-04\n",
        "   4.8368e-03   6.3307e-03   5.1546e-03   4.4353e-03   4.9966e-04\n",
        "   4.3633e-03   4.9388e-04   9.9145e-04   9.0302e-04   3.1940e-03\n",
        "   3.8156e-04   8.3487e-04   2.8893e-03   3.4572e-04   9.6184e-04\n",
        "   3.2900e-04   9.9557e-04   1.0509e-02   7.2987e-04   2.6720e-03\n",
        "   6.6797e-04   8.9482e-04   2.6980e-05   1.1846e-04   9.9179e-05\n",
        "   1.5979e-03   2.2935e-03   2.7898e-03   3.7550e-03   3.5489e-04\n",
        "   5.4369e-03   7.5608e-04   2.3202e-04   5.5049e-04   6.5350e-03\n",
        "   5.6010e-03   1.4633e-03   3.3836e-03   1.3138e-04   2.3822e-03\n",
        "   7.0137e-04   2.4314e-03   2.6848e-04   8.1454e-04   1.6721e-03\n",
        "   1.5695e-04   5.1326e-03   4.8166e-03   4.4873e-03   6.9457e-04\n",
        "   2.7356e-04   2.5345e-03   1.0244e-04   3.5700e-03   1.8391e-03\n",
        "   8.7717e-04   1.8375e-03   2.3935e-03   1.6647e-05   4.1249e-03\n",
        "   2.9731e-03   5.5258e-03   3.8707e-04   3.6655e-05   3.1522e-04\n",
        "   3.6292e-03   6.4101e-03   1.2785e-03   9.7830e-04   1.5183e-04\n",
        "   2.6354e-03   1.5945e-03   4.2559e-05   2.7185e-04   1.8971e-03\n",
        "   5.0854e-03   2.2340e-03   2.1923e-03   2.6011e-04   4.5658e-03\n",
        "   3.9259e-03   8.8642e-05   2.5980e-04   2.0355e-03   4.9887e-03\n",
        "   5.5800e-04   4.2674e-03   1.1284e-03   2.2639e-03   5.8128e-04\n",
        "   9.7524e-04   3.6297e-03   5.0944e-03   5.6236e-05   1.3974e-03\n",
        "   2.5567e-04   2.3202e-03   1.1082e-03   6.2121e-03   4.0432e-05\n",
        "   7.6947e-04   4.1606e-03   2.1224e-03   2.1330e-03   1.0243e-03\n",
        "   2.2109e-03   2.4573e-04   1.5422e-03   3.1893e-03   1.3231e-04\n",
        "   8.0188e-04   1.7217e-03   3.0996e-04   2.8424e-03   5.3980e-04\n",
        "   1.9355e-03   3.0497e-03   4.8269e-03   2.5147e-03   2.6573e-03\n",
        "   1.0834e-03   2.0176e-03   1.5456e-03   2.0917e-03   1.1090e-03\n",
        "   1.6983e-03   2.7641e-03   3.6033e-03   1.1054e-02   4.1132e-03\n",
        "   3.3122e-07   2.0786e-04   3.1267e-03   3.3332e-03   4.3894e-03\n",
        "   7.3689e-04   3.5282e-03   2.9569e-04   1.4077e-04   1.9749e-03\n",
        "   1.9164e-03   8.1845e-04   1.8765e-03   8.8232e-03   1.7934e-03\n",
        "   4.3605e-04   3.6894e-04   1.3452e-03   3.7718e-03   3.9611e-03\n",
        "   1.3258e-04   6.5355e-03   1.3787e-02   3.8927e-03   8.0415e-04\n",
        "   3.0429e-03   7.4722e-05   2.6880e-04   9.9221e-04   1.1452e-04\n",
        "   8.2995e-03   1.8692e-03   2.8774e-04   3.0426e-03   1.0051e-03\n",
        "   1.4442e-03   2.8940e-03   2.4991e-03   3.3458e-03   2.6339e-03\n",
        "   1.4518e-03   7.5031e-03   7.6391e-03   1.8815e-03   3.0689e-03\n",
        "   3.3929e-03   4.5587e-04   4.7610e-03   6.2206e-03   5.9676e-03\n",
        "   2.7674e-03   4.2264e-03   1.8635e-03   5.0161e-04   6.1859e-04\n",
        "   3.3225e-03   2.2376e-03   8.6414e-04   2.2636e-04   1.0568e-02\n",
        "   4.2237e-04   2.4297e-03   3.1434e-03   7.7614e-04   3.1367e-03\n",
        "   2.8934e-04   5.9297e-03   4.2140e-06   6.0544e-04   2.9761e-03\n",
        "   3.8373e-03   4.4097e-03   1.5697e-03   2.9737e-03   2.6800e-03\n",
        "   1.0416e-03   3.2046e-03   1.9484e-03   6.3306e-04   2.4979e-03\n",
        "   5.8783e-03   1.9560e-03   3.4637e-04   1.0306e-03   8.3533e-04\n",
        "   3.6819e-03   7.1204e-05   2.3183e-03   4.3493e-03   3.2903e-03\n",
        "   1.3691e-03   6.1066e-04   4.9806e-03   1.0762e-03   7.0762e-03\n",
        "   9.5963e-05   6.3485e-03   1.2253e-03   4.1089e-04   4.8008e-04\n",
        "   2.1560e-03   9.8371e-03   8.6997e-04   5.3581e-03   3.6583e-03\n",
        "   4.4122e-03   3.7608e-03   1.6521e-03   3.5039e-03   5.9335e-03\n",
        "   1.6150e-03   1.2783e-05   5.3365e-04   1.9394e-03   1.2973e-04\n",
        "   1.8499e-03   1.1856e-03   1.3928e-04   1.6374e-03   1.1175e-03\n",
        "   7.0567e-06   1.9019e-04   2.3678e-03   4.8218e-03   9.1733e-05\n",
        "   2.0050e-03   1.0148e-02   1.4605e-04   7.0544e-04   3.4731e-04\n",
        "   2.6038e-03   1.8718e-07   4.7935e-03   4.4470e-03   2.1904e-04\n",
        "   2.1474e-05   1.7985e-04   2.4272e-03   1.6435e-05   5.8684e-03\n",
        "   9.3696e-04   8.5722e-04   4.7563e-03   1.1478e-04   1.0689e-03\n",
        "   7.1853e-03   1.7661e-03   5.1642e-04   2.1708e-03   7.5152e-04\n",
        "   9.3596e-04   1.1633e-03   2.1804e-03   9.5415e-04   3.6437e-03\n",
        "   3.7796e-04   8.8391e-04   5.2315e-03   1.0259e-03   1.1389e-03\n",
        "   5.0635e-04   1.3861e-03   2.5300e-03   4.8091e-04   4.5955e-04\n",
        "   1.4897e-03   1.3206e-03   2.2402e-03   7.5690e-04   3.3857e-04\n",
        "   1.6499e-03   1.0017e-02   3.0702e-03   4.6173e-05   6.1290e-04\n",
        "   1.6218e-03   6.3613e-04   3.3477e-03   6.7964e-04   2.7758e-03\n",
        "   7.7109e-04   4.7352e-04   1.7224e-03   3.5802e-03   1.4710e-03\n",
        "   3.9600e-03   5.8470e-03   6.7776e-04   4.2080e-04   6.2798e-03\n",
        "   3.6649e-03   2.3161e-03   2.8481e-03   1.3148e-03   1.3600e-03\n",
        "   6.3195e-04   3.6506e-04   1.1694e-03   2.9537e-04   1.9972e-03\n",
        "   4.8816e-03   8.6874e-04   1.1533e-03   3.4358e-04   3.0149e-03\n",
        "   1.3665e-02   1.8641e-04   1.3471e-03   1.9523e-03   1.3542e-03\n",
        "   1.9349e-04   1.5266e-03   3.1445e-03   2.8391e-03   7.9237e-04\n",
        "   4.5750e-03   2.8449e-03   5.0994e-03   2.5417e-03   3.1156e-03\n",
        "   3.5508e-03   4.5969e-03   2.6918e-03   5.7810e-03   9.0099e-04\n",
        "   3.7745e-03   1.4653e-02   1.0179e-03   4.8064e-03   1.6614e-03\n",
        "   3.6085e-03   7.5693e-04   1.9452e-03   1.3211e-03   1.5448e-03\n",
        "   1.8502e-03   3.8294e-03   4.9737e-04   2.6760e-03   7.6828e-04\n",
        "   1.1259e-03   6.6640e-03   3.3566e-03   3.6841e-03   2.1941e-04\n",
        "   3.9380e-03   1.3509e-03   9.0653e-04   5.5820e-04   1.6329e-03\n",
        "   1.5662e-03   1.2970e-03   7.6939e-03   1.0804e-03   1.5269e-03\n",
        "   2.1919e-03   2.4037e-03   3.4663e-03   3.8206e-04   2.7416e-03\n",
        "   1.0010e-02   5.4420e-04   1.3551e-03   7.4265e-03   5.4220e-03\n",
        "   4.8449e-03   3.8806e-03   2.8683e-03   1.0408e-03   1.3472e-03\n",
        "   1.9086e-03   2.6393e-03   1.8277e-03   6.2147e-03   1.6916e-03\n",
        "   1.5356e-03   2.3473e-04   3.7953e-03   8.0438e-03   7.5108e-03\n",
        "   1.3690e-04   8.6905e-03   2.4742e-03   2.3465e-03   4.4107e-03]\n"
       ]
      }
     ],
     "prompt_number": 147
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Gibbs Sampler -- Draft for Steps"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Gibbs Sampler -- Steps\n",
      "np.random.seed(151)\n",
      "\n",
      "# Step 1: Generate alpha|Z (Gibbs)\n",
      "alpha = stats.gamma.rvs(a = 1+Kplus, loc = 0, scale = np.reciprocal(1+sum_Harmonics),size=1)\n",
      "# Step 2: Generate Z|alpha (Gibbs)\n",
      "Z, Kplus = IBP(N,K,alpha)\n",
      "\n",
      "# Step 3: Sample sigmaX_star (Metropolis)\n",
      "epsilonX = stats.uniform.rvs(loc=-0.05,scale=0.05,size=1) # uniform(loc,loc+scale)\n",
      "sigmaX_star = sigmaX + epsilonX\n",
      "\n",
      "# print log_likelihood(X,Z,sigmaX_star,sigmaA,N,K,D)\n",
      "# print log_likelihood(X,Z,sigmaX,sigmaA,N,K,D)\n",
      "\n",
      "metropolisX = np.min((1,np.exp(log_likelihood(X,Z,sigmaX_star,sigmaA,N,K,D)-log_likelihood(X,Z,sigmaX,sigmaA,N,K,D))))\n",
      "rX = stats.uniform.rvs(loc=0,scale=1,size=1)\n",
      "if rX < metropolisX:\n",
      "    sigmaX = sigmaX_star\n",
      "else: \n",
      "    sigmaX = sigmaX\n",
      "\n",
      "# Step 4: Sample sigmaA_star\n",
      "epsilonA = stats.uniform.rvs(loc=-0.05,scale=0.05,size=1) # uniform(loc,loc+scale)\n",
      "sigmaA_star = sigmaA + epsilonA\n",
      "\n",
      "# print log_likelihood(X,Z,sigmaX,sigmaA_star,N,K,D)\n",
      "# print log_likelihood(X,Z,sigmaX,sigmaA,N,K,D)\n",
      "\n",
      "metropolisA = np.min((1,np.exp(log_likelihood(X,Z,sigmaX,sigmaA_star,N,K,D)-log_likelihood(X,Z,sigmaX,sigmaA,N,K,D))))\n",
      "rA = stats.uniform.rvs(loc=0,scale=1,size=1)\n",
      "if rA < metropolisA:\n",
      "    sigmaA = sigmaA_star\n",
      "else:\n",
      "    sigmaA = sigmaA\n",
      "\n",
      "# Step 5: Sample weight matrix A ~ N(0,sigmaA**2 I)\n",
      "A_new = stats.norm.rvs(loc=0,scale=sigmaA,size=(K,D))\n",
      "# Step 6: Sample the data X ~ N(ZA,sigmaX**2 I)\n",
      "X_new = stats.norm.rvs(loc=np.dot(Z,A),scale=sigmaX,size=(N,D))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[-4542.4257]\n",
        "[-4618.9093]\n",
        "[-4542.4257]\n",
        "[-4542.4257]\n"
       ]
      }
     ],
     "prompt_number": 343
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Posterior Distribution Calculation\n",
      "\n",
      "Priors: $P(z_{ik}=1 | \\mathbf{z_{-i,k}}) = \\dfrac{m_{-i,k}+\\dfrac{\\alpha}{K}}{N+\\dfrac{\\alpha}{K}} \\rightarrow \\dfrac{m_{-i,k}}{N}$ as $K \\rightarrow \\infty$\n",
      "\n",
      "Likelihood: $\\mathbf{X}|(\\mathbf{Z},\\mathbf{A},\\mathbf{\\sigma_X}) \\sim \\text{Normal}(\\mathbf{ZA},\\Sigma_X = \\sigma_X^2\\mathbf{I})$\n",
      "\n",
      "i.e. $P(\\mathbf{X} | \\mathbf{Z}, \\sigma_X, \\sigma_A) = \\dfrac{1}{(2\\pi)^{ND/2} \\sigma_X^{(N-K)D} \\sigma_A^{KD} |\\mathbf{Z}^T\\mathbf{Z} + \\dfrac{\\sigma_X^2}{\\sigma_A^2}\\mathbf{I}|^{D/2}} \\exp\\{-\\dfrac{1}{2\\sigma^2_X} \\text{tr}(\\mathbf{X}^T(\\mathbf{I}-\\mathbf{Z}(\\mathbf{Z}^T\\mathbf{Z}+\\dfrac{\\sigma_X^2}{\\sigma_A^2}\\mathbf{I})^{-1})\\mathbf{Z}^T)\\mathbf{X}\\}$\n",
      "\n",
      "Full conditional distribution: $P(z_{ik} | \\mathbf{X,Z_{-i,k}},\\sigma_X, \\sigma_A) \\propto P(\\mathbf{X} | \\mathbf{Z},\\sigma_X, \\sigma_A) P(z_{ik} | \\mathbf{z_{-i,k}})$"
     ]
    }
   ],
   "metadata": {}
  }
 ]
}