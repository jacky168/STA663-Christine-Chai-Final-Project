{
 "metadata": {
  "name": "",
  "signature": "sha256:565b2a5a00c79a8dc61d6f5c796cd286ee5e11e13c06aed42a6dfdede1c334af"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Initial Code -- Indian Buffet Process (IBP)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from __future__ import division\n",
      "import os\n",
      "import sys\n",
      "import glob\n",
      "import matplotlib.pyplot as plt\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "%matplotlib inline\n",
      "%precision 4\n",
      "plt.style.use('ggplot')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.random.seed(1234)\n",
      "import scipy.stats as stats"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Indian Buffet Process (IBP): Steps\n",
      "\n",
      "- Step 1: First customer takes a Poisson($\\alpha$) of dishes\n",
      "- Step 2: The $i$th customer takes dish $k$ with probability $\\frac{m_k}{i}$, where $m_k$ is the number of previous customers who sampled that dish\n",
      "- Step 3: The $i$th customer tries a Poisson($\\frac{\\alpha}{i}$) number of new dishes\n",
      "- Storage: Binary matrix $\\mathbf{Z}$ with $N$ rows and infinite columns, where $z_{ik}$ = 1 if customer $i$ sampled the dish $k$\n",
      "- Probability: $P(z_{ik}=1 | \\mathbf{z_{-i,k}}) = \\dfrac{m_{-i,k}+\\dfrac{\\alpha}{K}}{N+\\dfrac{\\alpha}{K}} \\rightarrow \\dfrac{m_{-i,k}}{N}$ as $K \\rightarrow \\infty$"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def IBP(N, K, alpha):\n",
      "    \"\"\"Indian Buffet Process (IBP) steps:\n",
      "    N is the number of customers (objects, images); K is the number of dishes (features); alpha is the only parameter\"\"\"\n",
      "    result = np.zeros((N,K))\n",
      "    \n",
      "    # Step 1: First customer takes a Poisson(alpha) of dishes\n",
      "    t = stats.poisson.rvs(alpha) # (set the random seed when calling the function)\n",
      "    if t > 0:\n",
      "        result[0,0:t] = 1\n",
      "    \n",
      "    # Kplus = the number of features for which m_k > 0 (m_k: the number of previous customers who sampled that dish)\n",
      "    Kplus = t\n",
      "    for i in range(1,N):\n",
      "        for k in range(K):\n",
      "            # Step 2: The ith customer takes dish k with probability m_k/i\n",
      "            p = np.sum(result[0:i,k])/i # this is a probability, so should be between 0 and 1\n",
      "            # print p\n",
      "            assert p <= 1 \n",
      "            assert p >= 0\n",
      "            if stats.uniform.rvs(0) < p:\n",
      "                result[i,k] = 1\n",
      "            else:\n",
      "                result[i,k] = 0\n",
      "        # Step 3: The ith customer tries a Poisson(alpha/i) number of new dishes\n",
      "        t = stats.poisson.rvs(alpha/i)\n",
      "        if t > 0:\n",
      "            result[i,Kplus:(Kplus+t)] = 1\n",
      "        Kplus += t\n",
      "    \n",
      "    return result, Kplus"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 273
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Indian Buffet Process (IBP): Testing\n",
      "\n",
      "Probability must be between 0 and 1: $ 0 \\leq \\dfrac{m_{-i,k}+\\dfrac{\\alpha}{K}}{N+\\dfrac{\\alpha}{K}}, \\dfrac{m_{-i,k}}{N} \\leq 1$\n",
      "\n",
      "This is equivalent to testing $m_{-i,k} \\leq N$"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.random.seed(3)\n",
      "N1 = 10\n",
      "K1 = 14\n",
      "alpha1 = 1.5\n",
      "\n",
      "result1, Kplus1 = IBP(N1,K1,alpha1)\n",
      "\n",
      "for i in range(N1):\n",
      "    for k in range(K1):\n",
      "        m_negik = np.sum(result[:,k])-result[i,k]\n",
      "        assert m_negik <= N1\n",
      "print \"done\"\n",
      "print result1\n",
      "print Kplus1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "done\n",
        "[[ 1.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
        " [ 1.  1.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
        " [ 1.  1.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
        " [ 1.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
        " [ 1.  1.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
        " [ 1.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
        " [ 1.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
        " [ 1.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
        " [ 1.  1.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
        " [ 1.  1.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]]\n",
        "4\n"
       ]
      }
     ],
     "prompt_number": 344
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Algorithm Application -- Linear-Gaussian Binary Latent Feature Models\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Variables in Data (Images)\n",
      "\n",
      "$N = 100$ is the number of images (customers, objects)\n",
      "\n",
      "$D = 6 \\times 6 = 36$ is the length of vectors (dishes, features) for each image\n",
      "\n",
      "$K = 4$ is the number of basis images (latent or underlying variables)\n",
      "\n",
      "Each object $i$ has a $D$-dimensional vector of properties, named $x_i$\n",
      "\n",
      "- Generate images $X$ with the $K$ basis images, indicating which bases are used (each with probability 0.5)\n",
      "- Add white noises $\\text{Normal}(0,\\sigma_X^2 = 0.5)$ to these images"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Basis images\n",
      "import Image\n",
      "basis1 = np.array([[0,0,0,0,0,0],[0,0,0,0,0,0],[0,0,0,0,0,0],[0,1,0,0,0,0],[1,1,1,0,0,0],[0,1,0,0,0,0]])\n",
      "basis2 = np.array([[1,1,1,0,0,0],[1,0,1,0,0,0],[1,1,1,0,0,0],[0,0,0,0,0,0],[0,0,0,0,0,0],[0,0,0,0,0,0]])\n",
      "basis3 = np.array([[0,0,0,0,0,0],[0,0,0,0,0,0],[0,0,0,0,0,0],[0,0,0,0,0,1],[0,0,0,0,1,1],[0,0,0,1,1,1]])\n",
      "basis4 = np.array([[0,0,0,1,0,0],[0,0,0,1,1,1],[0,0,0,1,0,0],[0,0,0,0,0,0],[0,0,0,0,0,0],[0,0,0,0,0,0]])\n",
      "\n",
      "# These are heatmaps!\n",
      "plt.figure(num=None, figsize=(12,3), dpi=80, facecolor='w', edgecolor='k')\n",
      "plt.subplot(141)\n",
      "plt.pcolormesh(basis1,cmap=plt.cm.gray)     \n",
      "plt.subplot(142)\n",
      "plt.pcolormesh(basis2,cmap=plt.cm.gray)  \n",
      "plt.subplot(143)\n",
      "plt.pcolormesh(basis3,cmap=plt.cm.gray)  \n",
      "plt.subplot(144)\n",
      "plt.pcolormesh(basis4,cmap=plt.cm.gray)  "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 108,
       "text": [
        "<matplotlib.collections.QuadMesh at 0x7f41bff54b90>"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAArsAAADMCAYAAABz22vSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAMlSdgEASJayCwBAsv4PXDEO/+iVgFAAAAAASUVORK5CYII=\n",
       "text": [
        "<matplotlib.figure.Figure at 0x7f41c0155990>"
       ]
      }
     ],
     "prompt_number": 108
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Generate image data: 100 matrices of size 6*6\n",
      "N = 100\n",
      "D = 36\n",
      "K = 4\n",
      "\n",
      "# All K basis images, each hof length D\n",
      "# Generate N images (customers, objects)\n",
      "np.random.seed(1234)\n",
      "images = np.zeros((N,6,6)) # simulated image data\n",
      "structure = np.zeros((N,6,6))  # 0/1 structure for each image\n",
      "add = stats.bernoulli.rvs(0.5,size=(N,K)) # whether the K=4 latent bases are present in each image\n",
      "epsilon = stats.norm.rvs(loc=0,scale=0.5,size = (N,6,6)) # random noise\n",
      "\n",
      "for i in range(N):\n",
      "    structure[i,:,:] = add[i,0]*basis1 + add[i,1]*basis2 + add[i,2]*basis3 + add[i,3]*basis4\n",
      "    images[i,:,:] = structure[i,:,:] + epsilon[i,:,:]\n",
      "    \n",
      "print images.shape\n",
      "print images[4]\n",
      "plt.pcolormesh(images[4],cmap=plt.cm.gray)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(100, 6, 6)\n",
        "[[ 0.2067  0.3588  0.1309  0.8786 -0.2506 -0.3491]\n",
        " [ 0.6923 -0.1432  0.25    1.9756  0.8608  1.0184]\n",
        " [ 0.2229 -0.7052  0.225   1.2577 -0.577  -0.6901]\n",
        " [-0.2479  0.7934 -0.8597 -0.0148 -0.383   1.0499]\n",
        " [ 0.6435 -0.1131  1.3629  0.4585  0.7181  0.2389]\n",
        " [-0.0071  0.8766 -0.0827  1.0596 -0.0375  0.4986]]\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 206,
       "text": [
        "<matplotlib.collections.QuadMesh at 0x7f41bf8f4750>"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAWwAAAEECAYAAAAMOA6OAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAADt1JREFUeJzt3F9oUwf/x/FP0mLrH0KtomMtpWVT1IN/CloE/7DWUphu\nwwvJRRG17mJUvRA2rHNMu5XiXFfn0HaFIc6rYRBWxhB2Lc+uVjrqztqCo8pEZme1VVqjTZPnYs/y\na12XVMzp8Zvf+3XVLOfJPoftee94kiaQSCQSAgC88IJ+DwAAzAzBBgAjCDYAGEGwAcAIgg0ARhBs\nADAiN90Bo6Oj6ujo0K1btyRJ9fX1Wr58uefDAABTpb3CvnDhgsrLy/X555/rs88+U3FxccrjXdfN\n2LgXEednG+dnVzafmzSz80sZ7LGxMfX19amqqkqSlJOTo3nz5j3339Qyzs82zs+ubD43aWbnl/KW\nyODgoEKhkNrb23Xz5k2VlZWprq5OeXl5GRsJAJiZlFfYExMTGhgYUE1NjU6dOqX8/Hx1dnbO1jYA\nwCSBVN8lMjw8rA8++EBtbW2SpL6+PnV2duro0aPJY1zXnXIpHw6HPZwLANkrEokkf3YcR47jTHk+\n5S2RgoICLV68WLdv39bLL7+snp6ef7zpON2Lvvnmm8+7+4W1c+dOvyd4avK/MNnmnXfe8XuCp86f\nP+/3BE+tW7fO7wmeam5uTnvBm/ZjfXV1dTp79qxisZiWLl2qAwcOZGwgAGDm0ga7tLRUJ0+enI0t\nAIAU+E1HADCCYAOAEQQbAIwg2ABgBMEGACMINgAYQbABwAiCDQBGEGwAMIJgA4ARBBsAjCDYAGAE\nwQYAIwg2ABhBsAHACIINAEYQbAAwgmADgBEEGwCMINgAYATBBgAjCDYAGEGwAcAIgg0ARhBsADCC\nYAOAEQQbAIwg2ABgRO5MDjp48KDmzp2rYDConJwcnTx50utdAICnzCjYktTY2KgFCxZ4uQUAkMKM\nb4kkEgkvdwAA0pjRFXYgEFBTU5OCwaCqq6tVXV3t9S4AwFNmFOympiYtXLhQDx48UFNTk4qKirRy\n5UqvtwEAJplRsBcuXChJCoVCqqio0PXr15PBdl1Xrusmjw2Hw9q0aZMHU18M33zzjd8TPNXc3Oz3\nBM98++23fk/wVLb/yXdyZ7JVJBJJ/uw4jhzHmfJ82mA/fvxY8Xhcc+fOVTQaVU9Pj3bt2pXyRQEA\nzy4cDqd8Pm2wR0ZG1NLSIkmKx+PavHmz1q5dm5l1AIAZSxvsJUuWJIMNAPAPv+kIAEYQbAAwgmAD\ngBEEGwCMINgAYATBBgAjCDYAGEGwAcAIgg0ARhBsADCCYAOAEQQbAIwg2ABgBMEGACMINgAYQbAB\nwAiCDQBGEGwAMIJgA4ARBBsAjCDYAGAEwQYAIwg2ABhBsAHACIINAEYQbAAwgmADgBEEGwCMINgA\nYMSMgh2Px3XkyBF98sknXu8BAPyLGQX7ypUrKi4uViAQ8HoPAOBfpA320NCQuru7VVVVpUQiMRub\nAADTSBvsixcvavfu3QoGud0NAH7KTfVkV1eXQqGQysrK5LrutMe4rjvluXA4rM7OzsyufIHs2bPH\n7wme2rhxo98TPPPGG2/4PcFT33//vd8TPPXRRx/5PcFzkUgk+bPjOHIcZ8rzKYPd39+vrq4udXd3\na3x8XI8ePdK5c+d06NChlC8KAHh24XA45fMpg11bW6va2lpJ0q+//qrvvvtuSqwBALPnmW5M8ykR\nAPBPyivsyVatWqVVq1Z5uQUAkAIf/QAAIwg2ABhBsAHACIINAEYQbAAwgmADgBEEGwCMINgAYATB\nBgAjCDYAGEGwAcAIgg0ARhBsADCCYAOAEQQbAIwg2ABgBMEGACMINgAYQbABwAiCDQBGEGwAMIJg\nA4ARBBsAjCDYAGAEwQYAIwg2ABhBsAHACIINAEbkpjvgyZMnamxs1Pj4uGKxmDZs2KDa2trZ2AYA\nmCRtsOfMmaMTJ04oLy9PExMTOn78uPr6+rRixYrZ2AcA+J8Z3RLJy8uTJMViMcXjcS1YsMDTUQCA\nf0p7hS1J8XhcDQ0NunPnjmpqalRcXOz1LgDAU2YU7GAwqJaWFo2Njam5uVmu68pxHEmS67pyXTd5\nbDgc9mYpAGS5SCSS/NlxnGRn/xZIJBKJZ3nBy5cva86cOXrrrbf+9Zj9+/c/40w7Ll++7PcET+3a\ntcvvCZ7Zs2eP3xM8le0fBhgbG/N7gqeGh4fTHpP2HvaDBw80Ojoq6a9PjFy7dk1lZWXPvw4A8EzS\n3hIZHh5WW1ub4vG4EomEtm7dqtWrV8/GNgDAJGmDXVJSolOnTs3GFgBACvymIwAYQbABwAiCDQBG\nEGwAMIJgA4ARBBsAjCDYAGAEwQYAIwg2ABhBsAHACIINAEYQbAAwgmADgBEEGwCMINgAYATBBgAj\nCDYAGEGwAcAIgg0ARhBsADCCYAOAEQQbAIwg2ABgBMEGACMINgAYQbABwAiCDQBGEGwAMCI33QF3\n795VW1ubRkZGFAgEtG3bNm3fvn02tgEAJkkb7NzcXO3du1elpaWKRqNqaGjQmjVrVFxcPBv7AAD/\nk/aWSEFBgUpLSyVJ+fn5Kioq0v37973eBQB4yjPdwx4cHNSNGze0bNkyr/YAAP5F2lsif4tGozp9\n+rT27dun/Pz85F93XVeu6yYfh8PhzC4EgP8nIpFI8mfHceQ4zpTnZxTsWCym1tZWbdmyRRUVFVOe\nm+5Fn36cTQYGBvye4KmcnBy/J3jmtdde83uCpz7++GO/J3gqFAr5PcFz6S54094SSSQS6ujoUFFR\nkXbs2JGxYQCAZ5P2Cru/v19Xr15VSUmJjhw5Ikmqra3VunXrPB8HAPg/aYO9YsUKXbp0aTa2AABS\n4DcdAcAIgg0ARhBsADCCYAOAEQQbAIwg2ABgBMEGACMINgAYQbABwAiCDQBGEGwAMIJgA4ARBBsA\njCDYAGAEwQYAIwg2ABhBsAHACIINAEYQbAAwgmADgBEEGwCMINgAYATBBgAjCDYAGEGwAcAIgg0A\nRhBsADCCYAOAEbnpDmhvb1d3d7dCoZBaW1tnYxMAYBppr7ArKyt17Nix2dgCAEghbbBXrlyp+fPn\nz8YWAEAK3MMGACMINgAYkfZNx3Rc15XrusnH4XBYv/zyy/O+7AtrzZo1fk/w1J9//un3BM+cP3/e\n7wme+uqrr/ye4KloNOr3BE+Fw2FFIpHkY8dx5DjOlGOeO9jTvSgA4NmFw+GUz6cN9pkzZ9Tb26uH\nDx+qvr5e4XBYlZWVGRsIAJiZtME+fPjwbOwAAKTBm44AYATBBgAjCDYAGEGwAcAIgg0ARhBsADCC\nYAOAEQQbAIwg2ABgBMEGACMINgAYQbABwAiCDQBGEGwAMIJgA4ARBBsAjCDYAGAEwQYAIwg2ABhB\nsAHACIINAEYQbAAwgmADgBEEGwCMINgAYATBBgAjCDYAGEGwAcCI3HQH/Pzzz/r6668Vj8dVVVWl\nnTt3zsYuAMBTUl5hx+NxnT9/XseOHdPp06f1n//8R7du3ZqtbQCASVIG+/r163rppZe0ZMkS5ebm\natOmTfrpp59maxsAYJKUwb53754WLVqUfFxYWKh79+55PgoA8E+86QgARqR807GwsFBDQ0PJx0ND\nQyosLJxyjOu6cl03+TgcDuvChQsZngkgnbffftvvCXhOkUgk+bPjOHIcZ+oBiRRisVji0KFDiTt3\n7iTGx8cT7733XuL3339P9T9JXLp0KeXz1nF+tnF+dmXzuSUSMzu/lFfYOTk52r9/v5qbm5Mf6ysu\nLvbkvywAgNTSfg67vLxc5eXls7EFAJBCxt90/Mc9lyzD+dnG+dmVzecmzez8AolEIjELWwAAz4mP\n9QGAEQQbAIxI+6bjs8jmL4pqb29Xd3e3QqGQWltb/Z6TcXfv3lVbW5tGRkYUCAS0bds2bd++3e9Z\nGfPkyRM1NjZqfHxcsVhMGzZsUG1trd+zMioej+vo0aMqLCzU0aNH/Z6TUQcPHtTcuXMVDAaVk5Oj\nkydP+j0po0ZHR9XR0ZH8rqb6+notX778H8dlLNh/f1HUhx9+qMLCQr3//vtav3591nwMsLKyUq+/\n/rrOnTvn9xRP5Obmau/evSotLVU0GlVDQ4PWrFmTNf/85syZoxMnTigvL08TExM6fvy4+vr6tGLF\nCr+nZcyVK1dUXFysR48e+T3FE42NjVqwYIHfMzxx4cIFlZeX691339XExIQeP3487XEZuyWS7V8U\ntXLlSs2fP9/vGZ4pKChQaWmpJCk/P19FRUW6f/++v6MyLC8vT5IUi8UUj8ez6v/8Q0ND6u7uVlVV\nlbL1cwTZel5jY2Pq6+tTVVWVpL9+/2XevHnTHpuxK+zpvijq+vXrmXp5zKLBwUHduHFDy5Yt83tK\nRsXjcTU0NOjOnTuqqanJmj89SNLFixe1e/furL26DgQCampqUjAYVHV1taqrq/2elDGDg4MKhUJq\nb2/XzZs3VVZWprq6uuQFxmS86YgpotGoTp8+rX379ik/P9/vORkVDAbV0tKijo4O9fb2TvkOHMu6\nuroUCoVUVlaWtVehTU1N+vTTT3Xs2DH98MMP6u3t9XtSxkxMTGhgYEA1NTU6deqU8vPz1dnZOe2x\nGQv2TL4oCi+2WCym1tZWbdmyRRUVFX7P8cy8efNUXl6u3377ze8pGdHf36+uri4dPHhQX3zxhVzX\nzbr3WhYuXChJCoVCqqioyKo/vS9atEiFhYV69dVXJUkbN27UwMDAtMdmLNivvPKK/vjjDw0ODioW\ni+nHH3/U+vXrM/Xy8FgikVBHR4eKioq0Y8cOv+dk3IMHDzQ6Oirpr0+MXLt2TWVlZT6vyoza2lp9\n+eWXamtr0+HDh+U4jg4dOuT3rIx5/Phx8lZPNBpVT0+PSkpKfF6VOQUFBVq8eLFu374tSerp6fnX\n23UZu4ed7V8UdebMGfX29urhw4eqr69XOBxWZWWl37Mypr+/X1evXlVJSYmOHDki6a8QrFu3zudl\nmTE8PKy2tjbF43ElEglt3bpVq1ev9nuWJwKBgN8TMmpkZEQtLS2S/nofYvPmzVq7dq3PqzKrrq5O\nZ8+eVSwW09KlS3XgwIFpj+NX0wHACN50BAAjCDYAGEGwAcAIgg0ARhBsADCCYAOAEQQbAIwg2ABg\nxH8BsFwqEFVt52UAAAAASUVORK5CYII=\n",
       "text": [
        "<matplotlib.figure.Figure at 0x7f41bf9899d0>"
       ]
      }
     ],
     "prompt_number": 206
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Variables in Transformation\n",
      "\n",
      "$x_i \\sim \\text{Normal}(\\mathbf{z_i} \\mathbf{A}, \\Sigma_X = \\sigma_X^2\\mathbf{I})$\n",
      "\n",
      "$\\mathbf{z_i}$ is a $K$-dimensional binary vector (features)\n",
      "\n",
      "$\\mathbf{A}$ is a $K \\times D$ matrix of weights, with prior $A \\sim \\text{Normal}(0,\\sigma_A^2 \\mathbf{I})$\n",
      "\n",
      "$Z \\sim \\text{IBP}(\\alpha)$, where $m_k$ is the number of objects with feature $k$\n",
      "\n",
      "$p(Z | \\alpha) = \\dfrac{\\alpha^K}{\\prod^{2^N-1}_{h=1}K_h!} \\exp(-\\alpha H_N) \\prod^{K}_{k=1}\\dfrac{(N-m_k)!(m_k-1)!}{N!}$\n",
      "\n",
      "Note 1: $\\alpha$ is a variable influencing the number of features  $D$\n",
      "\n",
      "Note 2: $K_h$ is the number of features with history $h$ (whether the $N$ images possess this feature, $2^N-1$ possibilities in total)\n",
      "\n",
      "Note 3: $H_N$ is the $N^{\\text{th}}$ harmonic number, and $m_k$ is the number of objects with feature $k$"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Initialization\n",
      "N = 100\n",
      "D = 36\n",
      "K = 4\n",
      "sigmaA = 0.5\n",
      "sigmaX = 1.7\n",
      "np.random.seed(157)\n",
      "alpha = stats.gamma.rvs(a = 1, loc = 0, scale = 1, size = 1) \n",
      "print alpha"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[ 1.5965]\n"
       ]
      }
     ],
     "prompt_number": 235
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Checking whether the gamma distribution is setup correctly\n",
      "# ff ~ Gamma(a,b): a = shape, b = 1/scale => E(ff) = a/b = a*scale, Var(ff) = a/b**2 = a*scale**2\n",
      "# Generate 1000 random samples from Ga(3,2)\n",
      "rv = stats.gamma.rvs(a = 3, loc = 0, scale = 2, size=1000)\n",
      "print np.mean(rv)  # should be close to 3*2 = 6\n",
      "print np.var(rv)   # should be close to 3*2*2 = 12"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "5.88519439843\n",
        "11.9639148358\n"
       ]
      }
     ],
     "prompt_number": 177
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Gibbs Sampler\n",
      "\n",
      "Initialization: $\\sigma_A = 0.5, \\sigma_X = 1.7, \\alpha \\sim Ga(1,1)$\n",
      "\n",
      "1. Generate $\\alpha|Z \\sim Ga(1+K_+,1+\\sum^{N}_{i=1}H_i)$, where $K_+ = \\sum^{2^N-1}_{h=1}K_h$ and $K_+$ is the number of features for which $m_k > 0$\n",
      "2. Generate $Z|\\alpha \\sim IBP(\\alpha)$\n",
      "3. Sample $\\sigma_{X}^* = \\sigma_X + \\epsilon$, where $\\epsilon \\sim \\text{Unif}(-0.05,0.05)$, and accept $\\sigma_{X}^*$ by Metropolis (not just when the likelihood is larger, i.e. $P(\\sigma_{X}^*) > P(\\sigma_{X})$)\n",
      "4. Sample $\\sigma_{A}^* = \\sigma_A + \\epsilon$, where $\\epsilon \\sim \\text{Unif}(-0.05,0.05)$, and accept $\\sigma_{A}^*$ by Metropolis (not just when the likelihood is larger, i.e. $P(\\sigma_{A}^*) > P(\\sigma_{A})$)\n",
      "5. Sample $A \\sim \\text{Normal}(0,\\sigma_A^2 I)$\n",
      "6. Sample $X \\sim \\text{Normal}(ZA,\\sigma_X^2 I)$\n",
      "\n",
      "Metropolis for $\\sigma_A$ (for $\\sigma_X$ is similar):\n",
      "\n",
      "Current value: $\\sigma_{A}^{(n)}$\n",
      "\n",
      "Candidate value: $\\sigma_{A}^{*}$\n",
      "\n",
      "Generate $r \\sim \\text{Unif}(0,1)$\n",
      "\n",
      "Accept $\\sigma_{A}^{*}$ if $r < \\text{min}\\{ 1, \\dfrac{P(\\sigma_{A}^{*} | \\mathbf{Z,X},\\sigma_X)}{P(\\sigma_{A}^{(n)} | \\mathbf{Z,X},\\sigma_X)} \\}$"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def log_likelihood(X,Z,sigmaX,sigmaA,N,K,D):\n",
      "    \"\"\"Calculate the log-likelihood: P(X|Z,sigmaX,sigmaA,N,K,D)\"\"\"\n",
      "    determinant = np.linalg.det(np.dot(Z.T,Z)+((sigmaX/sigmaA)**2)*np.identity(K))\n",
      "    constant = N*D*0.5*np.log(2*np.pi) + (N-K)*D*np.log(sigmaX) + K*D*np.log(sigmaA) + D*0.5*np.log(determinant)\n",
      "    \n",
      "    middle = np.identity(N) - np.dot(np.dot(Z, np.linalg.inv(np.dot(Z.T,Z)+((sigmaX/sigmaA)**2)*np.identity(K))),Z.T)\n",
      "    trace = np.trace(np.dot(np.dot(X.T,middle),X))\n",
      "    kernel = -0.5*np.reciprocal(sigmaX**2)*trace\n",
      "    \n",
      "    log_lik = -constant + kernel\n",
      "    #print constant\n",
      "    #print kernel\n",
      "    return log_lik\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 312
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Initialization\n",
      "N = 100\n",
      "D = 36\n",
      "K = 4\n",
      "sigmaA = 0.5\n",
      "sigmaX = 1.7\n",
      "\n",
      "np.random.seed(157)\n",
      "alpha = stats.gamma.rvs(a = 1, loc = 0, scale = 1, size = 1) \n",
      "\n",
      "b1 = basis1.reshape(D)\n",
      "b2 = basis2.reshape(D)\n",
      "b3 = basis3.reshape(D)\n",
      "b4 = basis4.reshape(D)\n",
      "\n",
      "A = np.array([b1,b2,b3,b4])\n",
      "\n",
      "Z, Kplus = IBP(N,K,alpha) # prior\n",
      "\n",
      "# Generate the Harmonic numbers, but we only need the sum\n",
      "from fractions import Fraction\n",
      "\n",
      "sum_Harmonics = 0\n",
      "for i in range(N):\n",
      "    sum_Harmonics += (N-i)*Fraction(1,i+1)\n",
      "\n",
      "print float(sum_Harmonics)\n",
      "\n",
      "print \"Z.shape:\",Z.shape # (100,4) = (N,K) (latent)\n",
      "print \"X.shape:\",X.shape # (100,36) = (N,D) (data)\n",
      "print \"A.shape:\",A.shape # (4,36) = (K,D)  (weight)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "423.925129282\n",
        "Z.shape: (100, 4)\n",
        "X.shape: (100, 36)\n",
        "A.shape: (4, 36)\n"
       ]
      }
     ],
     "prompt_number": 347
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Gibbs Sampler -- Steps\n",
      "np.random.seed(151)\n",
      "mcmc = 1000 # plan to sample for 1000 times\n",
      "alpha_arr = np.zeros(mcmc)\n",
      "Kplus_arr = np.zeros(mcmc)\n",
      "sigmaX_arr = np.zeros(mcmc)\n",
      "sigmaA_arr = np.zeros(mcmc)\n",
      "rX_accept = 0\n",
      "rA_accept = 0\n",
      "Z_arr = np.zeros((mcmc,N,K))\n",
      "X_arr = np.zeros((mcmc,N,D))\n",
      "A_arr = np.zeros((mcmc,K,D))\n",
      "\n",
      "alpha_arr[0] = alpha\n",
      "Kplus_arr[0] = Kplus\n",
      "sigmaX_arr[0] = sigmaX\n",
      "sigmaA_arr[0] = sigmaA\n",
      "Z_arr[0,:,:] = Z\n",
      "X_arr[0,:,:] = stats.norm.rvs(loc=0,scale=sigmaX,size=(N,D))\n",
      "A_arr[0,:,:] = stats.norm.rvs(loc=0,scale=sigmaA,size=(K,D))\n",
      "\n",
      "for (i in range(mcmc)):\n",
      "# for i in range(1,10):\n",
      "    # Step 1: Generate alpha|Z (Gibbs)\n",
      "    alpha_arr[i] = stats.gamma.rvs(a = 1+Kplus_arr[i-1], loc = 0, scale = np.reciprocal(1+sum_Harmonics),size=1)\n",
      "    # Step 2: Generate Z|alpha (Gibbs)\n",
      "    Z_arr[i,:,:], Kplus_arr[i] = IBP(N,K,alpha_arr[i])\n",
      "\n",
      "    # Step 3: Sample sigmaX_star (Metropolis)\n",
      "    epsilonX = stats.uniform.rvs(loc=-0.05,scale=0.05,size=1) # uniform(loc,loc+scale)\n",
      "    sigmaX_star = sigmaX_arr[i-1] + epsilonX\n",
      "\n",
      "    logLikX_star = log_likelihood(X_arr[i-1,:,:],Z_arr[i-1,:,:],sigmaX_star,sigmaA_arr[i-1],N,K,D)\n",
      "    logLikX = log_likelihood(X_arr[i-1,:,:],Z_arr[i-1,:,:],sigmaX_arr[i-1],sigmaA_arr[i-1],N,K,D)\n",
      "    \n",
      "    # print logLikX_star\n",
      "    # print logLikX\n",
      "    \n",
      "    metropolisX = np.min((1,np.exp(logLikX_star-logLikX)))\n",
      "    rX = stats.uniform.rvs(loc=0,scale=1,size=1)\n",
      "    if rX < metropolisX:\n",
      "        sigmaX_arr[i] = sigmaX_star\n",
      "        rX_accept += 1\n",
      "    else: \n",
      "        sigmaX_arr[i] = sigmaX_arr[i-1]\n",
      "\n",
      "    # Step 4: Sample sigmaA_star\n",
      "    epsilonA = stats.uniform.rvs(loc=-0.05,scale=0.05,size=1) # uniform(loc,loc+scale)\n",
      "    sigmaA_star = sigmaA_arr[i-1] + epsilonA\n",
      "\n",
      "    logLikA_star = log_likelihood(X_arr[i-1,:,:],Z_arr[i-1,:,:],sigmaX_arr[i],sigmaA_star,N,K,D)\n",
      "    logLikA = log_likelihood(X_arr[i-1,:,:],Z_arr[i-1,:,:],sigmaX_arr[i],sigmaA_arr[i-1],N,K,D)\n",
      "    \n",
      "    # print logLikA_star\n",
      "    # print logLikA\n",
      "\n",
      "    metropolisA = np.min((1,np.exp(logLikA_star-logLikA)))\n",
      "    rA = stats.uniform.rvs(loc=0,scale=1,size=1)\n",
      "    if rA < metropolisA:\n",
      "        sigmaA_arr[i] = sigmaA_star\n",
      "        rA_accept += 1\n",
      "    else:\n",
      "        sigmaA_arr[i] = sigmaA_arr[i-1]\n",
      "\n",
      "    # Step 5: Sample weight matrix A ~ N(0,sigmaA**2 I)\n",
      "    A_arr[i,:,:] = stats.norm.rvs(loc=0,scale=sigmaA_arr[i],size=(K,D))\n",
      "    # Step 6: Sample the data X ~ N(ZA,sigmaX**2 I)\n",
      "    X_arr[i,:,:] = stats.norm.rvs(loc=np.dot(Z_arr[i,:,:],A_arr[i,:,:]),scale=sigmaX_arr[i],size=(N,D))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[-7068.9083]\n",
        "-7066.7117174\n",
        "[-7060.1952]\n",
        "-7066.7117174\n",
        "[-6975.8424]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "-6976.1750244\n",
        "[-6975.8424]\n",
        "-6975.84243011\n",
        "[-7000.7476]\n",
        "-7000.67752462\n",
        "[-7000.7476]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "-7000.74759543\n",
        "[-6952.5431]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "-6952.76769262\n",
        "[-6952.5431]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "-6952.54309224\n",
        "[-6879.6931]\n",
        "-6880.10687916\n",
        "[-6879.6931]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "-6879.69305112\n",
        "[-6883.2826]\n",
        "-6877.35746397\n",
        "[-6877.3575]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "-6877.35746397\n",
        "[-6854.7046]\n",
        "-6852.16551568\n",
        "[-6852.1655]\n",
        "-6852.16551568\n",
        "[-6827.0363]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "-6825.12714247\n",
        "[-6827.0363]\n",
        "-6827.03625894\n",
        "[-6814.4206]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "-6813.37605097\n",
        "[-6814.4206]\n",
        "-6814.42063351\n"
       ]
      }
     ],
     "prompt_number": 354
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Gibbs Sampler -- Draft for Steps"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Gibbs Sampler -- Steps\n",
      "np.random.seed(151)\n",
      "\n",
      "# Step 1: Generate alpha|Z (Gibbs)\n",
      "alpha = stats.gamma.rvs(a = 1+Kplus, loc = 0, scale = np.reciprocal(1+sum_Harmonics),size=1)\n",
      "# Step 2: Generate Z|alpha (Gibbs)\n",
      "Z, Kplus = IBP(N,K,alpha)\n",
      "\n",
      "# Step 3: Sample sigmaX_star (Metropolis)\n",
      "epsilonX = stats.uniform.rvs(loc=-0.05,scale=0.05,size=1) # uniform(loc,loc+scale)\n",
      "sigmaX_star = sigmaX + epsilonX\n",
      "\n",
      "# print log_likelihood(X,Z,sigmaX_star,sigmaA,N,K,D)\n",
      "# print log_likelihood(X,Z,sigmaX,sigmaA,N,K,D)\n",
      "\n",
      "metropolisX = np.min((1,np.exp(log_likelihood(X,Z,sigmaX_star,sigmaA,N,K,D)-log_likelihood(X,Z,sigmaX,sigmaA,N,K,D))))\n",
      "rX = stats.uniform.rvs(loc=0,scale=1,size=1)\n",
      "if rX < metropolisX:\n",
      "    sigmaX = sigmaX_star\n",
      "else: \n",
      "    sigmaX = sigmaX\n",
      "\n",
      "# Step 4: Sample sigmaA_star\n",
      "epsilonA = stats.uniform.rvs(loc=-0.05,scale=0.05,size=1) # uniform(loc,loc+scale)\n",
      "sigmaA_star = sigmaA + epsilonA\n",
      "\n",
      "# print log_likelihood(X,Z,sigmaX,sigmaA_star,N,K,D)\n",
      "# print log_likelihood(X,Z,sigmaX,sigmaA,N,K,D)\n",
      "\n",
      "metropolisA = np.min((1,np.exp(log_likelihood(X,Z,sigmaX,sigmaA_star,N,K,D)-log_likelihood(X,Z,sigmaX,sigmaA,N,K,D))))\n",
      "rA = stats.uniform.rvs(loc=0,scale=1,size=1)\n",
      "if rA < metropolisA:\n",
      "    sigmaA = sigmaA_star\n",
      "else:\n",
      "    sigmaA = sigmaA\n",
      "\n",
      "# Step 5: Sample weight matrix A ~ N(0,sigmaA**2 I)\n",
      "A_new = stats.norm.rvs(loc=0,scale=sigmaA,size=(K,D))\n",
      "# Step 6: Sample the data X ~ N(ZA,sigmaX**2 I)\n",
      "X_new = stats.norm.rvs(loc=np.dot(Z,A),scale=sigmaX,size=(N,D))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[-4542.4257]\n",
        "[-4618.9093]\n",
        "[-4542.4257]\n",
        "[-4542.4257]\n"
       ]
      }
     ],
     "prompt_number": 343
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Posterior Distribution Calculation\n",
      "\n",
      "Priors: $P(z_{ik}=1 | \\mathbf{z_{-i,k}}) = \\dfrac{m_{-i,k}+\\dfrac{\\alpha}{K}}{N+\\dfrac{\\alpha}{K}} \\rightarrow \\dfrac{m_{-i,k}}{N}$ as $K \\rightarrow \\infty$\n",
      "\n",
      "Likelihood: $\\mathbf{X}|(\\mathbf{Z},\\mathbf{A},\\mathbf{\\sigma_X}) \\sim \\text{Normal}(\\mathbf{ZA},\\Sigma_X = \\sigma_X^2\\mathbf{I})$\n",
      "\n",
      "i.e. $P(\\mathbf{X} | \\mathbf{Z}, \\sigma_X, \\sigma_A) = \\dfrac{1}{(2\\pi)^{ND/2} \\sigma_X^{(N-K)D} \\sigma_A^{KD} |\\mathbf{Z}^T\\mathbf{Z} + \\dfrac{\\sigma_X^2}{\\sigma_A^2}\\mathbf{I}|^{D/2}} \\exp\\{-\\dfrac{1}{2\\sigma^2_X} \\text{tr}(\\mathbf{X}^T(\\mathbf{I}-\\mathbf{Z}(\\mathbf{Z}^T\\mathbf{Z}+\\dfrac{\\sigma_X^2}{\\sigma_A^2}\\mathbf{I})^{-1})\\mathbf{Z}^T)\\mathbf{X}\\}$\n",
      "\n",
      "Full conditional distribution: $P(z_{ik} | \\mathbf{X,Z_{-i,k}},\\sigma_X, \\sigma_A) \\propto P(\\mathbf{X} | \\mathbf{Z},\\sigma_X, \\sigma_A) P(z_{ik} | \\mathbf{z_{-i,k}})$"
     ]
    }
   ],
   "metadata": {}
  }
 ]
}