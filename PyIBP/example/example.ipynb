{
 "metadata": {
  "signature": "sha256:8cee93c833bce2057b9e35b1fde2d25d9c0ebab01df401c1185e0cc233a250bb"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Run IBP on the synthetic 'Cambridge Bars' dataset\n",
      "\"\"\"\n",
      "import sys\n",
      "import cPickle as CP\n",
      "\n",
      "import numpy as NP\n",
      "import scipy.io as SPIO\n",
      "\n",
      "from PyIBP import PyIBP as IBP\n",
      "\n",
      "# IBP parameter (gamma hyperparameters)\n",
      "(alpha, alpha_a, alpha_b) = (1., 1., 1.)\n",
      "# Observed data Gaussian noise (Gamma hyperparameters)\n",
      "(sigma_x, sx_a, sx_b) = (1., 1., 1.)\n",
      "# Latent feature weight Gaussian noise (Gamma hyperparameters)\n",
      "(sigma_a, sa_a, sa_b) = (1., 1., 1.)\n",
      "\n",
      "# Number of full sampling sweeps\n",
      "numsamp = 5\n",
      "\n",
      "# Load the data\n",
      "matvals = SPIO.loadmat('block_image_set.mat')\n",
      "trueWeights = matvals['trueWeights']\n",
      "features = matvals['features']\n",
      "data = matvals['data']\n",
      "\n",
      "# Center the data\n",
      "(N,D) = data.shape\n",
      "cdata = IBP.centerData(data)\n",
      "\n",
      "# Initialize the model\n",
      "f = IBP(cdata,(alpha,alpha_a,alpha_b),\n",
      "        (sigma_x, sx_a, sx_b),\n",
      "        (sigma_a, sa_a, sa_b))\n",
      "\n",
      "# Do inference\n",
      "for s in range(numsamp):\n",
      "    # Print current chain state\n",
      "    f.sampleReport(s)\n",
      "    print 'Learned weights (rounded)'\n",
      "    for factor in NP.round(f.weights()).astype(NP.int):\n",
      "        print str(factor.reshape((6,6)))\n",
      "    print 'True weights'\n",
      "    for factor in trueWeights:\n",
      "        print str(factor.reshape((6,6)))    \n",
      "    # Take a new sample\n",
      "    f.fullSample()    \n",
      "\n",
      "# If matplotlib is installed, plot ground truth vs learned factors\n",
      "try:\n",
      "    import matplotlib.pyplot as P\n",
      "    from scaledimage import scaledimage\n",
      "except:\n",
      "    print 'matplotlib not installed, skipping visualization...'\n",
      "    sys.exit(0)\n",
      "\n",
      "# Intensity plots of\n",
      "# -ground truth factor-feature weights (top)\n",
      "# -learned factor-feature weights (bottom)\n",
      "K = max(len(trueWeights), len(f.weights()))\n",
      "(fig, subaxes) = P.subplots(2, K)\n",
      "for sa in subaxes.flatten():\n",
      "    sa.set_visible(False)\n",
      "fig.suptitle('Ground truth (top) vs learned factors (bottom)')\n",
      "for (idx, trueFactor) in enumerate(trueWeights):\n",
      "    ax = subaxes[0, idx]\n",
      "    ax.set_visible(True)\n",
      "    scaledimage(trueFactor.reshape(6,6),\n",
      "                pixwidth=3, ax=ax)\n",
      "for (idx, learnedFactor) in enumerate(f.weights()):\n",
      "    ax = subaxes[1, idx]    \n",
      "    scaledimage(learnedFactor.reshape(6,6),\n",
      "                pixwidth=3, ax=ax)\n",
      "    ax.set_visible(True)\n",
      "P.show()    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "iter 0\n",
        "\tcollapsed loglike = -39058.386590"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\tK = 10\n",
        "\talpha = 1.000000\n",
        "\tsigma_x = 1.000000\n",
        "\tsigma_a = 1.000000\n",
        "Learned weights (rounded)\n",
        "[[0 0 0 0 0 0]\n",
        " [0 0 0 0 0 0]\n",
        " [0 0 0 0 0 0]\n",
        " [0 0 0 0 0 0]\n",
        " [0 0 0 0 0 0]\n",
        " [0 0 0 0 0 0]]\n",
        "[[0 0 0 0 0 0]\n",
        " [0 0 0 0 0 0]\n",
        " [0 0 0 0 0 0]\n",
        " [0 0 0 0 0 0]\n",
        " [0 0 0 0 0 0]\n",
        " [0 0 0 0 0 0]]\n",
        "[[0 0 0 0 0 0]\n",
        " [0 0 0 0 0 0]\n",
        " [0 0 0 0 0 0]\n",
        " [0 0 0 0 0 0]\n",
        " [0 0 0 0 0 0]\n",
        " [0 0 0 0 0 0]]\n",
        "[[0 0 0 0 0 0]\n",
        " [0 0 0 0 0 0]\n",
        " [0 0 0 0 0 0]\n",
        " [0 0 0 0 0 0]\n",
        " [0 0 0 0 0 0]\n",
        " [0 0 0 0 0 0]]\n",
        "[[0 1 0 0 0 0]\n",
        " [0 1 0 0 0 0]\n",
        " [0 1 0 0 0 0]\n",
        " [0 0 0 0 0 0]\n",
        " [0 0 0 0 0 0]\n",
        " [0 0 0 0 0 0]]\n",
        "[[0 0 0 0 0 0]\n",
        " [0 0 0 0 0 0]\n",
        " [0 0 0 0 0 0]\n",
        " [0 0 0 0 0 0]\n",
        " [0 0 0 0 0 0]\n",
        " [0 0 0 0 0 0]]\n",
        "[[ 0  0  0  0  0  0]\n",
        " [ 0  0  0  0  0  0]\n",
        " [ 0  0  0  0  0  0]\n",
        " [ 0  0  0  0  0 -1]\n",
        " [ 0  0  0  0  0  0]\n",
        " [ 0  0  0  0  0  0]]\n",
        "[[0 0 0 0 0 0]\n",
        " [0 0 0 0 0 0]\n",
        " [0 0 0 0 0 0]\n",
        " [0 0 0 0 0 0]\n",
        " [0 0 0 0 0 0]\n",
        " [0 0 0 0 0 0]]\n",
        "[[0 0 0 0 0 0]\n",
        " [0 0 1 0 0 0]\n",
        " [0 0 0 0 0 0]\n",
        " [0 0 0 0 0 0]\n",
        " [0 0 0 0 0 0]\n",
        " [0 0 0 0 0 0]]\n",
        "[[0 0 0 0 0 0]\n",
        " [0 0 0 0 0 0]\n",
        " [0 0 0 0 0 0]\n",
        " [1 0 0 0 0 0]\n",
        " [1 0 0 0 0 0]\n",
        " [0 0 0 0 0 0]]\n",
        "True weights\n",
        "[[0 1 0 0 0 0]\n",
        " [1 1 1 0 0 0]\n",
        " [0 1 0 0 0 0]\n",
        " [0 0 0 0 0 0]\n",
        " [0 0 0 0 0 0]\n",
        " [0 0 0 0 0 0]]\n",
        "[[0 0 0 1 1 1]\n",
        " [0 0 0 1 0 1]\n",
        " [0 0 0 1 1 1]\n",
        " [0 0 0 0 0 0]\n",
        " [0 0 0 0 0 0]\n",
        " [0 0 0 0 0 0]]\n",
        "[[0 0 0 0 0 0]\n",
        " [0 0 0 0 0 0]\n",
        " [0 0 0 0 0 0]\n",
        " [1 0 0 0 0 0]\n",
        " [1 1 0 0 0 0]\n",
        " [1 1 1 0 0 0]]\n",
        "[[0 0 0 0 0 0]\n",
        " [0 0 0 0 0 0]\n",
        " [0 0 0 0 0 0]\n",
        " [0 0 0 1 1 1]\n",
        " [0 0 0 0 1 0]\n",
        " [0 0 0 0 1 0]]\n",
        "iter 1"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\tcollapsed loglike = -22894.834786\n",
        "\tK = 6\n",
        "\talpha = 0.495270\n",
        "\tsigma_x = 0.441871\n",
        "\tsigma_a = 0.227907\n",
        "Learned weights (rounded)\n",
        "[[0 0 0 0 0 0]\n",
        " [0 0 0 0 0 0]\n",
        " [0 0 0 0 0 0]\n",
        " [0 0 0 0 0 0]\n",
        " [0 0 0 0 0 0]\n",
        " [0 0 0 0 0 0]]\n",
        "[[0 0 0 0 0 0]\n",
        " [0 0 0 0 0 0]\n",
        " [0 0 0 0 0 0]\n",
        " [0 0 0 0 0 0]\n",
        " [0 0 0 0 0 0]\n",
        " [0 0 0 0 0 0]]\n",
        "[[0 0 0 0 0 0]\n",
        " [0 0 0 0 0 0]\n",
        " [0 0 0 0 0 0]\n",
        " [0 0 0 0 0 0]\n",
        " [0 0 0 0 0 0]\n",
        " [0 0 0 0 0 0]]\n",
        "[[0 0 0 0 0 0]\n",
        " [0 0 0 0 0 0]\n",
        " [0 0 0 0 0 0]\n",
        " [0 0 0 0 0 0]\n",
        " [0 0 0 0 0 0]\n",
        " [0 0 0 0 0 0]]\n",
        "[[0 0 0 0 0 0]\n",
        " [0 0 0 0 0 0]\n",
        " [0 0 0 0 0 0]\n",
        " [0 0 0 0 0 0]\n",
        " [0 0 0 0 0 0]\n",
        " [0 0 0 0 0 0]]\n",
        "[[0 0 0 0 0 0]\n",
        " [0 0 0 0 0 0]\n",
        " [0 0 0 0 0 0]\n",
        " [0 0 0 0 0 0]\n",
        " [0 0 0 0 0 0]\n",
        " [0 0 0 0 0 0]]\n",
        "True weights\n",
        "[[0 1 0 0 0 0]\n",
        " [1 1 1 0 0 0]\n",
        " [0 1 0 0 0 0]\n",
        " [0 0 0 0 0 0]\n",
        " [0 0 0 0 0 0]\n",
        " [0 0 0 0 0 0]]\n",
        "[[0 0 0 1 1 1]\n",
        " [0 0 0 1 0 1]\n",
        " [0 0 0 1 1 1]\n",
        " [0 0 0 0 0 0]\n",
        " [0 0 0 0 0 0]\n",
        " [0 0 0 0 0 0]]\n",
        "[[0 0 0 0 0 0]\n",
        " [0 0 0 0 0 0]\n",
        " [0 0 0 0 0 0]\n",
        " [1 0 0 0 0 0]\n",
        " [1 1 0 0 0 0]\n",
        " [1 1 1 0 0 0]]\n",
        "[[0 0 0 0 0 0]\n",
        " [0 0 0 0 0 0]\n",
        " [0 0 0 0 0 0]\n",
        " [0 0 0 1 1 1]\n",
        " [0 0 0 0 1 0]\n",
        " [0 0 0 0 1 0]]\n",
        "iter 2"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\tcollapsed loglike = -12522.089803\n",
        "\tK = 6\n",
        "\talpha = 1.612926\n",
        "\tsigma_x = 0.309111\n",
        "\tsigma_a = 0.261030\n",
        "Learned weights (rounded)\n",
        "[[0 0 0 0 1 0]\n",
        " [0 0 0 0 0 0]\n",
        " [0 0 0 0 0 1]\n",
        " [0 0 0 0 0 0]\n",
        " [0 0 0 0 0 0]\n",
        " [0 0 0 0 0 0]]\n",
        "[[0 0 0 0 0 0]\n",
        " [0 0 0 0 0 0]\n",
        " [0 0 0 0 0 0]\n",
        " [1 0 0 0 0 0]\n",
        " [1 1 0 0 0 0]\n",
        " [1 1 1 0 0 0]]\n",
        "[[ 0  0  0  0  0  0]\n",
        " [ 0  0  0  0  0  0]\n",
        " [ 0  0  0  0  0  0]\n",
        " [ 0  0  0 -1 -1 -1]\n",
        " [ 0  0  0  0 -1  0]\n",
        " [ 0  0  0  0 -1  0]]\n",
        "[[0 0 0 0 0 0]\n",
        " [0 0 0 0 0 0]\n",
        " [0 0 0 0 0 0]\n",
        " [0 0 0 0 0 0]\n",
        " [0 0 0 0 0 0]\n",
        " [0 0 0 0 0 0]]\n",
        "[[ 0 -1  0  0  0  0]\n",
        " [-1 -1  0  0  0  0]\n",
        " [ 0 -1  0  0  0  0]\n",
        " [ 0  0  0  0  0  0]\n",
        " [ 0  0  0  0  0  0]\n",
        " [ 0  0  0  0  0  0]]\n",
        "[[0 1 0 0 0 0]\n",
        " [1 1 1 0 0 0]\n",
        " [0 1 0 0 0 0]\n",
        " [0 0 0 0 0 0]\n",
        " [0 0 0 0 0 0]\n",
        " [0 0 0 0 0 0]]\n",
        "True weights\n",
        "[[0 1 0 0 0 0]\n",
        " [1 1 1 0 0 0]\n",
        " [0 1 0 0 0 0]\n",
        " [0 0 0 0 0 0]\n",
        " [0 0 0 0 0 0]\n",
        " [0 0 0 0 0 0]]\n",
        "[[0 0 0 1 1 1]\n",
        " [0 0 0 1 0 1]\n",
        " [0 0 0 1 1 1]\n",
        " [0 0 0 0 0 0]\n",
        " [0 0 0 0 0 0]\n",
        " [0 0 0 0 0 0]]\n",
        "[[0 0 0 0 0 0]\n",
        " [0 0 0 0 0 0]\n",
        " [0 0 0 0 0 0]\n",
        " [1 0 0 0 0 0]\n",
        " [1 1 0 0 0 0]\n",
        " [1 1 1 0 0 0]]\n",
        "[[0 0 0 0 0 0]\n",
        " [0 0 0 0 0 0]\n",
        " [0 0 0 0 0 0]\n",
        " [0 0 0 1 1 1]\n",
        " [0 0 0 0 1 0]\n",
        " [0 0 0 0 1 0]]\n"
       ]
      },
      {
       "ename": "KeyboardInterrupt",
       "evalue": "",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-1-37e2db05d7df>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     46\u001b[0m         \u001b[1;32mprint\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfactor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[1;31m# Take a new sample\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 48\u001b[1;33m     \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfullSample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[1;31m# If matplotlib is installed, plot ground truth vs learned factors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/home/bitnami/STA663-Christine-Chai-Final-Project/PyIBP/example/PyIBP.pyc\u001b[0m in \u001b[0;36mfullSample\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    119\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfullSample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m         \u001b[1;34m\"\"\" Do all applicable samples \"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 121\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msampleZ\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    122\u001b[0m         \u001b[1;32mif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmissing\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    123\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msampleX\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/home/bitnami/STA663-Christine-Chai-Final-Project/PyIBP/example/PyIBP.pyc\u001b[0m in \u001b[0;36msampleZ\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    269\u001b[0m             \u001b[1;33m(\u001b[0m\u001b[0mmeanA\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcovarA\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfromInfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minfoA\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mhA\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    270\u001b[0m             \u001b[1;31m# Remove this data point from feature cts\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 271\u001b[1;33m             \u001b[0mnewcts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mm\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mZV\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mNP\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    272\u001b[0m             \u001b[1;31m# Log collapsed Beta-Bernoulli terms\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    273\u001b[0m             \u001b[0mlpz1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mNP\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnewcts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
       ]
      }
     ],
     "prompt_number": 1
    }
   ],
   "metadata": {}
  }
 ]
}