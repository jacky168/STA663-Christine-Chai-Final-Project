{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 0\n",
      "\tcollapsed loglike = -38531.736033\n",
      "\tK = 7\n",
      "\talpha = 1.000000\n",
      "\tsigma_x = 1.000000\n",
      "\tsigma_a = 1.000000\n",
      "Learned weights (rounded)\n",
      "[[0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]]\n",
      "[[0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]]\n",
      "[[0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]]\n",
      "[[0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]]\n",
      "[[0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]]\n",
      "[[0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]]\n",
      "[[0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]]\n",
      "True weights\n",
      "[[0 1 0 0 0 0]\n",
      " [1 1 1 0 0 0]\n",
      " [0 1 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]]\n",
      "[[0 0 0 1 1 1]\n",
      " [0 0 0 1 0 1]\n",
      " [0 0 0 1 1 1]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]]\n",
      "[[0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0]\n",
      " [1 1 0 0 0 0]\n",
      " [1 1 1 0 0 0]]\n",
      "[[0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 1 1 1]\n",
      " [0 0 0 0 1 0]\n",
      " [0 0 0 0 1 0]]\n",
      "iter 1\n",
      "\tcollapsed loglike = -22732.084976\n",
      "\tK = 4\n",
      "\talpha = 1.104189\n",
      "\tsigma_x = 0.441467\n",
      "\tsigma_a = 0.347428\n",
      "Learned weights (rounded)\n",
      "[[0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]]\n",
      "[[0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]]\n",
      "[[0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]]\n",
      "[[0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]]\n",
      "True weights\n",
      "[[0 1 0 0 0 0]\n",
      " [1 1 1 0 0 0]\n",
      " [0 1 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]]\n",
      "[[0 0 0 1 1 1]\n",
      " [0 0 0 1 0 1]\n",
      " [0 0 0 1 1 1]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]]\n",
      "[[0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0]\n",
      " [1 1 0 0 0 0]\n",
      " [1 1 1 0 0 0]]\n",
      "[[0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 1 1 1]\n",
      " [0 0 0 0 1 0]\n",
      " [0 0 0 0 1 0]]\n",
      "iter 2\n",
      "\tcollapsed loglike = -14583.072385\n",
      "\tK = 4\n",
      "\talpha = 1.414968\n",
      "\tsigma_x = 0.335380\n",
      "\tsigma_a = 0.340036\n",
      "Learned weights (rounded)\n",
      "[[0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]]\n",
      "[[0 0 0 0 1 1]\n",
      " [0 0 0 1 0 1]\n",
      " [0 0 0 1 0 1]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]]\n",
      "[[0 1 0 0 0 0]\n",
      " [1 1 1 0 0 0]\n",
      " [0 1 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]]\n",
      "[[0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0]\n",
      " [1 1 0 0 0 0]\n",
      " [1 1 1 0 0 0]]\n",
      "True weights\n",
      "[[0 1 0 0 0 0]\n",
      " [1 1 1 0 0 0]\n",
      " [0 1 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]]\n",
      "[[0 0 0 1 1 1]\n",
      " [0 0 0 1 0 1]\n",
      " [0 0 0 1 1 1]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]]\n",
      "[[0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0]\n",
      " [1 1 0 0 0 0]\n",
      " [1 1 1 0 0 0]]\n",
      "[[0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 1 1 1]\n",
      " [0 0 0 0 1 0]\n",
      " [0 0 0 0 1 0]]\n",
      "iter 3\n",
      "\tcollapsed loglike = -7334.547766\n",
      "\tK = 5\n",
      "\talpha = 1.779074\n",
      "\tsigma_x = 0.269595\n",
      "\tsigma_a = 0.360029\n",
      "Learned weights (rounded)\n",
      "[[0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]]\n",
      "[[0 0 0 1 1 1]\n",
      " [0 0 0 1 0 1]\n",
      " [0 0 0 1 1 1]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]]\n",
      "[[0 1 0 0 0 0]\n",
      " [1 1 1 0 0 0]\n",
      " [0 1 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]]\n",
      "[[0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0]\n",
      " [1 1 0 0 0 0]\n",
      " [1 1 1 0 0 0]]\n",
      "[[0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 1 1 1]\n",
      " [0 0 0 0 1 0]\n",
      " [0 0 0 0 1 0]]\n",
      "True weights\n",
      "[[0 1 0 0 0 0]\n",
      " [1 1 1 0 0 0]\n",
      " [0 1 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]]\n",
      "[[0 0 0 1 1 1]\n",
      " [0 0 0 1 0 1]\n",
      " [0 0 0 1 1 1]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]]\n",
      "[[0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0]\n",
      " [1 1 0 0 0 0]\n",
      " [1 1 1 0 0 0]]\n",
      "[[0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 1 1 1]\n",
      " [0 0 0 0 1 0]\n",
      " [0 0 0 0 1 0]]\n",
      "iter 4\n",
      "\tcollapsed loglike = 1703.800951\n",
      "\tK = 5\n",
      "\talpha = 2.038614\n",
      "\tsigma_x = 0.208147\n",
      "\tsigma_a = 0.336164\n",
      "Learned weights (rounded)\n",
      "[[0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]]\n",
      "[[0 0 0 1 1 1]\n",
      " [0 0 0 1 0 1]\n",
      " [0 0 0 1 1 1]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]]\n",
      "[[0 1 0 0 0 0]\n",
      " [1 1 1 0 0 0]\n",
      " [0 1 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]]\n",
      "[[0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0]\n",
      " [1 1 0 0 0 0]\n",
      " [1 1 1 0 0 0]]\n",
      "[[0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 1 1 1]\n",
      " [0 0 0 0 1 0]\n",
      " [0 0 0 0 1 0]]\n",
      "True weights\n",
      "[[0 1 0 0 0 0]\n",
      " [1 1 1 0 0 0]\n",
      " [0 1 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]]\n",
      "[[0 0 0 1 1 1]\n",
      " [0 0 0 1 0 1]\n",
      " [0 0 0 1 1 1]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]]\n",
      "[[0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0]\n",
      " [1 1 0 0 0 0]\n",
      " [1 1 1 0 0 0]]\n",
      "[[0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 1 1 1]\n",
      " [0 0 0 0 1 0]\n",
      " [0 0 0 0 1 0]]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Run IBP on the synthetic 'Cambridge Bars' dataset\n",
    "\"\"\"\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "# matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as P\n",
    "from scaledimage import scaledimage\n",
    "\n",
    "import sys\n",
    "import cPickle as CP\n",
    "\n",
    "import numpy as NP\n",
    "import scipy.io as SPIO\n",
    "\n",
    "from PyIBP import PyIBP as IBP\n",
    "\n",
    "# IBP parameter (gamma hyperparameters)\n",
    "(alpha, alpha_a, alpha_b) = (1., 1., 1.)\n",
    "# Observed data Gaussian noise (Gamma hyperparameters)\n",
    "(sigma_x, sx_a, sx_b) = (1., 1., 1.)\n",
    "# Latent feature weight Gaussian noise (Gamma hyperparameters)\n",
    "(sigma_a, sa_a, sa_b) = (1., 1., 1.)\n",
    "\n",
    "# Number of full sampling sweeps\n",
    "numsamp = 5\n",
    "\n",
    "# Load the data\n",
    "matvals = SPIO.loadmat('block_image_set.mat')\n",
    "trueWeights = matvals['trueWeights']\n",
    "features = matvals['features']\n",
    "data = matvals['data']\n",
    "\n",
    "# Center the data\n",
    "(N,D) = data.shape\n",
    "cdata = IBP.centerData(data)\n",
    "\n",
    "# Initialize the model\n",
    "f = IBP(cdata,(alpha,alpha_a,alpha_b),\n",
    "        (sigma_x, sx_a, sx_b),\n",
    "        (sigma_a, sa_a, sa_b))\n",
    "\n",
    "# Do inference\n",
    "for s in range(numsamp):\n",
    "    # Print current chain state\n",
    "    f.sampleReport(s)\n",
    "    print 'Learned weights (rounded)'\n",
    "    for factor in NP.round(f.weights()).astype(NP.int):\n",
    "        print str(factor.reshape((6,6)))\n",
    "    print 'True weights'\n",
    "    for factor in trueWeights:\n",
    "        print str(factor.reshape((6,6)))    \n",
    "    # Take a new sample\n",
    "    f.fullSample()    \n",
    "\n",
    "# If matplotlib is installed, plot ground truth vs learned factors\n",
    "# try:\n",
    "#     import matplotlib.pyplot as P\n",
    "#     from scaledimage import scaledimage\n",
    "# except:\n",
    "#     print 'matplotlib not installed, skipping visualization...'\n",
    "#     sys.exit(0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV0AAADuCAYAAACaodTYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAEH1JREFUeJzt3X2wXVV5x/HvkxASCG8hkGCsGIXBVqZaFWgrWrU4nWlh\nIik4htJgHFvfq1SnTmc6jvZlWt9GHLXFWjuE8QUCUhmZai1GfCnRooQQQKWtUrSDDQ5NCAlJyMvq\nH3tdsnM49551481zQ/L9zGTYZ5+1115nrXN+d5999mJHKQVJUo4Z090ASTqcGLqSlMjQlaREhq4k\nJTJ0JSmRoStJiQ7p0I2IhRHx2Yj4YUR8NyLWRMSFyW1YHBF3DVn/9Ii4ZD/rvDwijuo93tK43QUR\n8Z66fGFE/NL+7L9uvyQi3rW/249T59C+mi7j9WtEvDUivhcRn9qPOvcZu6k0ML4rI+KiSWz73Ij4\n7d7jl0TEr09h21ZHxLFTVd+T2SEbuhERwI3A10opp5VSzgKWAb8wpOwR2e0DngH83rAnGtrzNuDo\n3uPWi63fAVxZly8Ent243TA3ARdFxKyfo44DIqopqGq8fn0j8PJSyvL9qHNw7EaKiNbPaX98J3sB\n/vOA3+k9fhnwwknWMZFrgT+cwvqevEoph+Q/4Dy6wB3v+RXAF4DVwC3APLqQvhP4FvDLtdx7gHf0\ntrsbOBVYDHwf+ERd92VgTi3zglrPOuD9wF1D9v9tYBNwB3A58Opee74GvAS4qVf+Y7XMHwE7gPXA\n6vrcI8Bf1f19C1gwZH9PA26tyy8EHgJ+VPf/TOBXapvuBP4JOKGW/Rrw4VruLuDsXp1XAucP7GcG\ncB9wfG/dfwAnA6+sdawDvj6kjYvH+gqYCXwAuK226XV1/THAV4Dbax8s6W17L3B1HY/fmGB8TgO+\nBHwX+AbwrLr+GbX/1tf+fGRIGz/e6//LgbOBNcBa4FbgjF77P1hf753AW8YZu0vq47uA9/b2s6Vu\nvw44F3gvcE+t6wMTjW99fFUdn+/Ufjm/rp9Tn1tf2/xSYBbwY+DBOs7vBH4K/E99fG7t36/W/X8F\neFqtbyXwd7Xffljruxr4HnBVrz0LgdumOxcOhn/T3oAD9sLgrcCHJnh+BfAT9obLR4F31eWXAXfU\n5Xezb+jexd7Q3Qk8p65fBVxal9cDL6rL44XuYKgOtuelA89/FLisLt8HnNh7bk/vQ/U+4M+G7G8Z\n8NHe46uA3+09Xg+8uC7/OXBFXb4F+Pu6/OL+awFeA7xvyL4+DKyoy78K/GtvH0+py8cN2W4xe0P3\ndWOvA5hNFx6L6cLs2Lr+JOA/e9vuBs7pPR5vfFYDp/faNxaAXwB+vy6/iSGhO9j/wLHAzLr8cuBz\ndfmNwHXAjPp43pBtFwH3A/Pr61oNvKI3phfX5fnAD3r7H9Z3g+O7EvhiXT6d7r01m+5o+JN1/bPq\n/mfT/UH/SG/7dwNv7z2+CVjeG/fP9/bz2bq8BNgMnAkE3R+15/bq+BEwd7qzYbr/HbKnFxj4ehUR\nH4uIdRFxW2/1zaWUTXX5XOBTAKWUW4D5Deeg7iulrK/LtwOLI+J4uqO8f6vrxzvvN/j1t9CF06Zh\nhUd4rJTyz/12DClzKt3RyxPa0GvzN+v6q+mOFMdcA1CfPy4ijqvrHxhnX6uAV9XlZfUxdEeCV0fE\nHwCjTqH8FnBZRNxBdwR+Il14BPA3EXEncDOwKCIW1G3uL6X0x3fY+MylO9K/vtb9ceCUWuaFY68V\n+PSI9o05AfhcPRf9IfaesjmP7o/VHoBSysYh254N3FJKeaiUshv4DHv7fTdwQ11+GNgeEf8YEUuB\nbUPqGhzfQhf6lFL+iy7wfpHuff7puv5eutA9o24z+J7sP/414LN1+dPAi3r7uaku3w38bynlntKl\n7D3s+/7YQHdEflibjnOZWe4BHv8hoZTyloiYT/fXd8zWgW2GnQfcxb7nvuf0lnf0lncDw34gmcy5\nxUcn2O9EP77s7C3vYfxxHRb0LeUGjW03Y5w6vg2cHhEnAa8A/gKglPLGiDgHOB+4PSJeUEr5vwn2\n85ZSys37NCxiBd0R7vNLKbsj4j72jsngeA6Oz5za5o2llOeNeI2t/pLuSHlpRCym+2bweHNHbFsG\nygR7+3N7DS5KKbtqv50HXEx3quK8IfW1jtv+nu8eb7vH6n/3sG+fD74X+6/vsHXIHumWUr4KzImI\nN/RWz51gk28ClwJExEuBn5VSHgH+G3h+Xf98uvN+E+33YWBTRJxbV106TtHNdF9Nxwy+oe8Hnh0R\nR0bECcBv9p57BDiOybmfvUd0+9RR27wxIsaOXpbTncsda9erAOrzm2q/ADyl1ruPGhafB64Avjd2\nlBcRp5VSbiulvBv4GUN+1Oz5MvCmsR8VI+KMiDi6tvnBGrgvA57e3gVEbft9EXFxrTci4jn1+Vvp\njsxh/HEbdBzdET90p4jG3Ay8PiJm1v3Mq+v7Y/cd4CURMb+WWwZ8/QmN7o7OTyilfAl4O/DcIe0Y\nHN8AXllf32l05+1/wL7v8zPojpB/UNvVfz8OPl7Dvn3zjSFtGGUh3Xniw9ohG7rVhXRv6h9FxL/T\nnX96Z32usO9f3fcAL6hfW/+a7hwXdF/xToyIu4E30/0oQa8Ohjx+DfC39evrsHLQnd/cXU95XD7Y\nnlLKT+i+Ht5N9/V8bW/bTwD/EhGrh9Q/+LrG3Er941FdC/xJRNweEc+sr/cD9fU/h3p0WuvaHhFr\n6X4weW2vjnMY/8O3iu7Duaq37v0Rsb5+Fb+199W/b6ztn6T7MWZtLX8l3XnPzwBnRcR6uj8O3x+y\n7ajHlwKvjYh1dP27pK5/G/DmWveiIdsPq/f9dKc71tb29dv/Y2B93c/Y5YGPj10p5afAn9IdHa8D\nvltKGfuq3t/HscBNdWy+CfzxkDYNjm+p+78N+CLw+lLKY3RjOKO+xmuBV5dSdtY2PDsi7oiIV9Kd\nMlhaH59L9yPga2obLq19Naw/hvZ5RJwCPFRKGfw2ctiJ+g1Gh4GI+Crdj0mD53Yn2uYWuh8S1w6s\nn0H3h+CsUsquqW2p9sf+jG+WiHgd3Y9oV0x3W6bboX6kq319EHjDyFJtLqD7pd7APXhM5fhOtVcB\n/zDdjTgYeKQrSYk80pWkRIauJCUydCUpkaErSYkMXUlKZOhKUiJDV5ISGbqSlMjQlaREhq4kJTJ0\nJSmRoStJiQxdSUpk6EpSIkNXkhIZupKUyNCVpESGriQlMnQlKZGhK0mJDF1JSmToSlIiQ1eSEhm6\nkpTI0JWkRIauJCUydCUpkaErSYkMXUlKZOhKUiJDV5ISGbqSlMjQlaRER0z0ZESUrIZMt1JKtJSz\nT4Y7XPrFPhluMv1yuJswdFuV0vbeinBc9kdr/04lx0o6MDy9IEmJDF1JSmToSlIiQ1eSEhm6kpTI\n0JWkRIauJCUaeZ3uVF4j2lKX14fuv9a+m47rfiV1PNKVpESGriQlMnQlKZGhK0mJDF1JSmToSlIi\nQ1eSEhm6kpTI0JWkRCNnpLXMcvLOEQcHZ5pJBz+PdCUpkaErSYkMXUlKZOhKUiJDV5ISGbqSlMjQ\nlaREhq4kJTJ0JSnRyBlpLZxpdmA9WfrXe+BNv+mYleiYTo5HupKUyNCVpESGriQlMnQlKZGhK0mJ\nDF1JSmToSlIiQ1eSEk3J5AiplRMoDqzWvvMWW9PHI11JSmToSlIiQ1eSEhm6kpTI0JWkRIauJCUy\ndCUpkaErSYkMXUlK5Iw0HXScLaVDmUe6kpTI0JWkRIauJCUydCUpkaErSYkMXUlKZOhKUiJDV5IS\nGbqSlMgZaZoyzhB78nCspk+0TrmUJP38PL0gSYkMXUlKZOhKUiJDV5ISGbqSlMjQlaREhq4kJTJ0\nJSmRoStJiQxdSUpk6EpSIkNXkhIZupKUyNCVpESGriQlMnQlKZGhK0mJDF1JSmToSlIiQ1eSEhm6\nkpTI0JWkRIauJCUydCUpkaErSYkMXUlKZOhKUiJDV5ISGbqSlMjQlaREhq4kJTJ0JSmRoStJiQxd\nSUpk6EpSIkNXkhIZupKUyNCVpESGriQlMnQlKZGhK0mJDF1JSmToSlIiQ1eSEhm6kpTI0JWkRIau\nJCUydCUpkaErSYkMXUlKZOhKUiJDV5ISGbqSlMjQlaREhq4kJTJ0JSmRoStJiQxdSUpk6EpSIkNX\nkhIZupKUyNCVpERHTPRkRJSshky3Ukq0lLNPhjtc+sU+Gc7PzxON1ycThm7dcGTlZ555ZlMj1qxZ\nM7LMokWLmuravn17U7njjz9+ZJmNGzc21TVm+fLlI8usWrWqqa6LLrpoZJmrrrqqqa4jjhg5nADM\nnDlzZJmI5mx53IwZo784tYxby5gB7Ny5s6ncnj17mspl1TOoZTwAZs2aNWX73LFjR1O5ls//ZLW8\n3t27dzfV1fKea30vH3300U3ltmzZMrLMRP3m6QVJSmToSlIiQ1eSEhm6kpTI0JWkRIauJCUydCUp\nUUx0PVlElHnz5o2spPW6yq1bt05JGYANGzY0lXvqU586sszmzZsndXH37NmzR5Zrvb6x5drLTZs2\nNdW1YsWKpnIrV64cWWbWrFmTngjQ8ppbrtM98sgjm/bZWq7lutBdu3aNLLNnz55J90nLe6X1+t+W\n601br0lt3WfrtdBT/flp1TJurZ/Flmt+oe16+O3bt4/bJx7pSlIiQ1eSEhm6kpTI0JWkRIauJCUy\ndCUpkaErSYkMXUlKZOhKUqKRUytaZn6deuqpTTu79957R5Y56aSTmupasGBBU7nW/yv/ZCxdunRk\nmRtvvLGprgsuuGBkmdaZMq13mNifu0JMVb0ts4OmcsYStM2+aunj/blzRMvrba13Kme3tZqqMZ1s\nnS0zzaBtdljrXShaPxetbRuPR7qSlMjQlaREhq4kJTJ0JSmRoStJiQxdSUpk6EpSIkNXkhIZupKU\naOR0jvnz54+s5MEHH2zaWcv9lo455pimulpn3kz1DB2A66+/fmSZZcuWNdXVMlum9V5grTPXWmfo\nTFZLO1va2Po6WmdCtZQ7ULP0Wu75d9RRRzXV1dIvLfegg7Z788HU3V+ur2U8WmaaQdt7+bHHHmuq\nq/V+cC3v84neTx7pSlIiQ1eSEhm6kpTI0JWkRIauJCUydCUpkaErSYkMXUlKFBNdqBwRZeHChSMr\n2bx5c9POHnjggeaGjXLyySdP2T4XLFhAKaXp6viIKHPmzBlZrnVSxpIlS0aWaZ0scN111zWVu+SS\nS0aWueaaa5r7BLp+aZlgMHfu3JFlWi+2by3XcjF7ywX727Ztm3SfPProoyPLtU5WOeWUU0aWaX3f\ntU4EaBnTnTt3Turz0zLxoXXyRkvftda1ZcuWpnItE7i2bt06bp94pCtJiQxdSUpk6EpSIkNXkhIZ\nupKUyNCVpESGriQlMnQlKZGhK0mJRk4Nefjhh0dW0joLZvHixSPLbNiwoamu1tlIrbf/mYyW2Tyt\nt5K54YYbRpa57LLLmupqnXnTOsNtslpuO9M6E6pF60yubdu2jSwze/bsn7c5Q7X0Sevnp2XmZ+t7\noGVWJcCOHTuayk1Gy+ttvX1SS12tt+tp1XpLpPF4pCtJiQxdSUpk6EpSIkNXkhIZupKUyNCVpESG\nriQlMnQlKZGhK0mJRt4jLbEt02oy93g60G05WEz2fmAHsi0HC/tkOD8/TzRen0wYupKkqeXpBUlK\nZOhKUiJDV5ISGbqSlMjQlaRE/w+5Z73IX2krsgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f8947368f10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Intensity plots of\n",
    "# -ground truth factor-feature weights (top)\n",
    "# -learned factor-feature weights (bottom)\n",
    "K = max(len(trueWeights), len(f.weights()))\n",
    "(fig, subaxes) = P.subplots(2, K)\n",
    "for sa in subaxes.flatten():\n",
    "    sa.set_visible(False)\n",
    "fig.suptitle('Ground truth (top) vs learned factors (bottom)')\n",
    "for (idx, trueFactor) in enumerate(trueWeights):\n",
    "    ax = subaxes[0, idx]\n",
    "    ax.set_visible(True)\n",
    "    scaledimage(trueFactor.reshape(6,6),\n",
    "                pixwidth=3, ax=ax)\n",
    "for (idx, learnedFactor) in enumerate(f.weights()):\n",
    "    ax = subaxes[1, idx]    \n",
    "    scaledimage(learnedFactor.reshape(6,6),\n",
    "                pixwidth=3, ax=ax)\n",
    "    ax.set_visible(True)\n",
    "P.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
