{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 0\n",
      "\tcollapsed loglike = -38908.993048\n",
      "\tK = 7\n",
      "\talpha = 1.000000\n",
      "\tsigma_x = 1.000000\n",
      "\tsigma_a = 1.000000\n",
      "Learned weights (rounded)\n",
      "[[0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]]\n",
      "[[0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]]\n",
      "[[0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]]\n",
      "[[0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]]\n",
      "[[0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]]\n",
      "[[0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]]\n",
      "[[0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0]]\n",
      "True weights\n",
      "[[0 1 0 0 0 0]\n",
      " [1 1 1 0 0 0]\n",
      " [0 1 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]]\n",
      "[[0 0 0 1 1 1]\n",
      " [0 0 0 1 0 1]\n",
      " [0 0 0 1 1 1]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]]\n",
      "[[0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0]\n",
      " [1 1 0 0 0 0]\n",
      " [1 1 1 0 0 0]]\n",
      "[[0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 1 1 1]\n",
      " [0 0 0 0 1 0]\n",
      " [0 0 0 0 1 0]]\n",
      "iter 1\n",
      "\tcollapsed loglike = -22984.729250\n",
      "\tK = 4\n",
      "\talpha = 1.412467\n",
      "\tsigma_x = 0.437796\n",
      "\tsigma_a = 0.175031\n",
      "Learned weights (rounded)\n",
      "[[0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]]\n",
      "[[0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]]\n",
      "[[0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]]\n",
      "[[0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]]\n",
      "True weights\n",
      "[[0 1 0 0 0 0]\n",
      " [1 1 1 0 0 0]\n",
      " [0 1 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]]\n",
      "[[0 0 0 1 1 1]\n",
      " [0 0 0 1 0 1]\n",
      " [0 0 0 1 1 1]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]]\n",
      "[[0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0]\n",
      " [1 1 0 0 0 0]\n",
      " [1 1 1 0 0 0]]\n",
      "[[0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 1 1 1]\n",
      " [0 0 0 0 1 0]\n",
      " [0 0 0 0 1 0]]\n",
      "iter 2\n",
      "\tcollapsed loglike = -10948.515446\n",
      "\tK = 4\n",
      "\talpha = 1.759941\n",
      "\tsigma_x = 0.302482\n",
      "\tsigma_a = 0.346689\n",
      "Learned weights (rounded)\n",
      "[[0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]]\n",
      "[[0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0]\n",
      " [1 1 0 0 0 0]\n",
      " [1 1 1 0 0 0]]\n",
      "[[ 0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0]\n",
      " [ 0  0  0 -1 -1 -1]\n",
      " [ 0  0  0  0 -1  0]\n",
      " [ 0  0  0  0 -1  0]]\n",
      "[[0 0 0 1 1 1]\n",
      " [0 0 0 1 0 1]\n",
      " [0 0 0 1 1 1]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]]\n",
      "True weights\n",
      "[[0 1 0 0 0 0]\n",
      " [1 1 1 0 0 0]\n",
      " [0 1 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]]\n",
      "[[0 0 0 1 1 1]\n",
      " [0 0 0 1 0 1]\n",
      " [0 0 0 1 1 1]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]]\n",
      "[[0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0]\n",
      " [1 1 0 0 0 0]\n",
      " [1 1 1 0 0 0]]\n",
      "[[0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 1 1 1]\n",
      " [0 0 0 0 1 0]\n",
      " [0 0 0 0 1 0]]\n",
      "iter 3\n",
      "\tcollapsed loglike = -8051.358081\n",
      "\tK = 4\n",
      "\talpha = 1.935577\n",
      "\tsigma_x = 0.278893\n",
      "\tsigma_a = 0.333456\n",
      "Learned weights (rounded)\n",
      "[[0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]]\n",
      "[[0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0]\n",
      " [1 1 0 0 0 0]\n",
      " [1 1 1 0 0 0]]\n",
      "[[ 0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0]\n",
      " [ 0  0  0 -1 -1 -1]\n",
      " [ 0  0  0  0 -1  0]\n",
      " [ 0  0  0  0 -1  0]]\n",
      "[[0 0 0 1 1 1]\n",
      " [0 0 0 1 0 1]\n",
      " [0 0 0 1 1 1]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]]\n",
      "True weights\n",
      "[[0 1 0 0 0 0]\n",
      " [1 1 1 0 0 0]\n",
      " [0 1 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]]\n",
      "[[0 0 0 1 1 1]\n",
      " [0 0 0 1 0 1]\n",
      " [0 0 0 1 1 1]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]]\n",
      "[[0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0]\n",
      " [1 1 0 0 0 0]\n",
      " [1 1 1 0 0 0]]\n",
      "[[0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 1 1 1]\n",
      " [0 0 0 0 1 0]\n",
      " [0 0 0 0 1 0]]\n",
      "iter 4\n",
      "\tcollapsed loglike = -7624.776947\n",
      "\tK = 4\n",
      "\talpha = 1.950735\n",
      "\tsigma_x = 0.273373\n",
      "\tsigma_a = 0.374703\n",
      "Learned weights (rounded)\n",
      "[[0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]]\n",
      "[[0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0]\n",
      " [1 1 0 0 0 0]\n",
      " [1 1 1 0 0 0]]\n",
      "[[ 0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0]\n",
      " [ 0  0  0 -1 -1 -1]\n",
      " [ 0  0  0  0 -1  0]\n",
      " [ 0  0  0  0 -1  0]]\n",
      "[[0 0 0 1 1 1]\n",
      " [0 0 0 1 0 1]\n",
      " [0 0 0 1 1 1]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]]\n",
      "True weights\n",
      "[[0 1 0 0 0 0]\n",
      " [1 1 1 0 0 0]\n",
      " [0 1 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]]\n",
      "[[0 0 0 1 1 1]\n",
      " [0 0 0 1 0 1]\n",
      " [0 0 0 1 1 1]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]]\n",
      "[[0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0]\n",
      " [1 1 0 0 0 0]\n",
      " [1 1 1 0 0 0]]\n",
      "[[0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 1 1 1]\n",
      " [0 0 0 0 1 0]\n",
      " [0 0 0 0 1 0]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV0AAAD2CAYAAAB1JFQuAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f894d6df650>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Run IBP on the synthetic 'Cambridge Bars' dataset\n",
    "\"\"\"\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "# matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as P\n",
    "from scaledimage import scaledimage\n",
    "\n",
    "import sys\n",
    "import cPickle as CP\n",
    "\n",
    "import numpy as NP\n",
    "import scipy.io as SPIO\n",
    "\n",
    "from PyIBP import PyIBP as IBP\n",
    "\n",
    "# IBP parameter (gamma hyperparameters)\n",
    "(alpha, alpha_a, alpha_b) = (1., 1., 1.)\n",
    "# Observed data Gaussian noise (Gamma hyperparameters)\n",
    "(sigma_x, sx_a, sx_b) = (1., 1., 1.)\n",
    "# Latent feature weight Gaussian noise (Gamma hyperparameters)\n",
    "(sigma_a, sa_a, sa_b) = (1., 1., 1.)\n",
    "\n",
    "# Number of full sampling sweeps\n",
    "numsamp = 5\n",
    "\n",
    "# Load the data\n",
    "matvals = SPIO.loadmat('block_image_set.mat')\n",
    "trueWeights = matvals['trueWeights']\n",
    "features = matvals['features']\n",
    "data = matvals['data']\n",
    "\n",
    "# Center the data\n",
    "(N,D) = data.shape\n",
    "cdata = IBP.centerData(data)\n",
    "\n",
    "# Initialize the model\n",
    "f = IBP(cdata,(alpha,alpha_a,alpha_b),\n",
    "        (sigma_x, sx_a, sx_b),\n",
    "        (sigma_a, sa_a, sa_b))\n",
    "\n",
    "# Do inference\n",
    "for s in range(numsamp):\n",
    "    # Print current chain state\n",
    "    f.sampleReport(s)\n",
    "    print 'Learned weights (rounded)'\n",
    "    for factor in NP.round(f.weights()).astype(NP.int):\n",
    "        print str(factor.reshape((6,6)))\n",
    "    print 'True weights'\n",
    "    for factor in trueWeights:\n",
    "        print str(factor.reshape((6,6)))    \n",
    "    # Take a new sample\n",
    "    f.fullSample()    \n",
    "\n",
    "# If matplotlib is installed, plot ground truth vs learned factors\n",
    "# try:\n",
    "#     import matplotlib.pyplot as P\n",
    "#     from scaledimage import scaledimage\n",
    "# except:\n",
    "#     print 'matplotlib not installed, skipping visualization...'\n",
    "#     sys.exit(0)\n",
    "\n",
    "# Intensity plots of\n",
    "# -ground truth factor-feature weights (top)\n",
    "# -learned factor-feature weights (bottom)\n",
    "K = max(len(trueWeights), len(f.weights()))\n",
    "(fig, subaxes) = P.subplots(2, K)\n",
    "for sa in subaxes.flatten():\n",
    "    sa.set_visible(False)\n",
    "fig.suptitle('Ground truth (top) vs learned factors (bottom)')\n",
    "for (idx, trueFactor) in enumerate(trueWeights):\n",
    "    ax = subaxes[0, idx]\n",
    "    ax.set_visible(True)\n",
    "    scaledimage(trueFactor.reshape(6,6),\n",
    "                pixwidth=3, ax=ax)\n",
    "for (idx, learnedFactor) in enumerate(f.weights()):\n",
    "    ax = subaxes[1, idx]    \n",
    "    scaledimage(learnedFactor.reshape(6,6),\n",
    "                pixwidth=3, ax=ax)\n",
    "    ax.set_visible(True)\n",
    "P.savefig('PyIBP_comparison.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
