{
 "metadata": {
  "name": "",
  "signature": "sha256:81c2bd5ff12dd877d7f59f7f5ba25783aa428f9e76974b3eb27632ec9f380757"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Initial Code Revised -- Indian Buffet Process (IBP)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from __future__ import division\n",
      "import os\n",
      "import sys\n",
      "import glob\n",
      "import matplotlib.pyplot as plt\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "%matplotlib inline\n",
      "%precision 4\n",
      "plt.style.use('ggplot')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.random.seed(1234)\n",
      "import scipy.stats as stats"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Indian Buffet Process (IBP): Steps\n",
      "\n",
      "- Step 1: First customer takes a Poisson($\\alpha$) of dishes\n",
      "- Step 2: The $i$th customer takes dish $k$ with probability $\\frac{m_k}{i}$, where $m_k$ is the number of previous customers who sampled that dish\n",
      "- Step 3: The $i$th customer tries a Poisson($\\frac{\\alpha}{i}$) number of new dishes\n",
      "- Storage: Binary matrix $\\mathbf{Z}$ with $N$ rows and infinite columns, where $z_{ik}$ = 1 if customer $i$ sampled the dish $k$\n",
      "- Probability: $P(z_{ik}=1 | \\mathbf{z_{-i,k}}) = \\dfrac{m_{-i,k}+\\dfrac{\\alpha}{K}}{N+\\dfrac{\\alpha}{K}} \\rightarrow \\dfrac{m_{-i,k}}{N}$ as $K \\rightarrow \\infty$\n",
      "\n",
      "Special note: This is JUST a prior, not something you put in the Gibbs sampler!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def IBP(N, alpha):\n",
      "    \"\"\"Indian Buffet Process (IBP) steps:\n",
      "    Input: N is the number of customers (objects, images); alpha is the only parameter;\n",
      "    Return: result is the binary matrix (prior); Kplus is the number of dishes (features)\"\"\"\n",
      "    result = np.zeros((N,1000))\n",
      "    \n",
      "    # Step 1: First customer takes a Poisson(alpha) of dishes\n",
      "    t = stats.poisson.rvs(alpha) # (set the random seed when calling the function)\n",
      "    if t > 0:\n",
      "        result[0,0:t] = 1\n",
      "    \n",
      "    # Kplus = the number of features for which m_k > 0 (m_k: the number of previous customers who sampled that dish)\n",
      "    Kplus = t\n",
      "    for i in range(1,N):\n",
      "        for k in range(Kplus):\n",
      "            # Step 2: The ith customer takes dish k with probability m_k/i\n",
      "            p = np.sum(result[0:(i+1),k])/(i+1) # this is a probability, so should be between 0 and 1\n",
      "            assert p <= 1 \n",
      "            assert p >= 0\n",
      "            if stats.uniform.rvs(0) < p:\n",
      "                result[i,k] = 1\n",
      "            else:\n",
      "                result[i,k] = 0\n",
      "                \n",
      "        # Step 3: The ith customer tries a Poisson(alpha/i) number of new dishes\n",
      "        t = stats.poisson.rvs(alpha/(i+1))\n",
      "        if t > 0:\n",
      "            result[i,Kplus:(Kplus+t)] = 1\n",
      "        Kplus += t\n",
      "    result = result[:,0:Kplus]\n",
      "    \n",
      "    return result, Kplus"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Indian Buffet Process (IBP): Testing\n",
      "\n",
      "Probability must be between 0 and 1: $ 0 \\leq \\dfrac{m_{-i,k}+\\dfrac{\\alpha}{K}}{N+\\dfrac{\\alpha}{K}}, \\dfrac{m_{-i,k}}{N} \\leq 1$\n",
      "\n",
      "This is equivalent to testing $m_{-i,k} \\leq N$"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.random.seed(12)\n",
      "N1 = 100\n",
      "alpha1 = 1.5\n",
      "\n",
      "result1, Kplus1 = IBP(N1,alpha1)\n",
      "print Kplus1\n",
      "\n",
      "print result1.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "5\n",
        "(100, 5)\n"
       ]
      }
     ],
     "prompt_number": 29
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Algorithm Application -- Linear-Gaussian Binary Latent Feature Models\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Variables in Data (Images)\n",
      "\n",
      "$N = 100$ is the number of images (customers, objects)\n",
      "\n",
      "$D = 6 \\times 6 = 36$ is the length of vectors (dishes, features) for each image\n",
      "\n",
      "$K = 4$ is the number of basis images (latent or underlying variables)\n",
      "\n",
      "Each object $i$ has a $D$-dimensional vector of properties, named $x_i$\n",
      "\n",
      "- Generate images $X$ with the $K$ basis images, indicating which bases are used (each with probability 0.5)\n",
      "- Add white noises $\\text{Normal}(0,\\sigma_X^2 = 0.5)$ to these images"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Basis images\n",
      "import Image\n",
      "basis1 = np.array([[0,0,0,0,0,0],[0,0,0,0,0,0],[0,0,0,0,0,0],[0,1,0,0,0,0],[1,1,1,0,0,0],[0,1,0,0,0,0]])\n",
      "basis2 = np.array([[1,1,1,0,0,0],[1,0,1,0,0,0],[1,1,1,0,0,0],[0,0,0,0,0,0],[0,0,0,0,0,0],[0,0,0,0,0,0]])\n",
      "basis3 = np.array([[0,0,0,0,0,0],[0,0,0,0,0,0],[0,0,0,0,0,0],[0,0,0,0,0,1],[0,0,0,0,1,1],[0,0,0,1,1,1]])\n",
      "basis4 = np.array([[0,0,0,1,0,0],[0,0,0,1,1,1],[0,0,0,1,0,0],[0,0,0,0,0,0],[0,0,0,0,0,0],[0,0,0,0,0,0]])\n",
      "\n",
      "D = 36\n",
      "b1 = basis1.reshape(D)\n",
      "b2 = basis2.reshape(D)\n",
      "b3 = basis3.reshape(D)\n",
      "b4 = basis4.reshape(D)\n",
      "A = np.array([b1,b2,b3,b4])\n",
      "\n",
      "# These are heatmaps!\n",
      "plt.figure(num=None, figsize=(12,3), dpi=80, facecolor='w', edgecolor='k')\n",
      "plt.subplot(141)\n",
      "plt.pcolormesh(basis1,cmap=plt.cm.gray)     \n",
      "plt.subplot(142)\n",
      "plt.pcolormesh(basis2,cmap=plt.cm.gray)  \n",
      "plt.subplot(143)\n",
      "plt.pcolormesh(basis3,cmap=plt.cm.gray)  \n",
      "plt.subplot(144)\n",
      "plt.pcolormesh(basis4,cmap=plt.cm.gray)  \n",
      "\n",
      "print \"Latent feature matrices (A):\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Latent feature matrices (A):\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAArsAAADMCAYAAABz22vSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAMlSdgEASJayCwBAsv4PXDEO/+iVgFAAAAAASUVORK5CYII=\n",
       "text": [
        "<matplotlib.figure.Figure at 0x7f836f229c90>"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Generate image data: 100 matrices of size 6*6\n",
      "N = 100\n",
      "D = 36\n",
      "K = 4\n",
      "sigmaX_orig = 0.5\n",
      "\n",
      "# All K basis images, each of length D\n",
      "# Generate N images (customers, objects)\n",
      "np.random.seed(1234)\n",
      "images = np.zeros((N,6,6)) # simulated image data\n",
      "structure = np.zeros((N,6,6))  # 0/1 structure for each image\n",
      "add = stats.bernoulli.rvs(0.5,size=(N,K)) # whether the K=4 latent bases are present in each image\n",
      "epsilon = stats.norm.rvs(loc=0,scale=0.5,size = (N,6,6)) # random noise\n",
      "\n",
      "for i in range(N):\n",
      "    structure[i,:,:] = add[i,0]*basis1 + add[i,1]*basis2 + add[i,2]*basis3 + add[i,3]*basis4\n",
      "    images[i,:,:] = structure[i,:,:] + epsilon[i,:,:]\n",
      "\n",
      "Z_orig = add    \n",
      "# X = structure.reshape(N,D)    \n",
      "# print Z_orig\n",
      "# print structure[0,:,:]\n",
      "# print X[0,:]\n",
      "# print X.shape\n",
      "\n",
      "# print images.shape\n",
      "print \"Example image:\\n\",images[4]\n",
      "plt.pcolormesh(images[4],cmap=plt.cm.gray)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Example image:\n",
        "[[ 0.2067  0.3588  0.1309  0.8786 -0.2506 -0.3491]\n",
        " [ 0.6923 -0.1432  0.25    1.9756  0.8608  1.0184]\n",
        " [ 0.2229 -0.7052  0.225   1.2577 -0.577  -0.6901]\n",
        " [-0.2479  0.7934 -0.8597 -0.0148 -0.383   1.0499]\n",
        " [ 0.6435 -0.1131  1.3629  0.4585  0.7181  0.2389]\n",
        " [-0.0071  0.8766 -0.0827  1.0596 -0.0375  0.4986]]\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 5,
       "text": [
        "<matplotlib.collections.QuadMesh at 0x7f836e96e550>"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAWwAAAEECAYAAAAMOA6OAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nxH8BsFwqEFVt52UAAAAASUVORK5CYII=\n",
       "text": [
        "<matplotlib.figure.Figure at 0x7f836ea47310>"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Variables in Transformation\n",
      "\n",
      "$x_i \\sim \\text{Normal}(\\mathbf{z_i} \\mathbf{A}, \\Sigma_X = \\sigma_X^2\\mathbf{I})$\n",
      "\n",
      "$\\mathbf{z_i}$ is a $K$-dimensional binary vector (features)\n",
      "\n",
      "$\\mathbf{A}$ is a $K \\times D$ matrix of weights, with prior $A \\sim \\text{Normal}(0,\\sigma_A^2 \\mathbf{I})$\n",
      "\n",
      "$Z \\sim \\text{IBP}(\\alpha)$, where $m_k$ is the number of objects with feature $k$\n",
      "\n",
      "$p(Z | \\alpha) = \\dfrac{\\alpha^K}{\\prod^{2^N-1}_{h=1}K_h!} \\exp(-\\alpha H_N) \\prod^{K}_{k=1}\\dfrac{(N-m_k)!(m_k-1)!}{N!}$\n",
      "\n",
      "Note 1: $\\alpha$ is a variable influencing the number of features  $D$\n",
      "\n",
      "Note 2: $K_h$ is the number of features with history $h$ (whether the $N$ images possess this feature, $2^N-1$ possibilities in total)\n",
      "\n",
      "Note 3: $H_N$ is the $N^{\\text{th}}$ harmonic number, and $m_k$ is the number of objects with feature $k$"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Generate the Harmonic numbers, but we only need the sum\n",
      "from fractions import Fraction\n",
      "sum_Harmonics = 0\n",
      "Harmonics = 0\n",
      "for i in range(N):\n",
      "    sum_Harmonics += (N-i)*Fraction(1,i+1)\n",
      "    Harmonics += Fraction(1,i+1)\n",
      "print \"Sum of H_1 + ... + H_N:\", float(sum_Harmonics)\n",
      "print \"Harmonic number H_N:\", float(Harmonics)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Sum of H_1 + ... + H_N: 423.925129282\n",
        "Harmonic number H_N: 5.18737751764\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Initialization\n",
      "N = 100\n",
      "D = 36\n",
      "K = 4\n",
      "sigmaA = 1\n",
      "sigmaX = 1\n",
      "\n",
      "np.random.seed(1005)\n",
      "# alpha = stats.gamma.rvs(a = 1, loc = 0, scale = 1, size = 1)[0]\n",
      "alpha = 1\n",
      "\n",
      "K_inf = 1000\n",
      "Z, Kplus = IBP(N, alpha)\n",
      "print \"Initial Kplus:\", Kplus\n",
      "print \"Z.shape:\",Z.shape # (100,4) = (N,Kplus) (latent)\n",
      "print \"A.shape:\",A.shape # (4,36) = (Kplus,D)  (weight)\n",
      "\n",
      "# Set MCMC steps\n",
      "mcmc = 1000 # plan to sample for 1000 times\n",
      "\n",
      "# Setup the array\n",
      "Z_arr = np.zeros((mcmc,N,K_inf))\n",
      "Kplus_arr = np.zeros(mcmc)\n",
      "sigmaX_arr = np.zeros(mcmc)\n",
      "sigmaA_arr = np.zeros(mcmc)\n",
      "alpha_arr = np.zeros(mcmc)\n",
      "rX_accept = 0\n",
      "rA_accept = 0"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Initial Kplus: 4\n",
        "Z.shape: (100, 4)\n",
        "A.shape: (4, 36)\n"
       ]
      }
     ],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# More initialization\n",
      "np.random.seed(16)\n",
      "basis1 = np.array([[0,0,0,0,0,0],[0,0,0,0,0,0],[0,0,0,0,0,0],[0,1,0,0,0,0],[1,1,1,0,0,0],[0,1,0,0,0,0]])\n",
      "basis2 = np.array([[1,1,1,0,0,0],[1,0,1,0,0,0],[1,1,1,0,0,0],[0,0,0,0,0,0],[0,0,0,0,0,0],[0,0,0,0,0,0]])\n",
      "basis3 = np.array([[0,0,0,0,0,0],[0,0,0,0,0,0],[0,0,0,0,0,0],[0,0,0,0,0,1],[0,0,0,0,1,1],[0,0,0,1,1,1]])\n",
      "basis4 = np.array([[0,0,0,1,0,0],[0,0,0,1,1,1],[0,0,0,1,0,0],[0,0,0,0,0,0],[0,0,0,0,0,0],[0,0,0,0,0,0]])\n",
      "\n",
      "D = 36\n",
      "b1 = basis1.reshape(D)\n",
      "b2 = basis2.reshape(D)\n",
      "b3 = basis3.reshape(D)\n",
      "b4 = basis4.reshape(D)\n",
      "A = np.array([b1,b2,b3,b4])\n",
      "\n",
      "Z_orig = np.zeros((N,4))\n",
      "sigmaX_orig = 0.5\n",
      "X = np.zeros((N,D))\n",
      "\n",
      "for i in range(N):\n",
      "    Z_orig[i,:] = stats.uniform.rvs(loc=0,scale=1,size=4) > 0.5\n",
      "    while np.sum(Z_orig[i,:]) == 0:\n",
      "        Z_orig[i,:] = stats.uniform.rvs(loc=0,scale=1,size=4) > 0.5\n",
      "    X[i,:] = np.random.normal(size=D)*sigmaX_orig + np.dot(Z_orig[i,:],A)\n",
      "    \n",
      "print \"X.shape:\",X.shape # (100,36) = (N,D) (data)\n",
      "print X[0:6,0:6]\n",
      "print Z_orig.shape\n",
      "print Z_orig[0:6,:]\n",
      "# print np.dot(Z_orig[i,:],A).shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "X.shape: (100, 36)\n",
        "[[ 0.3823  0.6893  0.5555  0.2495 -0.3934  0.0594]\n",
        " [-0.6691  0.2899  0.2682  0.7715  0.8372 -0.3196]\n",
        " [ 1.3606  0.9476  0.4842  1.4568  0.2546 -0.5242]\n",
        " [ 0.6291  1.015   1.2063  0.3139  0.0555 -0.5009]\n",
        " [ 0.2144  1.6798  1.192   1.686  -0.1699  0.0766]\n",
        " [ 0.4324  0.3552  0.0704  1.3771  0.2362 -0.3846]]\n",
        "(100, 4)\n",
        "[[ 0.  1.  1.  0.]\n",
        " [ 0.  0.  1.  0.]\n",
        " [ 1.  1.  1.  1.]\n",
        " [ 0.  1.  0.  0.]\n",
        " [ 0.  1.  1.  1.]\n",
        " [ 1.  0.  1.  1.]]\n"
       ]
      }
     ],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "M = calcM(Z,Kplus,sigmaX,sigmaA) \n",
      "log_likelihood(X,Z[:,0:Kplus],M,sigmaA,sigmaX,Kplus,N,D)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 78,
       "text": [
        "-4224.3456"
       ]
      }
     ],
     "prompt_number": 78
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Checking whether the gamma distribution is setup correctly\n",
      "# ff ~ Gamma(a,b): a = shape, b = 1/scale => E(ff) = a/b = a*scale, Var(ff) = a/b**2 = a*scale**2\n",
      "# Generate 1000 random samples from Ga(3,2)\n",
      "np.random.seed(17)\n",
      "rv = stats.gamma.rvs(a = 3, loc = 0, scale = 2, size=1000)\n",
      "print np.mean(rv)  # should be close to 3*2 = 6\n",
      "print np.var(rv)   # should be close to 3*2*2 = 12"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "6.11082455198\n",
        "12.3836326135\n"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Gibbs Sampler\n",
      "\n",
      "Initialization: $\\sigma_A = 1, \\sigma_X = 1, \\alpha \\sim Ga(1,1)$\n",
      "\n",
      "1. Generate $P(z_{ik} | \\mathbf{X,Z_{-i,k}},\\sigma_X, \\sigma_A)$ using the full conditional distribution\n",
      "2. Sample $\\sigma_{X}^* = \\sigma_X + \\epsilon$, where $\\epsilon \\sim \\text{Unif}(-0.05,0.05)$, and accept $\\sigma_{X}^*$ by Metropolis (not just when the likelihood is larger, i.e. $P(\\sigma_{X}^*) > P(\\sigma_{X})$)\n",
      "3. Sample $\\sigma_{A}^* = \\sigma_A + \\epsilon$, where $\\epsilon \\sim \\text{Unif}(-0.05,0.05)$, and accept $\\sigma_{A}^*$ by Metropolis (not just when the likelihood is larger, i.e. $P(\\sigma_{A}^*) > P(\\sigma_{A})$)\n",
      "4. Generate $\\alpha|Z \\sim Ga(1+K_+,1+\\sum^{N}_{i=1}H_i)$, where $K_+ = \\sum^{2^N-1}_{h=1}K_h$ and $K_+$ is the number of features for which $m_k > 0$\n",
      "\n",
      "Metropolis for $\\sigma_A$ (for $\\sigma_X$ is similar):\n",
      "\n",
      "Current value: $\\sigma_{A}^{(n)}$\n",
      "\n",
      "Candidate value: $\\sigma_{A}^{*}$\n",
      "\n",
      "Generate $r \\sim \\text{Unif}(0,1)$\n",
      "\n",
      "Accept $\\sigma_{A}^{*}$ if $r < \\text{min}\\{ 1, \\dfrac{P(\\sigma_{A}^{*} | \\mathbf{Z,X},\\sigma_X)}{P(\\sigma_{A}^{(n)} | \\mathbf{Z,X},\\sigma_X)} \\}$"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def calcM(Z,Kplus,sigmaX,sigmaA):\n",
      "    \"\"\"Save the matrix M so we won't need to calculate it again and again\"\"\"\n",
      "    return np.linalg.inv(np.dot(Z[:,0:Kplus].T,Z[:,0:Kplus])+((sigmaX/sigmaA)**2)*np.identity(Kplus))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def calcInverse(Z, M, i, k, val):\n",
      "    \"\"\"Effective inverse calculation from Griffiths and Ghahramani (2005; Equations 51 to 54)\n",
      "    M_(-i) = inv(inv(M) - zi.T * zi)\"\"\"\n",
      "    M_i = M - np.dot(np.dot(M,Z[i,:].T),np.dot(Z[i,:],M))/(np.dot(np.dot(Z[i,:],M),Z[i,:].T)-1)\n",
      "    Z[i,k] = val\n",
      "    M = M_i - np.dot(np.dot(M_i,Z[i,:].T),np.dot(Z[i,:],M_i))/(np.dot(np.dot(Z[i,:],M_i),Z[i,:].T)+1)\n",
      "    Inv = M\n",
      "    return Inv"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def calcInverse_new(Z, M, i, k, val):\n",
      "    \"\"\"New version to check\n",
      "    Effective inverse calculation from Griffiths and Ghahramani (2005; Equations 51 to 54)\n",
      "    M_(-i) = inv(inv(M) - zi.T * zi)\"\"\"\n",
      "    Z[i,k] = val\n",
      "#     counter = np.zeros((len(Z[i,:]),len(Z[i,:])))\n",
      "#     for j in range(Z.shape[0]):\n",
      "#         counter += np.dot(Z[j,:].T,Z[j,:])\n",
      "#     counter -= np.dot(Z[i,:].T,Z[i,:])\n",
      "    \n",
      "#     M_negi = np.linalg.inv(counter + ((sigmaX/sigmaA)**2)*np.identity(len(Z[i,:])))\n",
      "    \n",
      "#     return M_negi\n",
      "    return np.linalg.inv(np.linalg.inv(M) - np.dot(Z[i,:].T,Z[i,:]))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Z.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 184,
       "text": [
        "(100, 17)"
       ]
      }
     ],
     "prompt_number": 184
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def log_likelihood(X,Z,M,sigmaA,sigmaX,Kplus,N,D):  \n",
      "    \"\"\"Calculate the log-likelihood: P(X|Z,M,sigmaA,sigmaX,Kplus,N,D)\"\"\"  \n",
      "    determinant = np.linalg.det(np.dot(Z.T,Z)+((sigmaX/sigmaA)**2)*np.identity(Kplus))\n",
      "    constant = N*D*0.5*np.log(2*np.pi) + (N-Kplus)*D*np.log(sigmaX) + Kplus*D*np.log(sigmaA) + D*0.5*np.log(determinant)\n",
      "    \n",
      "    middle = np.identity(N) - np.dot(np.dot(Z, M),Z.T)\n",
      "    trace = np.trace(np.dot(np.dot(X.T,middle),X))\n",
      "    kernel = -0.5*np.reciprocal(sigmaX**2)*trace\n",
      "    \n",
      "    log_lik = -constant + kernel\n",
      "    #print constant\n",
      "    #print kernel\n",
      "    return log_lik"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Gibbs Sampler -- Steps\n",
      "np.random.seed(111)\n",
      "\n",
      "# for mc in range(mcmc):\n",
      "for mc in range(1000):\n",
      "\n",
      "    # Step 0: Save generated parameters to the MCMC array\n",
      "    Z_arr[mc,:,0:Kplus] = Z[:,0:Kplus]\n",
      "    # print \"Shape of Z:\",Z.shape\n",
      "    \n",
      "    alpha_arr[mc] = alpha\n",
      "    Kplus_arr[mc] = Kplus\n",
      "    sigmaX_arr[mc] = sigmaX\n",
      "    sigmaA_arr[mc] = sigmaA\n",
      "    print \"At iteration\",mc,\": Kplus is\",Kplus,\", alpha is\",alpha\n",
      "\n",
      "    # Step 1: Generate Z|alpha (Gibbs)\n",
      "    for i in range(N):\n",
      "        # Save the matrix M so we won't need to calculate it again and again\n",
      "        #M = calcM(Z,Kplus,sigmaX,sigmaA)\n",
      "                             \n",
      "        for k in range(Kplus):\n",
      "            # This is possible because Kplus may decrease in this loop (e.g. dropping redundant zeros)\n",
      "            if (k+1) > Kplus:\n",
      "                break\n",
      "            if Z[i,k] > 0:\n",
      "                # Take care of singular features\n",
      "                # Get rid of the features not sampled (remove the zeros)\n",
      "                if np.sum(Z[:,k]) - Z[i,k] <= 0: # whether the dish is sampled by other customers or not\n",
      "                # if np.sum(Z[:,k]) - Z[i,k] == 0: # same as the code above since Z is binary\n",
      "                    #Z[i,k] = 0\n",
      "                    # Avoid Kplus to become zero!\n",
      "#                     if Kplus == 1:\n",
      "#                         Z[:,0] = Z[:,1]\n",
      "#                     else: # Kplus > 1\n",
      "                    Z[:,k:(Kplus-1)] = Z[:,(k+1):Kplus]\n",
      "                    Kplus -= 1\n",
      "                        # Z = Z[:,0:Kplus] # remove the last column\n",
      "                    #M = calcM(Z,Kplus,sigmaX,sigmaA)          \n",
      "                    continue            \n",
      "            \n",
      "            # Effective inverse calculation from Griffiths and Ghahramani (2005; Equations 51 to 54)\n",
      "            # M_(-i) = inv(inv(M) - zi.T * zi)\n",
      "#             M0 = calcInverse(Z[:,0:Kplus], M, i, k, 0)\n",
      "#             M1 = calcInverse(Z[:,0:Kplus], M, i, k, 1)\n",
      "            \n",
      "            # Then calculate the posterior distribution: prior * likelihood \n",
      "            # i.e. customers sample the dishes that have been previously sampled\n",
      "            # Likelihood: P(X|Z_(-i,k),sigmaX,sigmaA)\n",
      "            # Prior: P(z_ik = 1 | z_(-i,k)) = m_(-i,k) / N, where m_(-i,k) = number of objects possess feature k, excluding i\n",
      "            P = np.zeros(2)\n",
      "            Z[i,k] = 1\n",
      "            M1 = calcM(Z,Kplus,sigmaX,sigmaA) \n",
      "            P[1] = log_likelihood(X,Z[:,0:Kplus],M1,sigmaA,sigmaX,Kplus,N,D) + np.log(sum(Z[:,k])-Z[i,k]) - np.log(N)\n",
      "            Z[i,k] = 0\n",
      "            M0 = calcM(Z,Kplus,sigmaX,sigmaA) \n",
      "            P[0] = log_likelihood(X,Z[:,0:Kplus],M0,sigmaA,sigmaX,Kplus,N,D) + np.log(N-sum(Z[:,k])) - np.log(N)\n",
      "            P = np.exp(P - max(P))\n",
      "            # Sample from the posterior distribution\n",
      "            rand = stats.uniform.rvs(loc=0,scale=1,size=1)           \n",
      "            if rand < P[0]/(P[0]+P[1]):\n",
      "                Z[i,k] = 0\n",
      "                #M = M0\n",
      "            else:\n",
      "                Z[i,k] = 1\n",
      "                #M = M1\n",
      "\n",
      "        # Sample the number of new dishes Pois(alpha/i) for the current customer/object\n",
      "        # Truncated prior: P(z_ik = 1 | z_(-i,k)) = (m_(-i,k) + alpha/Kplus) / (N + alpha/Kplus)\n",
      "        # trun = np.zeros(5)\n",
      "        trun = np.zeros(4)\n",
      "        # alphaN = alpha/N  # don't use alpha/i, or this can result in division by zero, but I don't know the details\n",
      "        # alphaN = alpha/(i+1)\n",
      "        alphaN = alpha/N\n",
      "        # Note: in MATLAB, any matrix can be expanded => in Python, we need np.vstack and/or np.hstack       \n",
      "        \n",
      "        # for ki in range(5):\n",
      "        for ki in range(4):\n",
      "            if ki > 0:\n",
      "                new_stack = np.zeros((N,ki))\n",
      "                new_stack[i,:] = 1\n",
      "                Z = np.hstack((Z[:,0:Kplus],new_stack))\n",
      "            M = np.linalg.inv(np.dot(Z[:,0:(Kplus+ki)].T,Z[:,0:(Kplus+ki)])+((sigmaX/sigmaA)**2)*np.identity(Kplus+ki))\n",
      "            # Prior: x ~ Pois(lambda): f(x) = ((lambda**x)/x!)*exp(-lambda), where x = ki, lambda = alphaN\n",
      "            \n",
      "            trun[ki] = (ki)*np.log(alphaN) - alphaN - np.log(np.math.factorial(ki)) \n",
      "            # posterior is proportional to prior x likelihood\n",
      "            trun[ki] += log_likelihood(X,Z[:,0:(Kplus+ki)],M,sigmaA,sigmaX,Kplus+ki,N,D)\n",
      "            \n",
      "        # Z[i,Kplus:(Kplus+4)] = 0\n",
      "        Z[i,Kplus:(Kplus+3)] = 0\n",
      "        trun = np.exp(trun-max(trun))\n",
      "        trun = trun/np.sum(trun)\n",
      "        \n",
      "        p = stats.uniform.rvs(loc=0,scale=1,size=1)  \n",
      "        t = 0\n",
      "        # for ki in range(5):\n",
      "        for ki in range(4):\n",
      "            t += trun[ki]\n",
      "            if p < t:\n",
      "                new_dishes = ki\n",
      "                break\n",
      "        Z[i,Kplus:(Kplus+new_dishes)] = 1\n",
      "        Kplus += new_dishes\n",
      "        \n",
      "    # Step 2: Sample sigmaX_star (Metropolis)\n",
      "    # M = calcM(Z, Kplus+new_dishes, sigmaX, sigmaA)\n",
      "    M = calcM(Z, Kplus, sigmaX, sigmaA)\n",
      "    #logLik = log_likelihood(X, Z[:,0:(Kplus+new_dishes)], M, sigmaA, sigmaX, Kplus+new_dishes, N, D)\n",
      "    logLik = log_likelihood(X, Z[:,0:Kplus], M, sigmaA, sigmaX, Kplus, N, D)\n",
      "    epsilonX = stats.uniform.rvs(loc=0,scale=1,size=1) \n",
      "    if epsilonX < 0.5:\n",
      "        # sigmaX_star = sigmaX - epsilonX/40\n",
      "        # sigmaX_star = sigmaX - epsilonX/20\n",
      "        sigmaX_star = sigmaX - stats.uniform.rvs(loc=0,scale=1,size=1)/20\n",
      "    else:\n",
      "        # sigmaX_star = sigmaX + epsilonX/20   \n",
      "        sigmaX_star = sigmaX + stats.uniform.rvs(loc=0,scale=1,size=1)/20 \n",
      "    # M_Xstar = calcM(Z, Kplus+new_dishes, sigmaX_star, sigmaA)\n",
      "    M_Xstar = calcM(Z, Kplus, sigmaX_star, sigmaA)\n",
      "    # logLikX_star = log_likelihood(X, Z[:,0:(Kplus+new_dishes)], M_Xstar, sigmaA, sigmaX_star, Kplus+new_dishes, N, D)\n",
      "    logLikX_star = log_likelihood(X, Z[:,0:Kplus], M_Xstar, sigmaA, sigmaX_star, Kplus, N, D)\n",
      "    acc_X = np.exp(min(0, logLikX_star-logLik))\n",
      "    \n",
      "    # Step 3: Sample sigmaA_star (Metropolis)\n",
      "    epsilonA = stats.uniform.rvs(loc=0,scale=1,size=1)\n",
      "    if epsilonA < 0.5:\n",
      "        # sigmaA_star = sigmaA - epsilonA/20\n",
      "        sigmaA_star = sigmaA - stats.uniform.rvs(loc=0,scale=1,size=1)/20\n",
      "    else:\n",
      "        # sigmaA_star = sigmaA + epsilonA/40 \n",
      "        sigmaA_star = sigmaA + stats.uniform.rvs(loc=0,scale=1,size=1)/20\n",
      "        # sigmaA_star = sigmaA + epsilonA/20   \n",
      "    # M_Astar = calcM(Z, Kplus+new_dishes, sigmaX, sigmaA_star)\n",
      "    M_Astar = calcM(Z, Kplus, sigmaX, sigmaA_star)\n",
      "    # logLikA_star = log_likelihood(X, Z[:,0:(Kplus+new_dishes)], M_Astar, sigmaA_star, sigmaX, Kplus+new_dishes, N, D)\n",
      "    logLikA_star = log_likelihood(X, Z[:,0:Kplus], M_Astar, sigmaA_star, sigmaX, Kplus, N, D)\n",
      "    acc_A = np.exp(min(0, logLikA_star-logLik))\n",
      "    \n",
      "    randX = stats.uniform.rvs(loc=0,scale=1,size=1)\n",
      "    if randX < acc_X:\n",
      "        sigmaX = sigmaX_star\n",
      "        rX_accept += 1\n",
      "    randA = stats.uniform.rvs(loc=0,scale=1,size=1)\n",
      "    if randA < acc_A:\n",
      "        sigmaA = sigmaA_star\n",
      "        rA_accept += 1\n",
      "    \n",
      "    # Step 4: Sample alpha|Z ~ Ga(a=1+Kplus,scale=1+Harmonics)\n",
      "    alpha = stats.gamma.rvs(a = 1+Kplus, loc = 0, scale = np.reciprocal(1+Harmonics),size=1)[0]\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At iteration 0 : Kplus is 4 , alpha is 1\n",
        "At iteration"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 1 : Kplus is 3 , alpha is 0.398572796978\n",
        "At iteration"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 2 : Kplus is 2 , alpha is 0.515214542874\n",
        "At iteration"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 3 : Kplus is 2 , alpha is 1.12571509406\n",
        "At iteration"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 4 : Kplus is 2 , alpha is 0.375985445657\n",
        "At iteration"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 5 : Kplus is 2 , alpha is 0.383656839482\n",
        "At iteration"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 6 : Kplus is 2 , alpha is 0.188087319338\n",
        "At iteration"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 7 : Kplus is 2 , alpha is 0.891555117631\n",
        "At iteration"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 8 : Kplus is 2 , alpha is 0.0625029771747\n",
        "At iteration"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 9 : Kplus is 2 , alpha is 0.278331450335\n",
        "At iteration"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 10 : Kplus is 2 , alpha is 0.191531588245\n",
        "At iteration"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 11 : Kplus is 2 , alpha is 0.400884435609\n",
        "At iteration"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 12 : Kplus is 2 , alpha is 0.230967019223\n",
        "At iteration"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 13 : Kplus is 2 , alpha is 0.106424791883\n",
        "At iteration"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 14 : Kplus is 2 , alpha is 0.812565844879\n",
        "At iteration"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 15 : Kplus is 2 , alpha is 0.282537660661\n",
        "At iteration"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 16 : Kplus is 2 , alpha is 0.250189365563\n",
        "At iteration"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 17 : Kplus is 2 , alpha is 0.176314957029\n",
        "At iteration"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 18 : Kplus is 2 , alpha is 0.634176071489\n",
        "At iteration"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 19 : Kplus is 2 , alpha is 0.412989127049\n",
        "At iteration"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 20 : Kplus is 2 , alpha is 0.125474929335\n",
        "At iteration"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 21 : Kplus is 2 , alpha is 0.378290122164\n",
        "At iteration"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 22 : Kplus is 2 , alpha is 0.274754387203\n",
        "At iteration"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 23 : Kplus is 2 , alpha is 0.532565160018\n",
        "At iteration"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 24 : Kplus is 2 , alpha is 0.236240256556\n",
        "At iteration"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 25 : Kplus is 2 , alpha is 0.466041394769\n",
        "At iteration"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 26 : Kplus is 2 , alpha is 0.336394783349\n",
        "At iteration"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 27 : Kplus is 2 , alpha is 0.779748366536\n",
        "At iteration"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 28 : Kplus is 2 , alpha is 0.391088188531\n",
        "At iteration"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 29 : Kplus is 2 , alpha is 0.168080465587\n",
        "At iteration"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 30 : Kplus is 2 , alpha is 0.616948140778\n",
        "At iteration"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 31 : Kplus is 2 , alpha is 0.868394520741\n",
        "At iteration"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 32 : Kplus is 2 , alpha is 0.280674994566\n",
        "At iteration"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 33 : Kplus is 2 , alpha is 0.648214039474\n",
        "At iteration"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 34 : Kplus is 2 , alpha is 0.191502172187\n",
        "At iteration"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 35 : Kplus is 2 , alpha is 0.855604557803\n",
        "At iteration"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 36 : Kplus is 2 , alpha is 0.233212399788\n",
        "At iteration"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 37 : Kplus is 2 , alpha is 0.733314113245\n",
        "At iteration"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 38 : Kplus is 2 , alpha is 0.329915994395\n",
        "At iteration"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 39 : Kplus is 2 , alpha is 0.534651575309\n",
        "At iteration"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 40 : Kplus is 2 , alpha is 0.230789639993\n",
        "At iteration"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 41 : Kplus is 2 , alpha is 0.144477639428\n",
        "At iteration"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 42 : Kplus is 2 , alpha is 0.188499310853\n",
        "At iteration"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 43 : Kplus is 2 , alpha is 0.166695908941\n",
        "At iteration"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 44 : Kplus is 2 , alpha is 0.738110543694\n",
        "At iteration"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 45 : Kplus is 2 , alpha is 0.849760665762\n",
        "At iteration"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 46 : Kplus is 2 , alpha is 0.449198206351\n",
        "At iteration"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 47 : Kplus is 2 , alpha is 0.275673843514\n",
        "At iteration"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 48 : Kplus is 2 , alpha is 0.29080082949\n",
        "At iteration"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 49 : Kplus is 3 , alpha is 0.571172365545\n",
        "At iteration"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 50 : Kplus is 3 , alpha is 0.657824749448\n",
        "At iteration"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 51 : Kplus is 4 , alpha is 0.774918456812\n",
        "At iteration"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 52 : Kplus is 4 , alpha is 0.923670482097\n",
        "At iteration"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 53 : Kplus is 5 , alpha is 0.611464509844\n",
        "At iteration"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 54 : Kplus is 4 , alpha is 0.853622257768\n",
        "At iteration"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 55 : Kplus is 5 , alpha is 0.478195689806\n",
        "At iteration"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 56 : Kplus is 5 , alpha is 1.31536574757\n",
        "At iteration"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 57 : Kplus is 6 , alpha is 0.966257930171\n",
        "At iteration"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 58 : Kplus is 5 , alpha is 0.767808578494\n",
        "At iteration"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 59 : Kplus is 8 , alpha is 1.64013879259\n",
        "At iteration"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 60 : Kplus is 6 , alpha is 1.12339091823\n",
        "At iteration"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 61 : Kplus is 7 , alpha is 1.92941757364\n",
        "At iteration"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 62 : Kplus is 6 , alpha is 1.21701453445\n",
        "At iteration"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 63 : Kplus is 5 , alpha is 1.61059798868\n",
        "At iteration"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 64 : Kplus is 5 , alpha is 1.13194276181\n",
        "At iteration"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 65 : Kplus is 4 , alpha is 0.742567435196\n",
        "At iteration"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 66 : Kplus is 7 , alpha is 0.753414364474\n",
        "At iteration"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 67 : Kplus is 5 , alpha is 0.912666657978\n",
        "At iteration"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 68 : Kplus is 4 , alpha is 1.44898425619\n",
        "At iteration"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 69 : Kplus is 6 , alpha is 0.734722565513\n",
        "At iteration"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 70 : Kplus is 7 , alpha is 1.19313889047\n",
        "At iteration"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 71 : Kplus is 8 , alpha is 1.11248147826\n",
        "At iteration"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 72 : Kplus is 7 , alpha is 1.20077478599\n",
        "At iteration"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 73 : Kplus is 6 , alpha is 1.01350830581\n",
        "At iteration"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 74 : Kplus is 5 , alpha is 2.2818065386\n",
        "At iteration"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 75 : Kplus is 5 , alpha is 0.200498412683\n",
        "At iteration"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 76 : Kplus is 5 , alpha is 1.85897272999\n",
        "At iteration"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 77 : Kplus is 5 , alpha is 0.548077954456\n",
        "At iteration"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 78 : Kplus is 6 , alpha is 1.58601031223\n",
        "At iteration"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 79 : Kplus is 6 , alpha is 0.664139361725\n",
        "At iteration"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 80 : Kplus is 6 , alpha is 1.36038565286\n",
        "At iteration"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 81 : Kplus is 6 , alpha is 0.842965215451\n",
        "At iteration"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 82 : Kplus is 7 , alpha is 1.40179618726\n",
        "At iteration"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 83 : Kplus is 7 , alpha is 1.45969570133\n",
        "At iteration"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 84 : Kplus is 8 , alpha is 1.33956934981\n",
        "At iteration"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 85 : Kplus is 6 , alpha is 0.643521472146\n",
        "At iteration"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 86 : Kplus is 5 , alpha is 1.78292384194\n",
        "At iteration"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 87 : Kplus is 7 , alpha is 1.34859238357\n",
        "At iteration"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 88 : Kplus is 6 , alpha is 0.847724891793\n",
        "At iteration"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 89 : Kplus is 6 , alpha is 1.05826751613\n",
        "At iteration"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 90 : Kplus is 6 , alpha is 0.82722012179\n",
        "At iteration"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 91 : Kplus is 5 , alpha is 0.697340013583\n",
        "At iteration"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 92 : Kplus is 6 , alpha is 1.63394637226\n",
        "At iteration"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 93 : Kplus is 8 , alpha is 1.51004814028\n",
        "At iteration"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 94 : Kplus is 5 , alpha is 1.9398775953\n",
        "At iteration"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 95 : Kplus is 6 , alpha is 0.787350359392\n",
        "At iteration"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 96 : Kplus is 6 , alpha is 0.685956458905\n",
        "At iteration"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 97 : Kplus is 5 , alpha is 0.753609582447\n",
        "At iteration"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 98 : Kplus is 6 , alpha is 1.14009737347\n",
        "At iteration"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 99 : Kplus is 7 , alpha is 1.35302519586\n",
        "At iteration"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 100 : Kplus is 7 , alpha is 1.49338800704\n",
        "At iteration"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 101 : Kplus is 5 , alpha is 1.61164519209\n",
        "At iteration"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 102 : Kplus is 7 , alpha is 1.81971800118\n",
        "At iteration"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 103 : Kplus is 5 , alpha is 0.857367340828\n",
        "At iteration"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 104 : Kplus is 6 , alpha is 1.16758954698\n",
        "At iteration"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 105 : Kplus is 7 , alpha is 1.44076158179\n",
        "At iteration"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 106 : Kplus is 7 , alpha is 1.54071165899\n",
        "At iteration"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 107 : Kplus is 8 , alpha is 1.25150655537\n",
        "At iteration"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 108 : Kplus is 8 , alpha is 1.24166069078\n",
        "At iteration"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 109 : Kplus is 6 , alpha is 1.04969929173\n",
        "At iteration"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 110 : Kplus is 5 , alpha is 1.69957673582\n",
        "At iteration"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 111 : Kplus is 6 , alpha is 0.939770471479\n",
        "At iteration"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 112 : Kplus is 6 , alpha is 1.51842140162\n",
        "At iteration"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 113 : Kplus is 7 , alpha is 1.37242317138\n",
        "At iteration"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 114 : Kplus is 6 , alpha is 2.55155023477\n",
        "At iteration"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 115 : Kplus is 7 , alpha is 0.842165479873\n",
        "At iteration"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 116 : Kplus is 6 , alpha is 1.81454472687\n",
        "At iteration"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 117 : Kplus is 6 , alpha is 0.720706160694\n",
        "At iteration"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 118 : Kplus is 5 , alpha is 0.449973809151\n",
        "At iteration"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 119 : Kplus is 5 , alpha is 1.01398908702\n",
        "At iteration"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 120 : Kplus is 7 , alpha is 1.7794317193\n",
        "At iteration"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 121 : Kplus is 7 , alpha is 1.20801239572\n",
        "At iteration"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 122 : Kplus is 7 , alpha is 1.31037393998\n",
        "At iteration"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 123 : Kplus is 5 , alpha is 0.821601846717\n",
        "At iteration"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 124 : Kplus is 5 , alpha is 1.84533027703\n",
        "At iteration"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 125 : Kplus is 6 , alpha is 1.35489649929\n",
        "At iteration"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 126 : Kplus is 7 , alpha is 1.18206660728\n",
        "At iteration"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 127 : Kplus is 6 , alpha is 0.503926343146\n",
        "At iteration"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 128 : Kplus is 5 , alpha is 1.80085585262\n",
        "At iteration"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 129 : Kplus is 5 , alpha is 1.10666879049\n",
        "At iteration"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 130 : Kplus is 6 , alpha is 1.37392920519\n",
        "At iteration"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 131 : Kplus is 6 , alpha is 1.14071395909\n",
        "At iteration"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 132 : Kplus is 6 , alpha is 0.838628323696\n",
        "At iteration"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 133 : Kplus is 5 , alpha is 1.81431064199\n",
        "At iteration"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 134 : Kplus is 5 , alpha is 1.67221208411\n",
        "At iteration"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 135 : Kplus is 5 , alpha is 1.03781823033\n",
        "At iteration"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 136 : Kplus is 5 , alpha is 0.76702676934\n",
        "At iteration"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 137 : Kplus is 6 , alpha is 1.21474221573\n",
        "At iteration"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 138 : Kplus is 6 , alpha is 0.935835911774\n",
        "At iteration"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 139 : Kplus is 7 , alpha is 1.09849919204\n",
        "At iteration"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 140 : Kplus is 5 , alpha is 1.23252517886\n",
        "At iteration"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 141 : Kplus is 7 , alpha is 0.556234521908\n",
        "At iteration"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 142 : Kplus is 6 , alpha is 1.28214041308\n",
        "At iteration"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 143 : Kplus is 5 , alpha is 1.03399134093\n",
        "At iteration"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 144 : Kplus is 5 , alpha is 1.41072830638\n",
        "At iteration"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 145 : Kplus is 5 , alpha is 0.53234187268\n",
        "At iteration"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 146 : Kplus is 5 , alpha is 0.926452609897\n",
        "At iteration"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 147 : Kplus is 6 , alpha is 0.611673565988\n",
        "At iteration"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 148 : Kplus is 7 , alpha is 1.60374237749\n",
        "At iteration"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 149 : Kplus is 6 , alpha is 0.868202175831\n",
        "At iteration"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 150 : Kplus is 5 , alpha is 1.22530463797\n",
        "At iteration"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 151 : Kplus is 6 , alpha is 0.473623859695\n",
        "At iteration"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 152 : Kplus is 6 , alpha is 0.829446127416\n"
       ]
      },
      {
       "ename": "KeyboardInterrupt",
       "evalue": "",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-21-9af36ec41938>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     86\u001b[0m             \u001b[0mtrun\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mki\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mki\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0malphaN\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0malphaN\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfactorial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mki\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m             \u001b[1;31m# posterior is proportional to prior x likelihood\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 88\u001b[1;33m             \u001b[0mtrun\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mki\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mlog_likelihood\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mZ\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mKplus\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mki\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mM\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msigmaA\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msigmaX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mKplus\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mki\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mN\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mD\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     89\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m         \u001b[1;31m# Z[i,Kplus:(Kplus+4)] = 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m<ipython-input-13-899a2214594e>\u001b[0m in \u001b[0;36mlog_likelihood\u001b[1;34m(X, Z, M, sigmaA, sigmaX, Kplus, N, D)\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mconstant\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mN\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mD\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpi\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mN\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mKplus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mD\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msigmaX\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mKplus\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mD\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msigmaA\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mD\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdeterminant\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mmiddle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0midentity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mN\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mZ\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mM\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mZ\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[0mtrace\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmiddle\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mkernel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreciprocal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msigmaX\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mtrace\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
       ]
      }
     ],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.plot(sigmaX_arr)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 85,
       "text": [
        "[<matplotlib.lines.Line2D at 0x7ff5b4fc27d0>]"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAX8AAAEECAYAAADAoTRlAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nPJriWM0AAAAASUVORK5CYII=\n",
       "text": [
        "<matplotlib.figure.Figure at 0x7ff5b5044b50>"
       ]
      }
     ],
     "prompt_number": 85
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.plot(sigmaA_arr)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 86,
       "text": [
        "[<matplotlib.lines.Line2D at 0x7ff5b4ef5450>]"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAX8AAAEECAYAAADAoTRlAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
       "text": [
        "<matplotlib.figure.Figure at 0x7ff5b50020d0>"
       ]
      }
     ],
     "prompt_number": 86
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# print np.mean(Kplus_arr)\n",
      "# print sigmaX_arr\n",
      "# print Kplus_arr\n",
      "# print sum(Kplus_arr == 5)\n",
      "Kplus00 = 4\n",
      "stats.gamma.rvs(a = 1+Kplus00, loc = 0, scale = np.reciprocal(1+Harmonics),size=1)[0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 150,
       "text": [
        "1.5390"
       ]
      }
     ],
     "prompt_number": 150
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print rX_accept/2430\n",
      "print rA_accept/2430\n",
      "print Z.shape\n",
      "print X.shape\n",
      "print Z_arr.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.237860082305\n",
        "0.497942386831\n",
        "(100, 6)\n",
        "(100, 36)\n",
        "(1000, 100, 1000)\n"
       ]
      }
     ],
     "prompt_number": 83
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Z_arr[999,:,0:6]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 109
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Setup the array\n",
      "Kplus_final = Kplus_arr[399] # in fact it is 5 =.=\n",
      "# Kplus_final = 4\n",
      "# Z_final = Z_arr[156,:,0:Kplus_final-1].reshape(N,Kplus_final-1)\n",
      "# Z_final = Z_arr[156,:,1:Kplus_final].reshape(N,Kplus_final-1)\n",
      "Z_final = Z_arr[156,:,0:Kplus_final].reshape(N,Kplus_final)\n",
      "sigmaX_final = sigmaX_arr[399]\n",
      "sigmaA_final = sigmaA_arr[399]\n",
      "A_inf = np.dot(np.linalg.inv(np.dot(Z_final.T,Z_final) +  ((sigmaX_final/sigmaA_final)**2)*np.identity(Kplus_final)),np.dot(Z_final.T,X))\n",
      "\n",
      "A_inf[3,:].reshape(6,6)\n",
      "# subplot(1,4,1); imagesc(reshape(A_inf(1,:),6,6)); colormap(gray); axis off\n",
      "# subplot(1,4,2); imagesc(reshape(A_inf(2,:),6,6)); colormap(gray); axis off\n",
      "# subplot(1,4,3); imagesc(reshape(A_inf(3,:),6,6)); colormap(gray); axis off\n",
      "# subplot(1,4,4); imagesc(reshape(A_inf(4,:),6,6)); colormap(gray); axis off\n",
      "\n",
      "# print \"Example image:\\n\",A_inf[0,:].reshape(6,6)\n",
      "plt.figure(num=None,figsize=(12,3),dpi=80)\n",
      "plt.subplot(151)\n",
      "plt.pcolormesh(A_inf[0,:].reshape(6,6),cmap=plt.cm.gray)\n",
      "plt.subplot(152)\n",
      "plt.pcolormesh(A_inf[1,:].reshape(6,6),cmap=plt.cm.gray)\n",
      "plt.subplot(153)\n",
      "plt.pcolormesh(A_inf[2,:].reshape(6,6),cmap=plt.cm.gray)\n",
      "plt.subplot(154)\n",
      "plt.pcolormesh(A_inf[3,:].reshape(6,6),cmap=plt.cm.gray)\n",
      "plt.subplot(155)\n",
      "plt.pcolormesh(A_inf[4,:].reshape(6,6),cmap=plt.cm.gray)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 95,
       "text": [
        "<matplotlib.collections.QuadMesh at 0x7ff5b41c5d90>"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAArsAAADMCAYAAABz22vSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
       "text": [
        "<matplotlib.figure.Figure at 0x7ff5b4532a50>"
       ]
      }
     ],
     "prompt_number": 95
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# These are heatmaps!\n",
      "plt.figure(num=None, figsize=(12,3), dpi=80, facecolor='w', edgecolor='k')\n",
      "plt.subplot(141)\n",
      "plt.pcolormesh(basis1,cmap=plt.cm.gray)     \n",
      "plt.subplot(142)\n",
      "plt.pcolormesh(basis2,cmap=plt.cm.gray)  \n",
      "plt.subplot(143)\n",
      "plt.pcolormesh(basis3,cmap=plt.cm.gray)  \n",
      "plt.subplot(144)\n",
      "plt.pcolormesh(basis4,cmap=plt.cm.gray)  "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 83,
       "text": [
        "<matplotlib.collections.QuadMesh at 0x7ff5b5189290>"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAArsAAADMCAYAAABz22vSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAMlSdgEASJayCwBAsv4PXDEO/+iVgFAAAAAASUVORK5CYII=\n",
       "text": [
        "<matplotlib.figure.Figure at 0x7ff5b5644790>"
       ]
      }
     ],
     "prompt_number": 83
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def calcM(Z,Kplus,sigmaX,sigmaA):\n",
      "    \"\"\"Save the matrix M so we won't need to calculate it again and again\"\"\"\n",
      "    return np.linalg.inv(np.dot(Z[:,0:Kplus].T,Z[:,0:Kplus])+((sigmaX/sigmaA)**2)*np.identity(Kplus))\n",
      "\n",
      "\n",
      "figure\n",
      "hist(chain.K(201:10:1000),3); colormap(gray)\n",
      "\n",
      "figure\n",
      "Z=reshape(chain.Z(1000,:,1:4),100,4);\n",
      "sigma_x=chain.sigma_X(1000);\n",
      "sigma_A=chain.sigma_A(1000);\n",
      "A_inf=(Z'*Z+(sigma_X/sigma_A)*eye(4))^-1*Z'*X;\n",
      "\n",
      "subplot(1,4,1); imagesc(reshape(A_inf(1,:),6,6)); colormap(gray); axis off\n",
      "subplot(1,4,2); imagesc(reshape(A_inf(2,:),6,6)); colormap(gray); axis off\n",
      "subplot(1,4,3); imagesc(reshape(A_inf(3,:),6,6)); colormap(gray); axis off\n",
      "subplot(1,4,4); imagesc(reshape(A_inf(4,:),6,6)); colormap(gray); axis off"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Acceptance rate\n",
      "print \"rA accept:\",np.sum(rA_accept)/mcmc\n",
      "print \"rX accept:\",np.sum(rX_accept)/mcmc\n",
      "\n",
      "\n",
      "# np.sum(np.dot(Z_arr[400,:,:],A_arr[400,:,:]))\n",
      "# print Z_arr[400,:,:]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "rA accept: 0.844\n",
        "rX accept: 0.406\n"
       ]
      }
     ],
     "prompt_number": 135
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Gibbs Sampler -- Draft for Steps"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Step 5: Sample weight matrix A ~ N(0,sigmaA**2 I)\n",
      "A_new = stats.norm.rvs(loc=0,scale=sigmaA,size=(K,D))\n",
      "# Step 6: Sample the data X ~ N(ZA,sigmaX**2 I)\n",
      "X_new = stats.norm.rvs(loc=np.dot(Z,A),scale=sigmaX,size=(N,D))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[-4542.4257]\n",
        "[-4618.9093]\n",
        "[-4542.4257]\n",
        "[-4542.4257]\n"
       ]
      }
     ],
     "prompt_number": 343
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Posterior Distribution Calculation\n",
      "\n",
      "Priors: $P(z_{ik}=1 | \\mathbf{z_{-i,k}}) = \\dfrac{m_{-i,k}+\\dfrac{\\alpha}{K}}{N+\\dfrac{\\alpha}{K}} \\rightarrow \\dfrac{m_{-i,k}}{N}$ as $K \\rightarrow \\infty$\n",
      "\n",
      "Likelihood: $\\mathbf{X}|(\\mathbf{Z},\\mathbf{A},\\mathbf{\\sigma_X}) \\sim \\text{Normal}(\\mathbf{ZA},\\Sigma_X = \\sigma_X^2\\mathbf{I})$\n",
      "\n",
      "i.e. $P(\\mathbf{X} | \\mathbf{Z}, \\sigma_X, \\sigma_A) = \\dfrac{1}{(2\\pi)^{ND/2} \\sigma_X^{(N-K)D} \\sigma_A^{KD} |\\mathbf{Z}^T\\mathbf{Z} + \\dfrac{\\sigma_X^2}{\\sigma_A^2}\\mathbf{I}|^{D/2}} \\exp\\{-\\dfrac{1}{2\\sigma^2_X} \\text{tr}(\\mathbf{X}^T(\\mathbf{I}-\\mathbf{Z}(\\mathbf{Z}^T\\mathbf{Z}+\\dfrac{\\sigma_X^2}{\\sigma_A^2}\\mathbf{I})^{-1})\\mathbf{Z}^T)\\mathbf{X}\\}$\n",
      "\n",
      "Full conditional distribution: $P(z_{ik} | \\mathbf{X,Z_{-i,k}},\\sigma_X, \\sigma_A) \\propto P(\\mathbf{X} | \\mathbf{Z},\\sigma_X, \\sigma_A) P(z_{ik} | \\mathbf{z_{-i,k}})$"
     ]
    }
   ],
   "metadata": {}
  }
 ]
}